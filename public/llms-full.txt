# https://www.firecrawl.dev llms-full.txt

## Web Data Scraping
Introducing Spark 1 Pro and Spark 1 Mini models in /agent. [Try it now ‚Üí](https://www.firecrawl.dev/agent)

[2 Months Free ‚Äî Annually](https://www.firecrawl.dev/pricing)

# Turn websites into   LLM-ready data

Power your AI apps with clean web data

from any website. [It's also open source.](https://github.com/firecrawl/firecrawl)

Scrape

Search

Agent

Map

Crawl

Scrape

Logo

\[ .JSON \]

```json
1[\
2  {\
3    "url": "https://example.9o?",\
4    "markdown": "# A90tA=g S0--!z-*-Z",\
5    "json": { "title": "Gui*!", "docs": "..." },\
6    "screenshot": "!tt-=?-/Zx9*p-e?Zoa0--?Z.png"\
7  }\
8]
```

-crzpz99...

Trusted by 80,000+

companies of all sizes

![Logo 17](https://www.firecrawl.dev/assets-original/logocloud/17.png)

![Logo 18](https://www.firecrawl.dev/assets-original/logocloud/18.png)

![Logo 1](https://www.firecrawl.dev/assets-original/logocloud/1.png)

![Logo 2](https://www.firecrawl.dev/assets-original/logocloud/2.png)

![Logo 3](https://www.firecrawl.dev/assets-original/logocloud/3.png)

![Logo 5](https://www.firecrawl.dev/assets-original/logocloud/5.png)

![Logo 6](https://www.firecrawl.dev/assets-original/logocloud/6.png)

![Logo 7](https://www.firecrawl.dev/assets-original/logocloud/7.png)

![Logo 8](https://www.firecrawl.dev/assets-original/logocloud/8.png)

![Logo 9](https://www.firecrawl.dev/assets-original/logocloud/9.png)

![Logo 10](https://www.firecrawl.dev/assets-original/logocloud/10.png)

![Logo 11](https://www.firecrawl.dev/assets-original/logocloud/11.png)

![Logo 12](https://www.firecrawl.dev/assets-original/logocloud/12.png)

![Logo 13](https://www.firecrawl.dev/assets-original/logocloud/13.png)

![Logo 14](https://www.firecrawl.dev/assets-original/logocloud/14.png)

![Logo 15](https://www.firecrawl.dev/assets-original/logocloud/15.png)

![Logo 16](https://www.firecrawl.dev/assets-original/logocloud/16.png)

![Logo 17](https://www.firecrawl.dev/assets-original/logocloud/17.png)

![Logo 18](https://www.firecrawl.dev/assets-original/logocloud/18.png)

![Logo 19](https://www.firecrawl.dev/assets-original/logocloud/19.png)

![Logo 20](https://www.firecrawl.dev/assets-original/logocloud/20.png)

![Logo 21](https://www.firecrawl.dev/assets-original/logocloud/21.png)

![Logo 17](https://www.firecrawl.dev/assets-original/logocloud/17.png)

![Logo 18](https://www.firecrawl.dev/assets-original/logocloud/18.png)

![Logo 1](https://www.firecrawl.dev/assets-original/logocloud/1.png)

![Logo 2](https://www.firecrawl.dev/assets-original/logocloud/2.png)

![Logo 3](https://www.firecrawl.dev/assets-original/logocloud/3.png)

![Logo 5](https://www.firecrawl.dev/assets-original/logocloud/5.png)

![Logo 6](https://www.firecrawl.dev/assets-original/logocloud/6.png)

![Logo 7](https://www.firecrawl.dev/assets-original/logocloud/7.png)

![Logo 8](https://www.firecrawl.dev/assets-original/logocloud/8.png)

![Logo 9](https://www.firecrawl.dev/assets-original/logocloud/9.png)

![Logo 10](https://www.firecrawl.dev/assets-original/logocloud/10.png)

![Logo 11](https://www.firecrawl.dev/assets-original/logocloud/11.png)

![Logo 12](https://www.firecrawl.dev/assets-original/logocloud/12.png)

![Logo 13](https://www.firecrawl.dev/assets-original/logocloud/13.png)

![Logo 14](https://www.firecrawl.dev/assets-original/logocloud/14.png)

![Logo 15](https://www.firecrawl.dev/assets-original/logocloud/15.png)

![Logo 16](https://www.firecrawl.dev/assets-original/logocloud/16.png)

![Logo 17](https://www.firecrawl.dev/assets-original/logocloud/17.png)

![Logo 18](https://www.firecrawl.dev/assets-original/logocloud/18.png)

![Logo 19](https://www.firecrawl.dev/assets-original/logocloud/19.png)

![Logo 20](https://www.firecrawl.dev/assets-original/logocloud/20.png)

![Logo 21](https://www.firecrawl.dev/assets-original/logocloud/21.png)

\[ 01 / 07 \]

¬∑

Main Features

//

Developer First

//

## Start scraping   today

Enhance your apps with industry leading web scraping and crawling capabilities.

Scrape

Get llm-ready data from websites. Markdown, JSON, screenshot, etc.

Search

Search the web and get full content from results.

Agent

Gather data wherever it lives on the web with a single prompt.

Python

Node.js

cURL

CLI

Copy code

```python
1# pip install firecrawl-py
2from firecrawl import Firecrawl
3
4app = Firecrawl(api_key="fc-YOUR_API_KEY")
5
6# Scrape a website:
7app.scrape('firecrawl.dev')
8
9
10
```

\[ .MD \]

```markdown
1# Firecrawl
2
3Firecrawl is a powerful web scraping
4library that makes it easy to extract
5data from websites.
6
7## Core Commands
8
9- Scrape: Markdown from any page
10- Search: Search + scrape the web
11- Map: Discover all site URLs
12- Agent: Extract with AI prompts
13
```

![developer-1](https://www.firecrawl.dev/assets-original/developer/1.png)

![developer-2](https://www.firecrawl.dev/assets-original/developer/2.png)

![developer-3](https://www.firecrawl.dev/assets-original/developer/3.png)

![developer-4](https://www.firecrawl.dev/assets-original/developer/4.png)

![developer-5](https://www.firecrawl.dev/assets-original/developer/5.png)

![developer-6](https://www.firecrawl.dev/assets-original/developer/6.png)

![developer-7](https://www.firecrawl.dev/assets-original/developer/7.png)

![developer-8](https://www.firecrawl.dev/assets-original/developer/8.png)

![developer-9](https://www.firecrawl.dev/assets-original/developer/1.png)

![developer-10](https://www.firecrawl.dev/assets-original/developer/2.png)

![developer-11](https://www.firecrawl.dev/assets-original/developer/3.png)

![developer-12](https://www.firecrawl.dev/assets-original/developer/4.png)

![developer-13](https://www.firecrawl.dev/assets-original/developer/5.png)

![developer-14](https://www.firecrawl.dev/assets-original/developer/6.png)

![developer-15](https://www.firecrawl.dev/assets-original/developer/7.png)

![developer-16](https://www.firecrawl.dev/assets-original/developer/8.png)

![developer-17](https://www.firecrawl.dev/assets-original/developer/1.png)

![developer-18](https://www.firecrawl.dev/assets-original/developer/2.png)

![developer-19](https://www.firecrawl.dev/assets-original/developer/3.png)

![developer-20](https://www.firecrawl.dev/assets-original/developer/4.png)

![developer-21](https://www.firecrawl.dev/assets-original/developer/5.png)

![developer-22](https://www.firecrawl.dev/assets-original/developer/6.png)

![developer-23](https://www.firecrawl.dev/assets-original/developer/7.png)

![developer-24](https://www.firecrawl.dev/assets-original/developer/8.png)

Integrations

### Use well-known tools

Already fully integrated with the greatest existing tools and workflows.

[See all integrations](https://www.firecrawl.dev/app)

![Firecrawl icon (blueprint)](https://www.firecrawl.dev/assets-original/developer-os-icon.png)

firecrawl/firecrawl

Public

Star

79.6K

Feature/o4 mini crawler

#1488

¬∑

Apr 22, 2025

¬∑

![aparupganguly](https://www.firecrawl.dev/_next/image?url=https%3A%2F%2Favatars.githubusercontent.com%2Fu%2F89296617%3Fv%3D4&w=48&q=75)

aparupganguly

\[python-SDK\] improvs/async

#1337

¬∑

Apr 18, 2025

¬∑

![rafaelsideguide](https://www.firecrawl.dev/_next/image?url=https%3A%2F%2Favatars.githubusercontent.com%2Fu%2F150964962%3Fv%3D4&w=48&q=75)

rafaelsideguide

feat(extract): cost limit

#1473

¬∑

Apr 17, 2025

¬∑

![mogery](https://www.firecrawl.dev/_next/image?url=https%3A%2F%2Favatars.githubusercontent.com%2Fu%2F66118807%3Fv%3D4&w=48&q=75)

mogery

feat(scrape): get job result from GCS, avoid Redis

#1461

¬∑

Apr 15, 2025

¬∑

![mogery](https://www.firecrawl.dev/_next/image?url=https%3A%2F%2Favatars.githubusercontent.com%2Fu%2F66118807%3Fv%3D4&w=48&q=75)

mogery

Extract v2/rerank improvs

#1437

¬∑

Apr 11, 2025

¬∑

![rafaelsideguide](https://www.firecrawl.dev/_next/image?url=https%3A%2F%2Favatars.githubusercontent.com%2Fu%2F150964962%3Fv%3D4&w=48&q=75)

rafaelsideguide

![https://avatars.githubusercontent.com/u/150964962?v=4](https://www.firecrawl.dev/_next/image?url=https%3A%2F%2Favatars.githubusercontent.com%2Fu%2F150964962%3Fv%3D4&w=96&q=75)

![https://avatars.githubusercontent.com/u/66118807?v=4](https://www.firecrawl.dev/_next/image?url=https%3A%2F%2Favatars.githubusercontent.com%2Fu%2F66118807%3Fv%3D4&w=96&q=75)

+90

Open Source

### Code you can trust

Developed transparently and collaboratively. Join our community of contributors.

[Check out our repo](https://github.com/firecrawl/firecrawl)

\[ 02 / 07 \]

¬∑

Core

//

Built to outperform

//

## Core principles,    proven performance

Built from the ground up to outperform traditional scrapers.

No proxy headaches

Reliable. Covers 96% of the web,

including JS-heavy and protected pages. No proxies, no puppets, just clean data.

Firecrawl

91%

![Puppeteer icon](https://www.firecrawl.dev/assets-original/puppeteer.png)

Puppeteer

76%

cURL

72%

Speed that feels invisible

Blazingly fast. Delivers results in less than 1 second, fast for real-time agents

and dynamic apps.

URL

Crawl

Scrape

firecrawl.dev/extract

0ms

0ms

firecrawl.dev/contact

250ms

300ms

firecrawl.dev/changelog

52ms

49ms

firecrawl.dev/support

49ms

52ms

firecrawl.dev/faq

52ms

51ms

firecrawl.dev/partners

52ms

52ms

firecrawl.dev/extract

50ms

50ms

\[ CTA \]

\[ CRAWL \]

\[ SCRAPE \]

\[ CTA \]

//

Get started

//

Ready to build?

Start getting Web Data for free and scale seamlessly as your project expands. No credit card needed.

[Start for free](https://www.firecrawl.dev/signin) [See our plans](https://www.firecrawl.dev/pricing)

\[ 03 / 07 \]

¬∑

Features

//

Zero configuration

//

## We handle the hard stuff

Rotating proxies, orchestration, rate limits, js-blocked content and more.

Docs to data

Media parsing. Firecrawl can parse and output content from web hosted pdfs, docx, and more.

https://example.com/docs/report.pdf

https://example.com/files/brief.docx

https://example.com/docs/guide.html

docx

Parsing

Knows the moment

Smart wait. Firecrawl intelligently waits for content to load, making scraping faster and more reliable.

https://example-spa.com

Request Sent

Scrapes the real thing

Cached, when you need it. Selective caching, you choose your caching patterns, growing web index.

![User](https://www.firecrawl.dev/_next/image?url=%2Fassets-original%2Ffeatures%2Fcached-user.png&w=256&q=75&dpl=dpl_2hQ8hmy6vNQsu8DPuBRaRM6deLpr)

User

Firecrawl

Web

Advanced web coverage

Enhanced mode. Reaches every corner of the web with comprehensive coverage and high reliability.

Interactive scraping

Actions. Click, scroll, write, wait, press and more before extracting content.

https://example.com

Navigate

Click

Type

Wait

Scroll

Press

Screenshot

Scrape

\[ 04 / 07 \]

¬∑

Pricing

//

Transparent

//

## Flexible pricing

Explore transparent pricing built for real-world scraping.  Start for free, then scale as you grow.

üá∫üá∏USD

Free Plan

A lightweight way to try scraping.

No cost, no card, no hassle.

500 credits (one-time)

$0123456789

one-time

Get started

Scrape 500 pages

2 concurrent requests

Low rate limits

Hobby

Great for side projects and small tools.

Fast, simple, no overkill.

3,000 credits / month

$01234567890123456789

/monthly

Billed yearly

2 months free

Subscribe

Scrape 3,000 pages

5 concurrent requests

Basic support

$9 per extra 1k credits

Standard

Most popular

Perfect for scaling with less effort.

Simple, solid, dependable.

100,000 credits / month

$01234567890123456789

/monthly

Billed yearly

2 months free

Subscribe

Scrape 100,000 pages

50 concurrent requests

Standard support

$47 per extra 35k credits

Growth

Built for high volume and speed.

Firecrawl at full force.

500,000 credits / month

$012345678901234567890123456789

/monthly

Billed yearly

2 months free

Subscribe

Scrape 500,000 pages

100 concurrent requests

Priority support

$177 per extra 175k credits

Extra credits are available via auto-recharge packs. [Enable](https://www.firecrawl.dev/signin?view=signup)

## Scale Plans

High-volume plans for teams that need more power and dedicated support. Get access to higher rate limits, more concurrent browsers, and priority support.

[Need more? Contact us](https://fk4bvu0n5qp.typeform.com/to/Ej6oydlg)

Scale

For teams scaling their data pipelines

1,000,000 credits

$599per month

Billed yearly

2 months free

Subscribe

Scrape 1,000,000 pages

150 concurrent requests

Priority support

Enterprise

Power at your pace with custom solutions

Custom credits

Custom

[Get Started](https://fk4bvu0n5qp.typeform.com/to/Ej6oydlg)

Scrape unlimited pages

Custom concurrent requests

Dedicated support & SLA

Bulk discounts

Zero-data retention

SSO & advanced security

\[ 05 / 07 \]

¬∑

Testimonials

//

Community

//

## People love    building with Firecrawl

Discover why developers choose Firecrawl every day.

[![Morgan Linton](https://www.firecrawl.dev/assets-original/testimonials/morgan-linton.png)Morgan Linton@morganlinton"If you're coding with AI, and haven't discovered @firecrawl yet, prepare to have your mind blown ü§Ø"](https://x.com/morganlinton/status/1839454165703204955) [![Chris DeWeese](https://www.firecrawl.dev/assets-original/testimonials/chris-deweese.png)Chris DeWeese@chrisdeweese\_"Started using @firecrawl for a project, I wish I used this sooner."](https://x.com/chrisdeweese_/status/1853587120406876601) [![Alex Reibman](https://www.firecrawl.dev/assets-original/testimonials/alex-reibman.png)Alex Reibman@AlexReibman"Moved our internal agent's web scraping tool from Apify to Firecrawl because it benchmarked 50x faster with AgentOps."](https://x.com/AlexReibman/status/1780299595484131836) [![Tom - Morpho](https://www.firecrawl.dev/assets-original/testimonials/tom-morpho.png)Tom - Morpho@TomReppelin"I found gold today. Thank you @firecrawl"](https://x.com/TomReppelin/status/1844382491014201613)

[![Morgan Linton](https://www.firecrawl.dev/assets-original/testimonials/morgan-linton.png)Morgan Linton@morganlinton"If you're coding with AI, and haven't discovered @firecrawl yet, prepare to have your mind blown ü§Ø"](https://x.com/morganlinton/status/1839454165703204955) [![Chris DeWeese](https://www.firecrawl.dev/assets-original/testimonials/chris-deweese.png)Chris DeWeese@chrisdeweese\_"Started using @firecrawl for a project, I wish I used this sooner."](https://x.com/chrisdeweese_/status/1853587120406876601) [![Alex Reibman](https://www.firecrawl.dev/assets-original/testimonials/alex-reibman.png)Alex Reibman@AlexReibman"Moved our internal agent's web scraping tool from Apify to Firecrawl because it benchmarked 50x faster with AgentOps."](https://x.com/AlexReibman/status/1780299595484131836) [![Tom - Morpho](https://www.firecrawl.dev/assets-original/testimonials/tom-morpho.png)Tom - Morpho@TomReppelin"I found gold today. Thank you @firecrawl"](https://x.com/TomReppelin/status/1844382491014201613)

[![Bardia](https://www.firecrawl.dev/assets-original/testimonials/bardia.png)Bardia@thepericulum"The Firecrawl team ships. I wanted types for their node SDK, and less than an hour later, I got them."](https://x.com/thepericulum/status/1781397799487078874) [![Matt Busigin](https://www.firecrawl.dev/assets-original/testimonials/matt-busigin.png)Matt Busigin@mbusigin"Firecrawl is dope. Congrats guys üëè"](https://x.com/mbusigin/status/1836065372010656069) [![Sumanth](https://www.firecrawl.dev/assets-original/testimonials/sumanth.png)Sumanth@Sumanth\_077"Web scraping will never be the same!\\
\\
Firecrawl is an open-source framework that takes a URL, crawls it, and conver..."](https://x.com/Sumanth_077/status/1940049003074478511) [![Steven Tey](https://www.firecrawl.dev/assets-original/testimonials/steven-tey.png)Steven Tey@steventey"Open-source Clay alternative just dropped\\
\\
Upload a CSV of emails and..."](https://x.com/steventey/status/1932945651761098889)

[![Bardia](https://www.firecrawl.dev/assets-original/testimonials/bardia.png)Bardia@thepericulum"The Firecrawl team ships. I wanted types for their node SDK, and less than an hour later, I got them."](https://x.com/thepericulum/status/1781397799487078874) [![Matt Busigin](https://www.firecrawl.dev/assets-original/testimonials/matt-busigin.png)Matt Busigin@mbusigin"Firecrawl is dope. Congrats guys üëè"](https://x.com/mbusigin/status/1836065372010656069) [![Sumanth](https://www.firecrawl.dev/assets-original/testimonials/sumanth.png)Sumanth@Sumanth\_077"Web scraping will never be the same!\\
\\
Firecrawl is an open-source framework that takes a URL, crawls it, and conver..."](https://x.com/Sumanth_077/status/1940049003074478511) [![Steven Tey](https://www.firecrawl.dev/assets-original/testimonials/steven-tey.png)Steven Tey@steventey"Open-source Clay alternative just dropped\\
\\
Upload a CSV of emails and..."](https://x.com/steventey/status/1932945651761098889)

\[ 06 / 07 \]

¬∑

Use Cases

//

Use cases

//

## Transform    web data into   AI-powered solutions

Discover how Firecrawl customers are getting the most out of our API.

[View all use cases](https://www.firecrawl.dev/use-cases)

Chat with context

Smarter AI chats

Power your AI assistants with real-time, accurate web content.

[Learn more](https://www.firecrawl.dev/use-cases/ai-chats)

![AI Assistant](https://www.firecrawl.dev/assets-original/ai/bot.png)

AI Assistant

withFirecrawl

Real-time¬∑Updated 2 min ago

What's new in the Re\|

Know your leads

Lead enrichment

Enhance your sales data with

web information.

[Learn more](https://www.firecrawl.dev/use-cases/lead-enrichment)

Extracting leads from directory

Tech startups

1,243

With contact info

8!2

Decision makers

00=-=

Funding stage

S\*-9e? A+

Ready to engage

64-

![Emily Tran](https://www.firecrawl.dev/assets-original/ai/leads-1.png)

Emily Tran

Product Manager

+1 (415) 80-Za46-

emilA.=r9nzn-ura9Alo-.9\*

![James Carter](https://www.firecrawl.dev/assets-original/ai/leads-2.png)

?\-\\*?\- zarte!

H!ad o9 -?rtn!rzh=ps

+1 -a4-- Z01az=40

0zAr-!\*==?n!yZAZ\*zZz

![Sophia Kim](https://www.firecrawl.dev/assets-original/ai/leads-3.png)

9\*?h0a Ki?

S9nior D-t9 A-azAst

\+\- (3-2A z-8Z=-a9

!9k?m@a-aAs=\*-=c-m

![Michael Rivera](https://www.firecrawl.dev/assets-original/ai/leads-4.png)

a=?hae9 RiZz0-

CT-

+1 \*9\*?) Z6?A8-ZA

m.ai--?a-0-zep\*\*h0\*ez

Know your leads

MCPs

Add powerful scraping to your

code editors.

[Learn more](https://www.firecrawl.dev/use-cases/ai-mcps)

![Claude Code](https://www.firecrawl.dev/assets-original/ai/mcps-claude.png)

Claude Code

![Cursor](https://www.firecrawl.dev/assets-original/ai/mcps-cursor.png)

Cursor

![Windsurf](https://www.firecrawl.dev/assets-original/ai/mcps-windsurf.png)

Windsurf

‚úª

Welcome to Claude Code!

/help for help, /status for your current setup

\>

Extract pricing

Build with context

AI platforms

Let your customers build AI apps

with web data.

[Learn more](https://www.firecrawl.dev/use-cases/ai-platforms)

![Logo 1](https://www.firecrawl.dev/assets-original/ai/platforms-1.png)

![Logo 2](https://www.firecrawl.dev/assets-original/ai/platforms-2.png)

![Logo 4](https://www.firecrawl.dev/assets-original/ai/platforms-4.png)

![Logo 3](https://www.firecrawl.dev/assets-original/ai/platforms-3.png)

Extracting text

No insight missed

Deep research

Extract comprehensive information for

in-depth research.

[Learn more](https://www.firecrawl.dev/use-cases/deep-research)

Deep research in progress

Academic papers

0 found

News articles

0 found

Expert opinions

0 found

Research reports

0 found

Industry data

0 found

Qu\|

\[ CTA \]

\[ CRAWL \]

\[ SCRAPE \]

\[ CTA \]

//

Get started

//

Ready to build?

Start getting Web Data for free and scale seamlessly as your project expands. No credit card needed.

[Start for free](https://www.firecrawl.dev/signin) [See our plans](https://www.firecrawl.dev/pricing)

\[ 07 / 07 \]

¬∑

FAQ

//

FAQ

//

## Frequently    asked questions

Everything you need to know about Firecrawl.

General

What is Firecrawl?

Firecrawl turns entire websites into clean, LLM-ready markdown or structured data. Scrape, crawl and extract the web with a single API. Ideal for AI companies looking to empower their LLM applications with web data

What sites work?

Firecrawl is best suited for business websites, docs and help centers. We currently don't support social media platforms.

Who can benefit from using Firecrawl?

Firecrawl is tailored for LLM engineers, data scientists, AI researchers, and developers looking to harness web data for training machine learning models, market research, content aggregation, and more. It simplifies the data preparation process, allowing professionals to focus on insights and model development.

Is Firecrawl open-source?

Yes, it is. You can check out the repository on GitHub. Keep in mind that this repository is currently in its early stages of development. We are in the process of merging custom modules into this mono repository.

What is the difference between Firecrawl and other web scrapers?

Firecrawl is designed with reliability and AI-ready data in mind. We focus on delivering data reliably and in a LLM-ready format - so you can spend less tokens and build better AI applications.

What is the difference between the open-source version and the hosted version?

Firecrawl's hosted version features Fire-engine which is our proprietary scraper that takes care of proxies, anti-bot mechanisms and more. It is an intelligent scraper designed to get the data you need - reliably. The hosted version also allows for actions (interacting with the page before scraping), a dashboard for analytics, and it is 1 API call away.

Scraping & Crawling

How does Firecrawl handle dynamic content on websites?

Unlike traditional web scrapers, Firecrawl is equipped to handle dynamic content rendered with JavaScript. It ensures comprehensive data collection from all accessible subpages, making it a reliable tool for scraping websites that rely heavily on JS for content delivery.

Why is it not crawling all the pages?

There are a few reasons why Firecrawl may not be able to crawl all the pages of a website. Some common reasons include rate limiting, and anti-scraping mechanisms, disallowing the crawler from accessing certain pages. If you're experiencing issues with the crawler, please reach out to our support team at help@firecrawl.com.

Can Firecrawl crawl websites without a sitemap?

Yes, Firecrawl can access and crawl all accessible subpages of a website, even in the absence of a sitemap. This feature enables users to gather data from a wide array of web sources with minimal setup.

What formats can Firecrawl convert web data into?

Firecrawl specializes in converting web data into clean, well-formatted markdown. This format is particularly suited for LLM applications, offering a structured yet flexible way to represent web content.

How does Firecrawl ensure the cleanliness of the data?

Firecrawl employs advanced algorithms to clean and structure the scraped data, removing unnecessary elements and formatting the content into readable markdown. This process ensures that the data is ready for use in LLM applications without further preprocessing.

Is Firecrawl suitable for large-scale data scraping projects?

Absolutely. Firecrawl offers various pricing plans, including a Scale plan that supports scraping of millions of pages. With features like caching and scheduled syncs, it's designed to efficiently handle large-scale data scraping and continuous updates, making it ideal for enterprises and large projects.

Does it respect robots.txt?

Yes, Firecrawl's crawl endpoint respects the rules set in a website's robots.txt file. If you notice any issues with the way Firecrawl interacts with your website, you can adjust the robots.txt file to control the crawler's behavior. Firecrawl user agent name is 'FirecrawlAgent'. If you notice any behavior that is not expected, please let us know at help@firecrawl.com.

What measures does Firecrawl take to handle web scraping challenges like rate limits and caching?

Firecrawl is built to navigate common web scraping challenges, including stealth proxies, rate limits, and smart wait. It smartly manages requests and employs techniques to minimize bandwidth usage and avoid triggering anti-scraping mechanisms, ensuring reliable data collection.

Does Firecrawl handle complex websites?

Firecrawl uses optimized infrastructure including proxy management and smart request handling to reliably collect data from complex websites. You can also pass custom headers to the API for additional flexibility.

API Related

Where can I find my API key?

Click on the dashboard button on the top navigation menu when logged in and you will find your API key in the main screen and under API Keys.

Billing

Is Firecrawl free?

Firecrawl is free for the first 500 scraped pages (500 free credits). After that, you can upgrade to our Hobby, Standard or Growth plans for more credits and higher rate limits.

Is there a pay-per-use plan instead of monthly?

We currently do not offer a pay-per-use plan, instead you can upgrade to our Hobby, Standard or Growth plans for more credits and higher rate limits.

Do credits roll over to the next month?

In short, no ‚Äî credits do not roll over to the next month/year. Credit packs follow their own billing period. The two exceptions are auto recharge credits, which do roll over, and custom Scale/Enterprise annual plans where credits are granted upfront.

How many credits do scraping and crawling cost?

Scraping and crawling usually cost 1 credit per webpage or 1 credit per PDF page. There are advanced features available which cost additional credits. Check out the credits table on the pricing page for more details.

Do you charge for failed requests?

We do not usually charge for any failed requests. The only exception is requests using FIRE-1 agent are always billed, even if the request fails. Please contact support at help@firecrawl.com if you notice something wrong.

What payment methods do you accept?

We accept payments through Stripe which accepts most major credit cards, debit cards, and PayPal.

FOOTER

The easiest way to extract

data from the web

Backed by

Y Combinator

[Linkedin](https://www.linkedin.com/company/firecrawl) [Github](https://github.com/firecrawl/firecrawl) [YouTube](https://www.youtube.com/@Firecrawl_dev)

SOC II ¬∑ Type 2

AICPA

SOC 2

[X (Twitter)](https://x.com/firecrawl) [Discord](https://discord.gg/gSmWdAkdwd)

Products

[Playground](https://www.firecrawl.dev/playground) [Agent](https://www.firecrawl.dev/agent) [Pricing](https://www.firecrawl.dev/pricing) [Templates](https://www.firecrawl.dev/templates) [Changelog](https://www.firecrawl.dev/changelog)

Use Cases

[AI Platforms](https://www.firecrawl.dev/use-cases/ai-platforms) [Lead Enrichment](https://www.firecrawl.dev/use-cases/lead-enrichment) [SEO Teams](https://www.firecrawl.dev/use-cases/seo-teams) [Deep Research](https://www.firecrawl.dev/use-cases/deep-research) [Competitive Intelligence](https://www.firecrawl.dev/use-cases/competitive-intelligence)

Documentation

[Getting started](https://docs.firecrawl.dev/introduction) [API Reference](https://docs.firecrawl.dev/api-reference/introduction) [Integrations](https://www.firecrawl.dev/app) [Examples](https://docs.firecrawl.dev/use-cases/overview) [SDKs](https://docs.firecrawl.dev/sdks/overview)

Company

[Blog](https://www.firecrawl.dev/blog) [Careers](https://www.firecrawl.dev/careers) [Creator & OSS program](https://www.firecrawl.dev/creator-oss-program) [Student program](https://www.firecrawl.dev/student-program)

¬© 2025 Firecrawl

[Terms of Service](https://www.firecrawl.dev/terms-of-service) [Privacy Policy](https://www.firecrawl.dev/privacy-policy) [Report Abuse](mailto:help@firecrawl.com?subject=Issue:)

[All systems normal](https://status.firecrawl.dev/)

StripeM-Inner

## Web Data Extraction Playground
Introducing Spark 1 Pro and Spark 1 Mini models in /agent. [Try it now ‚Üí](https://www.firecrawl.dev/agent)

# Playground

API, Docs and Playground

\- all in one place

Scrape

Search

Agent
New

Map

Crawl

Scrape

https://

Format:Markdown

Get code

Start scraping

FOOTER

The easiest way to extract

data from the web

Backed by

Y Combinator

[Linkedin](https://www.linkedin.com/company/firecrawl) [Github](https://github.com/firecrawl/firecrawl) [YouTube](https://www.youtube.com/@Firecrawl_dev)

SOC II ¬∑ Type 2

AICPA

SOC 2

[X (Twitter)](https://x.com/firecrawl) [Discord](https://discord.gg/gSmWdAkdwd)

Products

[Playground](https://www.firecrawl.dev/playground) [Agent](https://www.firecrawl.dev/agent) [Pricing](https://www.firecrawl.dev/pricing) [Templates](https://www.firecrawl.dev/templates) [Changelog](https://www.firecrawl.dev/changelog)

Use Cases

[AI Platforms](https://www.firecrawl.dev/use-cases/ai-platforms) [Lead Enrichment](https://www.firecrawl.dev/use-cases/lead-enrichment) [SEO Teams](https://www.firecrawl.dev/use-cases/seo-teams) [Deep Research](https://www.firecrawl.dev/use-cases/deep-research) [Competitive Intelligence](https://www.firecrawl.dev/use-cases/competitive-intelligence)

Documentation

[Getting started](https://docs.firecrawl.dev/introduction) [API Reference](https://docs.firecrawl.dev/api-reference/introduction) [Integrations](https://www.firecrawl.dev/app) [Examples](https://docs.firecrawl.dev/use-cases/overview) [SDKs](https://docs.firecrawl.dev/sdks/overview)

Company

[Blog](https://www.firecrawl.dev/blog) [Careers](https://www.firecrawl.dev/careers) [Creator & OSS program](https://www.firecrawl.dev/creator-oss-program) [Student program](https://www.firecrawl.dev/student-program)

¬© 2025 Firecrawl

[Terms of Service](https://www.firecrawl.dev/terms-of-service) [Privacy Policy](https://www.firecrawl.dev/privacy-policy) [Report Abuse](mailto:help@firecrawl.com?subject=Issue:)

[All systems normal](https://status.firecrawl.dev/)

reCAPTCHA

Recaptcha requires verification.

[Privacy](https://www.google.com/intl/en/policies/privacy/) \- [Terms](https://www.google.com/intl/en/policies/terms/)

protected by **reCAPTCHA**

[Privacy](https://www.google.com/intl/en/policies/privacy/) \- [Terms](https://www.google.com/intl/en/policies/terms/)

## Open Agent Builder Tool
Introducing Spark 1 Pro and Spark 1 Mini models in /agent. [Try it now ‚Üí](https://www.firecrawl.dev/agent)

//

Get started

//

### Ready to build?

Start getting Web Data for free and scale seamlessly as your project expands. No credit card needed.

[Start for free](https://www.firecrawl.dev/signin) [See our plans](https://www.firecrawl.dev/pricing)

#### Table of Contents

[Blog](https://www.firecrawl.dev/blog)

Open Agent Builder - Open-Source Visual Workflow Builder for AI Agents

![placeholder](https://www.firecrawl.dev/_next/image?url=%2Fblog%2Fauthors%2Fbex.jpg&w=48&q=75&dpl=dpl_2hQ8hmy6vNQsu8DPuBRaRM6deLpr)Bex Tuychiev

Nov 05, 2025

![Open Agent Builder - Open-Source Visual Workflow Builder for AI Agents image](https://www.firecrawl.dev/_next/image?url=%2Fimages%2Fblog%2Fopen-agent-builder%2Fopen-agent-builder-visual-workflow.webp&w=3840&q=75&dpl=dpl_2hQ8hmy6vNQsu8DPuBRaRM6deLpr)

Building AI agents means dealing with code. You need to understand Python frameworks like LangGraph or CrewAI, wire up APIs, and manage orchestration logic. When you want to create a workflow that scrapes websites, makes decisions, and processes data, you're looking at setting up multiple libraries, handling state management, and debugging complex execution flows. The setup takes time when you just want to build and test quickly.

![Open Agent Builder landing page](https://www.firecrawl.dev/images/blog/open-agent-builder/open-agent-builder-landing-page-once-localhost-is-running.webp)

Visual workflow builders exist. Tools like n8n, Zapier, and Make handle automation well, but they were designed for general task automation rather than AI agent patterns. OpenAI released its own agent builder, but it locks you into OpenAI's models only. There's room for something built specifically for agent workflows that lets you choose your AI provider.

[Open Agent Builder](https://github.com/firecrawl/open-agent-builder) fills this space. It's an open-source visual workflow builder designed for AI agents. Built by the [Firecrawl](https://firecrawl.dev/) team, you drag and drop nodes to create agent workflows‚Äîfrom web scraping to reasoning to conditional logic. It supports multiple AI providers (Anthropic, OpenAI, Groq) and runs in real-time. No Python files, just a visual canvas that shows exactly what your agent will do.

This article covers what Open Agent Builder is and how it works. You'll learn about the node-based system, how to deploy your first workflow, and what kinds of automation you can build with it. By the end, you'll know whether this tool fits your needs.

## What is Open Agent Builder?

Open Agent Builder is a visual workflow builder for AI agents. You connect nodes to create pipelines: web scraping, reasoning, conditional logic. Unlike OpenAI's agent builder which locks you to their models, this is open source and supports any AI provider (Claude, OpenAI, Groq, or OpenAI-compatible endpoints). Built by the [Firecrawl](https://firecrawl.dev/) team under MIT license, it runs locally or deploys to Vercel.

Open Agent Builder makes AI agent workflows accessible through visual design. The project fits into the broader ecosystem of [open source agent frameworks](https://www.firecrawl.dev/blog/best-open-source-agent-frameworks-2025) but takes a different approach: those frameworks require code, while this uses a visual interface.

Common use cases:

- Web scraping workflows with multi-step logic
- Research automation that crawls and summarizes content
- Competitive analysis pipelines
- Price monitoring with conditional alerts
- Custom workflows that integrate internal tools

The workflow system uses eight node types:

- Start/End nodes
- Agent nodes (LLM reasoning)
- MCP Tools (external APIs)
- Transform (data manipulation)
- Conditional logic (If/Else, While Loop)
- User Approval for human-in-the-loop workflows

These node types combine to handle patterns from simple scrapers to complex multi-agent systems.

### Who should use Open Agent Builder?

Open Agent Builder is a great tool for:

**Developers** who want to prototype agent workflows quickly. Visual design speeds up iteration and makes debugging easier. You get LangGraph's orchestration under the hood.

**Non-technical users** who need AI-powered automation. If you've used tools like Zapier or n8n, you already understand the workflow concept. Open Agent Builder applies that same pattern to AI agents. Transform nodes support JavaScript for custom logic when needed.

**Teams** building automation together. Visual workflows make collaboration easier. Product managers can design workflows, developers can deploy them, and everyone sees what the automation does.

### The tech stack

- **Frontend**: Next.js 16, React, Tailwind CSS, React Flow (drag-and-drop canvas interface)
- **Backend**: LangGraph (workflow orchestration and state management), Convex (real-time database with live workflow updates)
- **Auth**: Clerk (user authentication and session management)
- **AI providers**: Claude, OpenAI, Groq, or any OpenAI-compatible endpoint (powers the agent reasoning)
- **Scraping**: Firecrawl (handles JavaScript rendering and returns clean, structured data)
- **Execution**: E2B or Vercel sandboxes (secure isolated environments for running code)

You can switch AI providers without rebuilding workflows. Firecrawl is built by the same team and handles web scraping reliably.

With a clear understanding of what Open Agent Builder offers and who can benefit from it, let's get it running on your local machine.

## Setting Up Open Agent Builder Locally

Now that you've learned what Open Agent Builder can do and the technology behind it, let's walk through how to set it up on your local machine.

### Prerequisites

You need Node.js 18 or higher installed‚Äîthis is the JavaScript runtime that runs the application. You also need npm or pnpm (package managers that come with Node.js) and Git to clone the repository.

### Clone the repository

```
git clone https://github.com/firecrawl/open-agent-builder.git
cd open-agent-builder

# Install dependencies
npm install
# or if you use pnpm
pnpm install
```

### Get your API keys

Before configuring the application, you need accounts and API keys from these services:

**Firecrawl** (for web scraping):

- Sign up at [firecrawl.dev](https://firecrawl.dev/)
- Navigate to your dashboard and copy the API key
- See the [Firecrawl quickstart guide](https://docs.firecrawl.dev/) for detailed steps

**AI provider** (choose one):

- Anthropic Claude: Sign up at anthropic.com and create an API key (works best with MCP tools)
- OpenAI: Sign up at openai.com and create an API key
- Groq: Sign up at groq.com and create an API key

**Convex** (real-time database):

- Create a free account at [convex.dev](https://convex.dev/)
- We'll get the deployment URL in the next step

**Clerk** (authentication):

- Create a free account at [clerk.com](https://clerk.com/)
- Create a new application
- Copy your API keys from the dashboard (you'll see both the secret key and publishable key)
- Go to Configure > JWT Templates > Create New Template
- Select "Convex" from the template options
- Copy the Issuer URL that appears (looks like `https://your-app.clerk.accounts.dev`)

![Clerk JWT template configuration page](https://www.firecrawl.dev/images/blog/open-agent-builder/clerk-app-settings-page-to-get-jwt-token.webp)_Copy the Issuer URL from your Convex JWT template configuration_

Save these credentials - you'll need them in the configuration steps below.

**E2B** (optional, for code execution sandboxes):

- Sign up at [e2b.dev](https://e2b.dev/) if you need secure code execution

### Set up Convex

Convex powers the real-time database. Open Agent Builder needs a database to store your workflows, execution history, and real-time updates as nodes run. Convex handles this automatically with live synchronization between the backend and your browser interface.

To start, install the Convex CLI and initialize your project:

```
# Install Convex CLI globally
npm install -g convex

# Initialize and start Convex development server
npx convex dev
```

The `npx convex dev` command automatically creates your `.env.local` file and adds the `NEXT_PUBLIC_CONVEX_URL` variable. It will prompt you to log in from the terminal. Follow the instructions to create a project and set your device name.

Keep the Convex dev server running in the background.

### Configure environment variables

Open `.env.local` in your editor. The file should already have `NEXT_PUBLIC_CONVEX_URL` from the Convex setup. Add your API keys from the services above:

```
# Automatically added by npx convex dev
NEXT_PUBLIC_CONVEX_URL=https://your-deployment.convex.cloud

# Add these manually:
FIRECRAWL_API_KEY=your_firecrawl_key_here

# Pick one AI provider
ANTHROPIC_API_KEY=your_claude_key_here
# or use OPENAI_API_KEY if you picked OpenAI
# or use GROQ_API_KEY if you picked Groq

# Clerk authentication (from clerk.com dashboard)
CLERK_SECRET_KEY=your_clerk_secret_key
NEXT_PUBLIC_CLERK_PUBLISHABLE_KEY=your_clerk_publishable_key
CLERK_JWT_ISSUER_DOMAIN=https://your-app.clerk.accounts.dev  # Save this - you'll need it for the next step

# Optional: E2B sandbox for code execution
E2B_API_KEY=your_e2b_key_here
```

Save the file.

### Configure Convex authentication

Convex needs to integrate with Clerk for authentication. Open `convex/auth.config.ts` and **hardcode** your Clerk issuer domain:

```
export default {
  providers: [\
    {\
      domain: "https://your-app.clerk.accounts.dev", // Replace with your actual Clerk issuer URL from .env.local\
      applicationID: "convex",\
    },\
  ],
};
```

**Important:** The domain must be hardcoded: don't use `process.env.CLERK_JWT_ISSUER_DOMAIN`. Convex functions don't run in a Node.js environment, so `process` is undefined and will cause TypeScript errors.

After editing the file, **restart your Convex dev server**:

```
# Stop the server (Ctrl+C), then restart
npx convex dev
```

This ensures Convex picks up the authentication configuration changes.

### Run the development server

You have two options:

**Option 1: Run both servers with one command** (recommended):

```
npm run dev:all
```

**Option 2: Run servers separately**:

```
# Terminal 1: Convex (if not already running)
npx convex dev

# Terminal 2: Next.js development server
npm run dev
```

Open `http://localhost:3000` in your browser. You should see the Open Agent Builder interface with a blank canvas.

### Try your first workflow

Start with a template from the library to get familiar with the interface. The library includes pre-built categories like Web Scraping, Research Automation, and Price Monitoring.

![Workflow templates gallery](https://www.firecrawl.dev/images/blog/open-agent-builder/existing-workflow-templates-provided-by-open-agent-builder.webp)_Available workflow templates to help you get started_

Select one, look at how the nodes connect, and click run to watch it execute. You can customize any workflow by adding or removing nodes.

We'll explore the interface and node types in detail in the next section, where we'll walk through a complete workflow example to show you exactly how everything works together.

### Troubleshooting common issues

**Authentication error: "No auth provider found matching the given token"**

This happens when your Clerk JWT issuer doesn't match the domain in `convex/auth.config.ts`.

**Fix:**

1. Verify `convex/auth.config.ts` domain exactly matches your `CLERK_JWT_ISSUER_DOMAIN` from `.env.local`
2. Clear browser cache: DevTools ‚Üí Application ‚Üí Storage ‚Üí Clear "Local Storage" and "Cookies" for localhost:3000
3. Hard refresh (Cmd+Shift+R or Ctrl+Shift+R)
4. Restart Convex dev server if you changed `auth.config.ts`

**TypeScript error: "Cannot find name 'process'"**

```
convex/auth.config.ts:13:15 - error TS2591: Cannot find name 'process'
```

**Fix:** You're using `process.env.CLERK_JWT_ISSUER_DOMAIN` in your auth config. Replace it with the hardcoded domain value:

```
// ‚ùå Wrong - causes error
domain: process.env.CLERK_JWT_ISSUER_DOMAIN!,

// ‚úÖ Correct - use actual domain
domain: "https://your-app.clerk.accounts.dev",
```

With Open Agent Builder running successfully on your machine, you're ready to explore how workflows are built and executed through the visual interface.

## Exploring the Open Agent Builder UI

With Open Agent Builder running locally, you can explore how workflows are built and executed. The best way to understand the interface is through an actual example, so we'll walk through the Zillow Property Finder template. This workflow searches for properties in a specific location, analyzes each one, and generates a comparison report‚Äîa real-world automation that demonstrates all the key UI concepts.

### The workflow canvas

Opening any workflow displays a visual canvas where nodes connect to form your automation pipeline. Each node represents a step, and the lines between them show how data flows:

![Zillow Property Finder workflow on canvas](https://www.firecrawl.dev/images/blog/open-agent-builder/zillow-property-finder-workflow-snapshot-on-canvas-part-of-it.webp)_The complete Zillow workflow showing how nodes connect from start to finish_

The workflow flows left to right, with data passing from one node to the next through the connections. Notice how the Loop Properties node has two outgoing paths‚ÄîContinue and Break‚Äîwhich control whether the loop keeps running or stops. This branching structure is how workflows handle conditional logic.

### Running a workflow

Before running the workflow, ensure your API keys are set up in the workflow settings page:

![Configuration status showing configured API keys](https://www.firecrawl.dev/images/blog/open-agent-builder/workflow-settings-page-where-you-should-have-configured-api-keys-and-env-variables.webp)_Check that your LLM providers and Firecrawl integration are properly configured_

Now, click the play button. A preview panel opens on the right side, displaying each node's output in real-time:

![Workflow execution preview panel](https://www.firecrawl.dev/images/blog/open-agent-builder/sample-agent-named-search-zillow-running-in-openagentbuilder-canvas.webp)_The Search Zillow agent running with input parameters: location, max\_price, and min\_beds_

The preview shows the Start node's output first, which includes your workflow inputs (Austin, TX location, $500,000 max price, 3 minimum bedrooms). These variables get passed to the next node in the chain, where they're used to customize the search parameters.

### Configuring Agent nodes

Agent nodes are where your AI reasoning happens. Click any Agent node to open its configuration panel and see what instructions it follows. The Analyze Property node shows a typical setup:

![Agent node configuration modal](https://www.firecrawl.dev/images/blog/open-agent-builder/expanded-menu-of-agent-node-in-zillow-property-finder-workflow.webp)_Agent node showing instructions, model selection, and available tools_

The configuration has several parts:

**Instructions**: Tell the AI what to do. You can insert variables from previous nodes using the `{{variable}}` syntax. In this example, `{{lastOutput.address}}` pulls the property address from the previous node's output.

**Model**: Choose your AI provider from the dropdown. You'll see available models like GPT-5, Claude, or Groq. Switching models doesn't require changing your workflow‚Äîjust select a different option.

**Tools**: The agent can use external tools when needed. Firecrawl shows 7 available tools for web scraping and data extraction. The agent automatically calls these tools when its instructions require them.

**Output format**: Control how the agent returns data (text, JSON, etc.).

### Control flow with loops

Loops let you repeat actions across multiple items. The Loop Properties node iterates through each property found by the search. Click it to see how loop conditions work:

![Loop node configuration](https://www.firecrawl.dev/images/blog/open-agent-builder/sample-loop-node-as-example-of-control-flow-in-workflows.webp)_Loop condition using JavaScript to check iteration count against total properties_

The loop condition is a JavaScript expression: `iteration <= state.variables["parse-properties"].totalCount`. This compares the current iteration number to the total number of properties found.

The orange helper box shows available variables you can reference:

- **Input Variables**: The workflow's starting inputs (location, max\_price, min\_beds)
- **Previous Nodes**: Output from each node that ran before this one
- **Special**: Built-in variables like `lastOutput` and `iteration`

Common patterns are listed at the bottom, and you can click any pattern to insert it into your condition.

### Viewing results

When all nodes finish executing, the End node displays your final output:

![Completed workflow showing results](https://www.firecrawl.dev/images/blog/open-agent-builder/sample-completed-run-of-zillow-property-finder-workflow.webp)_The End node displaying a completed property comparison report for Austin, TX_

This workflow took 23 seconds to run and produced a detailed analysis comparing properties in the Austin market, complete with specific recommendations about pricing strategy and investment opportunities.

### Building your own workflows

Open the Zillow Property Finder template from your templates gallery and experiment with it. Change the location to your city, adjust the price range, and run it to see how each node executes. Try modifying the instructions in the Agent nodes and watch how the output changes.

Once you're comfortable with how templates work, use the Create Workflow button to build your own automation from scratch. Most workflows follow this basic structure: Start ‚Üí Fetch data ‚Üí Process with AI ‚Üí Apply logic ‚Üí Output results. The templates give you a foundation to understand these patterns before you design custom solutions.

Now that you understand how to build and run workflows locally, the next step is making your instance accessible from anywhere by deploying it to production.

## Deploying Open Agent Builder to Vercel

You've explored the interface and tested workflows locally. The next step is getting Open Agent Builder online so you can access it from anywhere and share it with your team. Vercel is the deployment platform built by the creators of Next.js, making it the natural choice for this Next.js application.

### Vercel benefits

Vercel is designed for Next.js applications like Open Agent Builder. You get a free tier for personal projects, automatic deployments whenever you push code to GitHub, and a global CDN that makes your app fast anywhere in the world. The platform auto-detects Next.js configuration, so you don't need to configure build settings manually.

### Prerequisites

Before you start the deployment process, gather these requirements:

- A GitHub account (free at github.com)
- A Vercel account (free at vercel.com)
- Your local Open Agent Builder setup working from the previous section
- Git installed on your machine

### Preparing Your Repository

Vercel deploys directly from GitHub, so you'll need to push your configured setup to your own repository. Since you cloned the original Open Agent Builder repository, Git is already initialized, but the remote origin points to the Firecrawl repository. You need to change it to point to your own repository.

First, go to github.com and create a new repository. When GitHub asks if you want to initialize it with a README, skip that option since you already have code.

![GitHub repository creation form](https://www.firecrawl.dev/images/blog/open-agent-builder/github-repo-creation-for-vercel-deployment.webp)_Create a new repository without initializing it with README or .gitignore_

Copy the repository URL from the page, then update your local repository to point to your new GitHub repository:

```
# Change the remote to your repository
git remote set-url origin https://github.com/yourusername/your-repo-name.git

# Commit your local configuration changes
git add .
git commit -m "Configure for personal deployment"

# Push to your repository
git push -u origin main
```

Your code is now in your GitHub repository and ready for deployment. The `.gitignore` file from the original project already excludes `.env.local`, so your API keys stay safe. Just verify that `.env.local` isn't showing up in your Git status before committing.

### Connecting Vercel to GitHub

Sign in to vercel.com using your GitHub account. This connection lets Vercel access your repositories. Once you're in the dashboard, click "Add New Project."

Vercel shows a list of your GitHub repositories. Find the Open Agent Builder repository you just pushed and click "Import."

![Vercel repository import page](https://www.firecrawl.dev/images/blog/open-agent-builder/vercel-github-project-import.webp)_Import your GitHub repository from the Vercel dashboard_

The platform detects that this is a Next.js project automatically and fills in the build settings for you. The default configuration works for most cases, so leave those settings as-is unless you have specific requirements.

What you do need to configure are the environment variables. Click "Environment Variables" and add each key from your `.env.local` file:

- `NEXT_PUBLIC_CONVEX_URL` (your Convex deployment URL)
- `FIRECRAWL_API_KEY` (from firecrawl.dev)
- `ANTHROPIC_API_KEY` or `OPENAI_API_KEY` or `GROQ_API_KEY` (whichever AI provider you chose)
- `CLERK_SECRET_KEY` (from clerk.com)
- `NEXT_PUBLIC_CLERK_PUBLISHABLE_KEY` (from clerk.com)
- `CLERK_JWT_ISSUER_DOMAIN` (your Clerk Frontend API URL from the dashboard, looks like `https://your-app.clerk.accounts.dev`)
- `E2B_API_KEY` (if you're using E2B for code execution)

![Vercel environment variables configuration](https://www.firecrawl.dev/images/blog/open-agent-builder/vercel-project-deployment-in-progress.webp)_Configure environment variables before deploying. You can also import them from a .env file_

Add these for the "Production" environment at minimum. If you plan to test preview deployments, you can add them to "Preview" and "Development" environments as well.

Once the environment variables are set, click "Deploy." Vercel builds your application and deploys it to their global network. Most projects finish in 1-3 minutes, though larger applications may take longer. You'll see a real-time build log showing the progress.

### Testing Your Deployment

When the build completes, Vercel provides a URL like `your-project.vercel.app`. Click it to open your live Open Agent Builder instance.

![Successful Vercel deployment](https://www.firecrawl.dev/images/blog/open-agent-builder/vercel-project-successfully-deployed.webp)_Deployment complete with live URLs and build details_

Run through a workflow to verify everything works as expected. The app should behave exactly like it did on localhost, but now it's accessible from anywhere. If you configured Clerk authentication correctly, only authorized users will be able to access it.

Vercel automatically rebuilds and redeploys your app every time you push new commits to your main branch on GitHub. You can monitor this activity in the Vercel dashboard, where you'll find deployment history and build logs for troubleshooting.

For a more professional setup, you can connect a custom domain like `workflows.yourcompany.com` through your project settings in Vercel. The platform handles SSL certificates automatically, so your custom domain will be secure without any additional configuration.

With your workflows now live and accessible online, you can take integration one step further by exposing them as programmable API endpoints.

## Using your workflows via API

Once your workflows are deployed and tested, you can access them programmatically through API endpoints. This transforms your visual workflows into reusable services that other applications can call.

Click the Production tab in your workflow editor to see the API configuration panel.

![Production API endpoint access](https://www.firecrawl.dev/images/blog/open-agent-builder/production.webp)_Switch to the Production tab to get your workflow's API endpoint and integration examples_

The panel shows your workflow's endpoint URL, required input format, and example cURL commands for calling the workflow from external applications. This lets you integrate your workflows into other services, trigger them from scripts, or build custom applications on top of them.

Common use cases for API access include:

- **Webhook integrations**: Trigger workflows when events happen in other services
- **Scheduled automation**: Use cron jobs to run workflows at specific times
- **Custom applications**: Build frontend interfaces that call your workflows as backend services
- **Cross-platform integration**: Connect workflows to mobile apps, Slack bots, or internal tools

## Build fast with Open Agent Builder

Open Agent Builder makes AI agent workflows accessible through visual design. You drag nodes onto a canvas instead of writing Python code. It supports multiple AI providers and runs on production-grade technology. Built by the Firecrawl team, Open Agent Builder integrates naturally with Firecrawl's web scraping capabilities and fits into their broader ecosystem of open source AI tools.

The visual approach matters because it reduces the time from idea to working workflow. You see what your agent does before it runs, and you can modify logic without touching code. No vendor lock-in means you control where your workflows run and which AI models they use.

Start today by [cloning the repository](https://github.com/firecrawl/open-agent-builder) and running through the setup guide above.

Firecrawl has built other open source tools that can help you build your own workflows: [Open Researcher](https://www.firecrawl.dev/blog/open-researcher-interleaved-thinking) for AI research workflows and [Fireplexity](https://www.firecrawl.dev/blog/introducing-fireplexity-open-source-answer-engine) for building answer engines. Visit [firecrawl.dev](https://firecrawl.dev/) to learn more about the platform and join the community.

## Frequently Asked Questions

### How is Open Agent Builder different from OpenAI's agent builder?

OpenAI's agent builder locks you to OpenAI models only. Open Agent Builder supports any AI provider (Claude, OpenAI, Groq, or OpenAI-compatible endpoints). It's also open source under MIT license, so you can self-host, modify the code, and deploy wherever you want. No vendor lock-in.

### Do I need coding experience to use Open Agent Builder?

No for most workflows. The visual interface handles the complexity. You connect nodes, write instructions in plain English, and watch your workflow execute. JavaScript knowledge helps when you need custom logic in Transform nodes, but the templates and Agent nodes work without code.

### What AI models does Open Agent Builder support?

Claude from Anthropic (recommended for MCP tool support), OpenAI models like GPT-5, Groq for fast inference, and any OpenAI-compatible API endpoint. You can switch models from the dropdown in each Agent node without rebuilding your workflow.

### Is it really free?

The software is free and open source (MIT license). You pay for the services it uses: Firecrawl API calls, AI provider API usage (Claude, OpenAI, etc.), and infrastructure if you deploy to Vercel beyond the free tier. Convex and Clerk have free tiers that work for most personal projects.

### What are MCP Tools and why do they matter?

MCP (Model Context Protocol) Tools extend what your agents can do beyond basic text generation. They let agents perform actions like file operations, API calls, or specialized computations. Claude models have the best MCP support, which is why Anthropic is the recommended provider for workflows that need these capabilities.

### Can I customize Open Agent Builder for my team?

Yes. It's open source, so you can fork the repository, add custom node types, integrate proprietary tools, modify the UI, or build features specific to your use case. The [Firecrawl documentation](https://docs.firecrawl.dev/) helps if you want to extend the web scraping capabilities.

### What will running Open Agent Builder actually cost me?

The software is free, but you pay for the services it uses. Here's the breakdown:

**Free tier capabilities:**

- **Firecrawl**: 500 credits free (500 page scrapes). Each scrape costs 1 credit.
- **Convex**: 1 million function calls/month, 0.5 GB storage free
- **Clerk**: 10,000 monthly active users free
- **Vercel**: Free forever for personal use (1M requests/month, 100 GB transfer)
- **E2B** (optional): $100 in free usage credits

**AI provider costs** (per million tokens):

- **GPT-5**: $1.25 input / $10 output
- **Claude 3.5 Sonnet**: $3 input / $15 output
- **Groq Llama 3.1**: $0.05 input / $0.08 output (cheapest)

**Realistic monthly cost for light use:** If you stay within free tiers and run 10-20 workflows per day with moderate AI usage, expect $5-15/month in AI costs. Firecrawl will be your main recurring cost after the free 500 credits run out ($16/month for 3,000 credits on the Hobby plan). Heavy users running production workflows daily should budget $50-100/month across all services.

\[ CTA \]

\[ CRAWL \]

\[ SCRAPE \]

\[ CTA \]

//

Get started

//

Ready to build?

Start getting Web Data for free and scale seamlessly as your project expands. No credit card needed.

[Start for free](https://www.firecrawl.dev/signin) [See our plans](https://www.firecrawl.dev/pricing)

![placeholder](https://www.firecrawl.dev/_next/image?url=%2Fblog%2Fauthors%2Fbex.jpg&w=128&q=75&dpl=dpl_2hQ8hmy6vNQsu8DPuBRaRM6deLpr)

Bex Tuychiev [@bextuychiev](https://x.com/bextuychiev)

Technical Writer at Firecrawl

About the Author

Bex Tuychiev is a Technical Writer at Firecrawl and a Kaggle Master with over 15k followers. He loves writing detailed guides, tutorials, and notebooks on complex data science and machine learning topics

More articles by Bex Tuychiev

[22 Python Web Scraping Projects: From Beginner to Advanced](https://www.firecrawl.dev/blog/python-web-scraping-projects) [15 Best MCP Servers You Can Add to Cursor For 10x Productivity](https://www.firecrawl.dev/blog/best-mcp-servers-for-cursor) [Building Multi-Agent Systems With CrewAI - A Comprehensive Tutorial](https://www.firecrawl.dev/blog/crewai-multi-agent-systems-tutorial) [How to Build MCP Servers in Python: Complete FastMCP Tutorial for AI Developers](https://www.firecrawl.dev/blog/fastmcp-tutorial-building-mcp-servers-python) [Data Enrichment: A Complete Guide to Enhancing Your Data Quality](https://www.firecrawl.dev/blog/complete-guide-to-data-enrichment) [Top 10 Browser Automation Tools for Web Testing and Scraping in 2026](https://www.firecrawl.dev/blog/browser-automation-tools-comparison-2025) [How to Create a Claude Code Skill: A Web Scraping Example with Firecrawl](https://www.firecrawl.dev/blog/claude-code-skill) [Best Open-Source Web Crawlers in 2026](https://www.firecrawl.dev/blog/best-open-source-web-crawler) [Scraper vs Crawler: When to Use Each (With Examples)](https://www.firecrawl.dev/blog/scraper-vs-crawler) [15 Best Open-Source RAG Frameworks in 2026](https://www.firecrawl.dev/blog/best-open-source-rag-frameworks)

FOOTER

The easiest way to extract

data from the web

Backed by

Y Combinator

[Linkedin](https://www.linkedin.com/company/firecrawl) [Github](https://github.com/firecrawl/firecrawl) [YouTube](https://www.youtube.com/@Firecrawl_dev)

SOC II ¬∑ Type 2

AICPA

SOC 2

[X (Twitter)](https://x.com/firecrawl) [Discord](https://discord.gg/gSmWdAkdwd)

Products

[Playground](https://www.firecrawl.dev/playground) [Agent](https://www.firecrawl.dev/agent) [Pricing](https://www.firecrawl.dev/pricing) [Templates](https://www.firecrawl.dev/templates) [Changelog](https://www.firecrawl.dev/changelog)

Use Cases

[AI Platforms](https://www.firecrawl.dev/use-cases/ai-platforms) [Lead Enrichment](https://www.firecrawl.dev/use-cases/lead-enrichment) [SEO Teams](https://www.firecrawl.dev/use-cases/seo-teams) [Deep Research](https://www.firecrawl.dev/use-cases/deep-research) [Competitive Intelligence](https://www.firecrawl.dev/use-cases/competitive-intelligence)

Documentation

[Getting started](https://docs.firecrawl.dev/introduction) [API Reference](https://docs.firecrawl.dev/api-reference/introduction) [Integrations](https://www.firecrawl.dev/app) [Examples](https://docs.firecrawl.dev/use-cases/overview) [SDKs](https://docs.firecrawl.dev/sdks/overview)

Company

[Blog](https://www.firecrawl.dev/blog) [Careers](https://www.firecrawl.dev/careers) [Creator & OSS program](https://www.firecrawl.dev/creator-oss-program) [Student program](https://www.firecrawl.dev/student-program)

¬© 2025 Firecrawl

[Terms of Service](https://www.firecrawl.dev/terms-of-service) [Privacy Policy](https://www.firecrawl.dev/privacy-policy) [Report Abuse](mailto:help@firecrawl.com?subject=Issue:)

[All systems normal](https://status.firecrawl.dev/)

## Medical AI Application
Introducing the Firecrawl Skill + CLI for Agents. [Learn more ‚Üí](https://docs.firecrawl.dev/sdks/cli)

//

Get started

//

### Ready to build?

Start getting Web Data for free and scale seamlessly as your project expands. No credit card needed.

[Start for free](https://www.firecrawl.dev/signin) [See our plans](https://www.firecrawl.dev/pricing)

#### Table of Contents

[Blog](https://www.firecrawl.dev/blog)

Building a Medical AI Application with Grok 4

![placeholder](https://www.firecrawl.dev/_next/image?url=%2Fblog%2Fauthors%2Fabid.jpg&w=48&q=75&dpl=dpl_2hQ8hmy6vNQsu8DPuBRaRM6deLpr)Abid Ali Awan

Jul 29, 2025

![Building a Medical AI Application with Grok 4 image](https://www.firecrawl.dev/_next/image?url=%2Fimages%2Fblog%2Fbuilding_medical_ai_application_with_grok_4%2Fbuilding_medical_ai_application_with_grok_abid.webp&w=3840&q=75&dpl=dpl_2hQ8hmy6vNQsu8DPuBRaRM6deLpr)

Grok 4 is one of the most advanced AI models available today, featuring native tool use, advanced agentic reasoning, and reliable API integration. Unlike some AI models that have tool capabilities added as an afterthought, Grok 4 was trained with tools from the start. This means you can build workflows that are more accurate and complex than some simpler AI solutions.

In this tutorial, we'll build a medical prescription analyzer to explore these capabilities. Users can upload a prescription image, and the app will automatically extract medical data, provide dosage information, display prices, and offer direct purchase links. We'll use Grok 4's image analysis to read prescriptions, its function calling to trigger web searches, and Firecrawl's API to scrape medicine information from pharmacy websites.

## Getting Started with xAI SDK

In this section, we will set up an xAI account, purchase some credits, generate an API key, and use the xAI SDK to run text-based and image-based medical prescription examples.

### 1\. Setting up

Go to console.x.ai and sign up for an account. Once logged in, navigate to the ‚ÄúBilling‚Äù tab and add least $5 worth of credits using a debit or credit card.

![xAI console billing](https://www.firecrawl.dev/images/blog/building_medical_ai_application_with_grok_4/building_medical_ai_application_with_grok4_1.webp)

Next, click on the ‚ÄúAPI Keys‚Äù tab and generate your API key.

![xAI API key tab](https://www.firecrawl.dev/images/blog/building_medical_ai_application_with_grok_4/building_medical_ai_application_with_grok4_2.webp)

Save the API key as an environment variable in your local system:

```
export XAI_API_KEY="your_api_key"
```

Install the xAI Python SDK. You'll need Python 3.10 or higher.

```
pip install xai-sdk
```

### 2\. Text‚ÄëBased Prescription Analysis

We will first test the simple Grok 4 workflows to understand how the API works. We will create the xAI client using the API key:

```
import os
from xai_sdk import Client
from xai_sdk.chat import system, user

# Initialize the client with extended timeout
client = Client(
    api_key=os.getenv("XAI_API_KEY"),
    timeout=3600,  # Extended timeout for reasoning-intensive tasks
)
```

Initialize the chat with the system prompt:

```
chat = client.chat.create(
    model="grok-4",
    messages=[\
        system("""\
        You are MedGuide AI, a helpful and intelligent assistant that helps users understand their medical prescriptions.\
        You explain each medicine's price, availability, and prescribed duration in a clear and concise manner.\
        """),\
    ],
)
```

Provide the user prompt and ask about Paracetamol and Azithromycin:

```
# Append a user prompt simulating a text-only prescription input
chat.append(
    user("""
My prescription says:
- Paracetamol 500mg, take twice a day for 5 days.
- Azithromycin 250mg, once a day for 3 days.
Can you explain the duration and check if these medicines are commonly available?
""")
)
```

Now, we will generate the response and display the reasoning content, the final response, the number of completion tokens, and the number of reasoning tokens. It will take a few seconds for it to complete.

```
# Get the response from Grok
response = chat.sample()

# Print detailed response information
print("Reasoning Content:")
print(response.reasoning_content)

print("\nFinal Response:")
print(response.content)

print("\nNumber of completion tokens:")
print(response.usage.completion_tokens)

print("Number of reasoning tokens:")
print(response.usage.reasoning_tokens)
```

> **Please note** that Grok 4 does not currently support reasoning traces (reasoning\_content). If you want to obtain the model‚Äôs step-by-step thinking (reasoning trace), you need to use Grok-3-mini or Grok-3-mini-fast.
> As a result, the reasoning content may return empty even if 289 reasoning tokens were used.

```
Reasoning Content:


Final Response:
Below, I'll explain your prescription based on the details you provided. As MedGuide AI, I'll cover the prescribed duration for each medicine, their common availability (based on general knowledge in most countries like the US, UK, or India‚Äîavailability can vary by location and regulations), and approximate prices (these are estimates and can fluctuate based on brand, location, pharmacy, and whether it's generic or branded; I recommend checking with a local pharmacy for exact details). Remember, I'm not a substitute for professional medical advice‚Äîalways follow your doctor's instructions and consult them if you have questions.

### 1. **Paracetamol 500mg**
   - **Prescribed Duration**: Take one tablet twice a day (e.g., morning and evening) for 5 days. This means a total course of 10 tablets (2 per day √ó 5 days). It's commonly used for pain relief, fever, or mild inflammation.
   - **Availability**: Very commonly available over-the-counter (OTC) in most pharmacies, supermarkets, and online stores (e.g., via Amazon or local apps like CVS or Boots). No prescription is typically needed for this strength, but it's always good to confirm with your pharmacist.
   - **Approximate Price**: Around $0.10‚Äì$0.50 per tablet (generic versions are cheaper). A pack of 10 tablets might cost $1‚Äì$5 (e.g., $2‚Äì$3 in the US for a generic brand like Tylenol equivalent).

### 2. **Azithromycin 250mg**
   - **Prescribed Duration**: Take one tablet once a day for 3 days. This means a total course of 3 tablets. It's an antibiotic often used for bacterial infections like respiratory issues‚Äîcomplete the full course even if you feel better to avoid resistance.
   - **Availability**: Commonly available but usually requires a prescription from a doctor, as it's an antibiotic. You can find it at most pharmacies (e.g., Walgreens, local chemists) or online with a valid prescription. It's widely stocked due to its common use.
   - **Approximate Price**: Around $1‚Äì$5 per tablet (generic is cheaper). A pack for a 3-day course might cost $3‚Äì$15 (e.g., $5‚Äì$10 in the US for a generic like Zithromax equivalent).

If you need help calculating the total quantity to buy or have questions about side effects, interactions, or alternatives, feel free to provide more details. Stay healthy!

Number of completion tokens:
507
Number of reasoning tokens:
289
```

### 3\. Image‚ÄëBased Prescription Analysis

In this section, we will test the image reasoning capabilities by providing the model with an image from the [Handwritten Medical Prescriptions Collection](https://www.kaggle.com/datasets/mehaksingal/illegible-medical-prescription-images-dataset), available in the Kaggle dataset. Save it to your computer for the next step.

![A scanned medical prescription showing handwritten medication details.](https://www.firecrawl.dev/images/blog/building_medical_ai_application_with_grok_4/building_medical_ai_application_with_grok4_3.webp)

We will initiate a chat instance, provide it with the system prompt, encode the image into base64 format, and then give the chat a user prompt that includes the image in base64 format (note the file location). Finally, we will generate the response.

```
import base64
from xai_sdk.chat import image

# Set the path to your prescription image
image_path = "data/image1.jpg"

# Start a new chat with Grok 4
chat = client.chat.create(model="grok-4")

# Define the AI's role and behavior
chat.append(
    system(
        "You are MedGuide AI, a helpful and intelligent assistant that reads medical prescriptions and explains each medicine's price, availability, and prescribed duration. Be concise, clear, and accurate."
    )
)

# Function to encode image in base64
def encode_image(image_path):
    with open(image_path, "rb") as image_file:
        encoded_string = base64.b64encode(image_file.read()).decode("utf-8")
        return encoded_string

# Encode the image
base64_image = encode_image(image_path)

# Upload the image with a user query
chat.append(
    user(
        "Please analyze this prescription and tell me the details, price, availability, and duration for each medicine.",
        image(image_url=f"data:image/jpeg;base64,{base64_image}", detail="high"),
    )
)

# Get the AI response
response = chat.sample()
print(response.content)
```

When you run this code, you'll see Grok 4 extract the prescription data and generate a detailed medical report. It should looking similar the example below.

```
Below is a clear and concise analysis of the prescription dated 13/10/2022 for Ms. Fiza Mozawala (19/F). I've interpreted the handwritten items based on standard medical terminology (e.g., "1-0-1" means 1 dose in the morning, 0 in the afternoon, and 1 in the evening). For each item, I've provided:

- **Details**: What it is, common use, and dosage.
- **Prescribed Duration**: As noted.
- **Price**: Approximate retail price in INR (based on common Indian pharmacy rates as of 2023; prices may vary by location, brand, and discounts‚Äîcheck current rates at pharmacies like Apollo or 1mg).
- **Availability**: General status in India (prescription or over-the-counter; widely available unless noted).

This prescription appears to be for dental/oral health issues (e.g., infection, pain, gum care). Consult your doctor or pharmacist for exact usage, side effects, or alternatives. The last item is a recommended product, not a medicine.

### 1. Cap. Phexin 500mg
- **Details**: Cephalexin (antibiotic) capsule, 500mg strength. Used for bacterial infections (e.g., dental infections). Dosage: 1 capsule morning and evening (total 2 per day).
- **Prescribed Duration**: 5 days (total ~10 capsules needed).
- **Price**: ‚Çπ220-‚Çπ280 for a strip of 10 capsules (generic alternatives ~‚Çπ150-‚Çπ200).
- **Availability**: Prescription required; widely available at pharmacies and online (e.g., 1mg, Netmeds).

### 2. Tab. Zerodol PT
- **Details**: Tablet containing Aceclofenac (pain reliever/anti-inflammatory) + Paracetamol (fever/pain reducer) + possibly other actives (variant of Zerodol-P). Used for pain and inflammation (e.g., dental pain). Dosage: 1 tablet morning and evening (total 2 per day).
- **Prescribed Duration**: 5 days (total ~10 tablets needed).
- **Price**: ‚Çπ100-‚Çπ150 for a strip of 10 tablets (generics ~‚Çπ80-‚Çπ120).
- **Availability**: Prescription required; widely available at pharma‚Ä¶.
```

Let's see how many tokens we used to generate the response.

```
print(response.usage)
```

The majority of tokens were used for the image prompt due to the large size of the image. The rest were fairly normal.

```
completion_tokens: 893
prompt_tokens: 1860
total_tokens: 3351
prompt_text_tokens: 68
prompt_image_tokens: 1792
reasoning_tokens: 598
cached_prompt_text_tokens: 4
```

## Building Medical Prescription Analyzer with Grok 4 and Firecrawl

Now that we have become familiar with the xAI SDK, let's test the tool calling capabilities of Grok 4. In this section, we will build a medical prescription analyzer using the Grok 4 and Firecrawl APIs.

### 1\. Medicine Search with Content Scraping Using Firecrawl

First, you need to create a [Firecrawl](https://www.firecrawl.dev/) account and generate an API key. Save the API key as an environment variable:

```
FIRECRAWL_API_KEY=your_firecrawl_api_key_here
```

After that, install the Firecrawl Python SDK:

```
pip install firecrawl-py
```

Next, initialize both Firecrawl and xAI clients using the API keys:

```
import os
import json
import base64
from rich.console import Console
from rich.markdown import Markdown as RichMarkdown
from concurrent.futures import ThreadPoolExecutor, as_completed
from typing import Dict, List
from xai_sdk import Client
from xai_sdk.chat import system, user, image, tool, tool_result
from firecrawl import FirecrawlApp, ScrapeOptions

# Initialize clients with connection pooling
client = Client(
    api_key=os.getenv("XAI_API_KEY"),
    timeout=3600,
)
fc = FirecrawlApp(api_key=os.getenv("FIRECRAWL_API_KEY"))
```

We will create two functions for medicine search and scraping web pages:

- `get_medicine_info_fast` \- Takes a medicine name and retrieves its price, availability, and scrapes the page for more information.
- `get_multiple_medicines_concurrent` \- Uses multithreading to fetch information for several medicines at once, optimizing speed by running searches concurrently and handling errors or timeouts gracefully.

```
def get_medicine_info_fast(name: str) -> Dict:
    """Optimized medicine info fetcher with error handling"""
    try:
        results = fc.search(
            query=f"{name} medicine price availability",  # Shorter query for faster search
            limit=1,
            scrape_options=ScrapeOptions(formats=["markdown"]),
        )
        snippet = results.data[0] if results.data else {}
        return {
            "name": name,
            "info_markdown": snippet.get("markdown", "N/A"),
            "url": snippet.get("url", "N/A"),
            "description": snippet.get("description", "N/A"),
            "status": "success",
        }
    except Exception as e:
        return {
            "name": name,
            "info_markdown": "Error fetching data",
            "url": "N/A",
            "description": f"Error: {str(e)}",
            "status": "error",
        }


def get_multiple_medicines_concurrent(
    medicine_names: List[str], max_workers: int = 5
) -> List[Dict]:
    """Fetch multiple medicine info concurrently"""
    results = []

    with ThreadPoolExecutor(max_workers=max_workers) as executor:
        # Submit all tasks
        future_to_medicine = {
            executor.submit(get_medicine_info_fast, name): name
            for name in medicine_names
        }

        # Collect results as they complete
        for future in as_completed(future_to_medicine):
            try:
                result = future.result(timeout=30)  # 30 second timeout per request
                results.append(result)
            except Exception as e:
                medicine_name = future_to_medicine[future]
                results.append(
                    {
                        "name": medicine_name,
                        "info_markdown": "Timeout or error",
                        "url": "N/A",
                        "description": f"Error: {str(e)}",
                        "status": "error",
                    }
                )


    return results
```

Let's test the functions by providing them with the name of a medication:

```
print(get_medicine_info_fast("Aspirin"))
```

We receive the name, scraped webpage in markdown format, URL, description, and status in JSON format:

```
{'name': 'Aspirin', 'info_markdown': '[Skip to main content](https://www.goodrx.com/aspirin#skip-to-content)nnAre you a healthcare professional? [Join GoodRx for HCPs](https://www.goodrx.com/hcp/join?redire‚Ä¶‚Ä¶‚Ä¶, and other pharmacies. Prices start at $2.80.', 'status': 'success'}
```

Now, let's try to fetch information for multiple medicines:

```
print(get_multiple_medicines_concurrent(["Aspirin", "Ibuprofen"]))
```

We get quick results for both medications in JSON format, along with additional metadata:

```
[{'name': 'Aspirin', 'info_markdown': '[Skip to main content](https://www.goodrx.com/aspirin#skip-to-content)nnAre you a healthcare professional? [Join GoodRx for H‚Ä¶‚Ä¶‚Ä¶mon version, by using a GoodRx coupon.', 'status': 'success'}]\
```\
\
### 2\. Defining Tools for Function Calling\
\
To enable function calling with xAI models, we will define our Python functions as tools that the model can invoke dynamically, similar to how the OpenAI SDK handles function calling.\
\
Each tool is described in a dictionary format, specifying its **name, description, parameters, and required** arguments.\
\
In this project, we have defined two tools: one for fetching information about a single medicine (`get_medicine_info_fast`), and another for retrieving data on multiple medicines concurrently (`get_multiple_medicines_concurrent`).\
\
The following tool definitions tell Grok 4 what functions are available to call. For each function, the AI knows the name, what it does, and what information it needs to run. Based on the prescription image content, Grok 4 automatically selects and runs the most appropriate function.\
\
```\
# Tool definitions\
tool_definitions = [\
    tool(\
        name="get_medicine_info_fast",\
        description="Fetch markdown info, URL, and description for a medicine via Firecrawl (optimized)",\
        parameters={\
            "type": "object",\
            "properties": {\
                "name": {"type": "string", "description": "Name of the medicine"},\
            },\
            "required": ["name"],\
        },\
    ),\
    tool(\
        name="get_multiple_medicines_concurrent",\
        description="Fetch info for multiple medicines concurrently",\
        parameters={\
            "type": "object",\
            "properties": {\
                "medicine_names": {\
                    "type": "array",\
                    "items": {"type": "string"},\
                    "description": "List of medicine names",\
                },\
                "max_workers": {\
                    "type": "integer",\
                    "description": "Maximum concurrent workers (default: 5)",\
                    "default": 5,\
                },\
            },\
            "required": ["medicine_names"],\
        },\
    ),\
]\
\
# Map tools to functions\
tools_map = {\
    "get_medicine_info_fast": get_medicine_info_fast,\
    "get_multiple_medicines_concurrent": get_multiple_medicines_concurrent,\
}\
```\
\
### 3\. Creating Prescription Analysis with Tools\
\
The prescription analysis workflow uses function calling tools to automate the extraction and reporting of medicine information from a prescription image.\
\
It starts by encoding the prescription image into a `base64` string using a utility function so that AI can use it.\
\
The main `analyze_prescription_fast` function initiates a chat session with the Grok 4 AI model, providing it with the tool definitions. The AI analyzes the image, identifies medicine names, and calls the relevant tools to fetch detailed information such as descriptions, prices, and purchase links.\
\
Finally, the results are compiled into a markdown report, with clear sections for each medicine, enabling efficient and scalable prescription analysis within an AI assistant.\
\
```\
def encode_image(path: str) -> str:\
    """Utility to encode image to base64"""\
    try:\
        with open(path, "rb") as f:\
            return base64.b64encode(f.read()).decode("utf-8")\
    except FileNotFoundError:\
        raise FileNotFoundError(f"Image file not found: {path}")\
    except Exception as e:\
        raise Exception(f"Error encoding image: {str(e)}")\
\
def analyze_prescription_fast(image_path: str) -> str:\
    """Main function to analyze prescription with optimizations"""\
    try:\
        # Encode the prescription image\
        encoded_img = encode_image(image_path)\
\
        # Create chat session\
        chat = client.chat.create(\
            model="grok-4",\
            tools=tool_definitions,\
            tool_choice="auto",\
        )\
\
        # Enhanced system prompt for better extraction\
        chat.append(\
            system(\
                "You are MedGuide AI. Extract ALL medicine names from the prescription image. "\
                "If you find multiple medicines, use get_multiple_medicines_concurrent to fetch "\
                "all information at once for faster processing. For single medicine, use get_medicine_info_fast. "\
                "Create a comprehensive markdown report."\
            )\
        )\
\
        # User provides the prescription image\
        chat.append(\
            user(\
                "Extract all medicine names from this prescription and get their details efficiently.",\
                image(image_url=f"data:image/jpeg;base64,{encoded_img}", detail="high"),\
            )\
        )\
\
        # Initial model call\
        response = chat.sample()\
        chat.append(response)\
\
        # Execute tool calls if any\
        if response.tool_calls:\
            for tc in response.tool_calls:\
                func_name = tc.function.name\
                func_args = json.loads(tc.function.arguments)\
\
                print(f"Executing {func_name} with args: {func_args}")\
\
                result = tools_map[func_name](**func_args)\
                chat.append(tool_result(json.dumps(result)))\
\
            # Request final formatted report\
            chat.append(\
                user(\
                    "Create a comprehensive markdown report with H2 heading for each medicine that contains: Description, "\
                    "Typical Duration, Price Information, and Purchase Link"\
                )\
            )\
\
            # Generate final report\
            final = chat.sample()\
            return final.content\
        else:\
            return response.content\
\
    except Exception as e:\
        return f"Error analyzing prescription: {str(e)}"\
```\
\
### 4\. Running Prescription Analysis Workflow\
\
We'll now test our prescription analysis workflow by giving it with an image path and then displaying the result in markdown format. It may take up to a minute to generate the report.\
\
```\
image_path = "data/image1.jpg"\
result = analyze_prescription_fast(image_path)\
console = Console()\
console.print(RichMarkdown(result))\
```\
\
In this example, we can see that Grok 4 has accurately identified the medications, ran the functions, and correcly formatted the report in markdown.\
\
```\
Executing get_multiple_medicines_concurrent with args: {'medicine_names': ['Phexin', 'Zerodol PT', 'Stolin gum paint', 'Colgate Plax']}\
```\
\
![Medicine Report of prescribed medicine](https://www.firecrawl.dev/images/blog/building_medical_ai_application_with_grok_4/building_medical_ai_application_with_grok4_4.webp)\
\
You can also build this app using the Agentic frameworks. Check out [The Best Open Source Frameworks For Building AI Agents in 2025](https://www.firecrawl.dev/blog/best-open-source-agent-frameworks-2025) to learn more.\
\
## Creating User Interface for the Medical Prescription Analyzer\
\
Now that we have developed our backend, we can create a frontend so that anyone can run the app, upload an image, and generate a medical prescription report with all the key information.\
\
The source code for the UI is quite extensive, so we have hosted it on GitHub for you to copy and paste into the `app.py` file. You can find it here: [Medical-AI-with-Grok4/app.py at main()](https://github.com/kingabzpro/Medical-AI-with-Grok4/blob/main/app.py).\
\
The `app.py` file contains the code that creates a user interface for our application. Here is a brief explanation of how it works:\
\
- **Web Interface:** The app first builds a web interface using Gradio where a user can upload a prescription image and view a detailed report. The interface includes collapsible sections for logs and a medical disclaimer .\
- **AI Image Analysis:** When an image is uploaded, the script sends it to the Grok 4 AI model. The AI's first job is to act like a smart OCR, reading the image to identify and extract the names of all the medicines listed .\
- **Concurrent Web Search:** The AI then uses function calling to trigger a web search for each medicine using the Firecrawl API. To speed things up, it fetches information for multiple medicines at the same time (concurrently) using a `ThreadPoolExecutor` .\
- **Live Report Generation:** The search results are sent back to Grok 4, which then generates a final, detailed report. The script uses streaming (`chat.stream()` and `yield`) to display the AI's thought process and the final report in real-time.\
\
Before we run the `app.py` code, you'll need to install the Gradio and Pillow packages:\
\
```\
pip install gradio\
pip install pillow\
```\
\
Now you can try running the app:\
\
```\
python app.py\
```\
\
```\
* Running on local URL:  http://127.0.0.1:7860\
* To create a public link, set `share=True` in `launch()`.\
```\
\
Visit the URL: `http://127.0.0.1:7860` to access the MedGuide AI application.\
\
![MedGuide AI application running locally](https://www.firecrawl.dev/images/blog/building_medical_ai_application_with_grok_4/building_medical_ai_application_with_grok4_5.webp)\
\
Upload the image of the medical prescription from your local directory and press the ‚Äú **Analyze Prescription**‚Äù button. The analysis will begin within a few seconds.\
\
![Uploading the medical prescription and generating the report.](https://www.firecrawl.dev/images/blog/building_medical_ai_application_with_grok_4/building_medical_ai_application_with_grok4_6.webp)\
\
You can see what is happening in the background by clicking on the ‚Äú **Processing Logs**‚Äù tab. The screenshot below shows an exmample where the concurrent function is invoked, triggering multiple Firecrawl API requests.\
\
![Tool call and results under the progress logs.](https://www.firecrawl.dev/images/blog/building_medical_ai_application_with_grok_4/building_medical_ai_application_with_grok4_7.webp)\
\
At the end, you'll receive a properly formatted medical report detailing the medications, their descriptions, duration, price, and purchase link.\
\
![Final report is generated.](https://www.firecrawl.dev/images/blog/building_medical_ai_application_with_grok_4/building_medical_ai_application_with_grok4_8.webp)\
\
> **Please note** that the app is not perfect. It is intended for educational purposes and may make mistakes. Please consult a doctor about medical questions and any medication you've been prescribed.\
\
The purpose of this guide is to show how easy it has become to use vision [reasoning models](https://www.firecrawl.dev/blog/how-to-use-openai-o1-reasoning-models-in-applications) to invoke functions and generate highly accurate reports.\
\
If you are facing issues running the app, please check out the GitHub repository: [kingabzpro/Medical-AI-with-Grok4](https://github.com/kingabzpro/Medical-AI-with-Grok4/tree/main).\
\
## Final Thoughts\
\
In this tutorial, we created an app that helps patients quickly identify all medications from a prescription by simply uploading an image and receiving a detailed report for each medicine. The goal was to show how we can combine these AI tools to pull information from complex images like handwritten prescriptions and automatically gather related data from the web. This same approach works well for any task where you'd normally have to manually enter data and do research.\
\
Throughout this tutorial, we explored how the xAI SDK and Firecrawl API can be combined to create powerful web applications. I especially love the Firecrawl search with content [scraping API](https://docs.firecrawl.dev/features/scrape), scrapes and structures the page content to provide richer information than just a simple search does. You can find more information by reading the documentation: [Search \| Firecrawl](https://docs.firecrawl.dev/features/search)\
\
\[ CTA \]\
\
\[ CRAWL \]\
\
\[ SCRAPE \]\
\
\[ CTA \]\
\
//\
\
Get started\
\
//\
\
Ready to build?\
\
Start getting Web Data for free and scale seamlessly as your project expands. No credit card needed.\
\
[Start for free](https://www.firecrawl.dev/signin) [See our plans](https://www.firecrawl.dev/pricing)\
\
![placeholder](https://www.firecrawl.dev/_next/image?url=%2Fblog%2Fauthors%2Fabid.jpg&w=128&q=75&dpl=dpl_2hQ8hmy6vNQsu8DPuBRaRM6deLpr)\
\
Abid Ali Awan [@1abidaliawan](https://x.com/1abidaliawan)\
\
Technical Writer at Firecrawl\
\
About the Author\
\
Abid Ali Awan is a Technical Writer at Firecrawl and a certified data scientist who enjoys building machine learning applications and writing blogs on data science. He is currently focusing on content creation, editing, and working with large language models.\
\
More articles by Abid Ali Awan\
\
[Building E-Commerce Intelligence Application with GLM Coding Plan](https://www.firecrawl.dev/blog/building-ecommerce-intelligence-app-with-glm-4-6) [Building AI Agents with OpenAI Agent Builders & Firecrawl](https://www.firecrawl.dev/blog/openai-agent-builders-and-firecrawl) [Top 15 Python Projects to Build in 2025: From Beginner to Production](https://www.firecrawl.dev/blog/15-python-projects-2025) [10 Essential Python Libraries Every Data Analyst Should Know](https://www.firecrawl.dev/blog/python-libraries-for-data-analysts) [10 AI Projects You Can Build with Firecrawl Now](https://www.firecrawl.dev/blog/10-ai-projects-with-firecrawl) [11 AI Agent Projects You Can Build Today (With Guides)](https://www.firecrawl.dev/blog/11-ai-agent-projects) [Fine-Tune OpenAI GPT-OSS 20B on the Dermatology Dataset](https://www.firecrawl.dev/blog/fine_tune_openai_gpt_oss) [How to Create a Dermatology Q&A Dataset with OpenAI Harmony & Firecrawl Search](https://www.firecrawl.dev/blog/creating_dermatology_dataset_with_openai_harmony_firecrawl_search) [5 Easy Ways to Access GLM-4.5](https://www.firecrawl.dev/blog/5_easy_ways_to_access_glm_4_5) [Building AI Applications with Kimi K2: A Complete Travel Deal Finder Tutorial](https://www.firecrawl.dev/blog/building-ai-applications-kimi-k2-travel-deal-finder)\
\
FOOTER\
\
The easiest way to extract\
\
data from the web\
\
Backed by\
\
Y Combinator\
\
[Linkedin](https://www.linkedin.com/company/firecrawl) [Github](https://github.com/firecrawl/firecrawl) [YouTube](https://www.youtube.com/@Firecrawl_dev)\
\
SOC II ¬∑ Type 2\
\
AICPA\
\
SOC 2\
\
[X (Twitter)](https://x.com/firecrawl) [Discord](https://discord.gg/gSmWdAkdwd)\
\
Products\
\
[Playground](https://www.firecrawl.dev/playground) [Agent](https://www.firecrawl.dev/agent) [Pricing](https://www.firecrawl.dev/pricing) [Templates](https://www.firecrawl.dev/templates) [Changelog](https://www.firecrawl.dev/changelog)\
\
Use Cases\
\
[AI Platforms](https://www.firecrawl.dev/use-cases/ai-platforms) [Lead Enrichment](https://www.firecrawl.dev/use-cases/lead-enrichment) [SEO Teams](https://www.firecrawl.dev/use-cases/seo-teams) [Deep Research](https://www.firecrawl.dev/use-cases/deep-research) [Competitive Intelligence](https://www.firecrawl.dev/use-cases/competitive-intelligence)\
\
Documentation\
\
[Getting started](https://docs.firecrawl.dev/introduction) [API Reference](https://docs.firecrawl.dev/api-reference/introduction) [Integrations](https://www.firecrawl.dev/app) [Examples](https://docs.firecrawl.dev/use-cases/overview) [SDKs](https://docs.firecrawl.dev/sdks/overview)\
\
Company\
\
[Blog](https://www.firecrawl.dev/blog) [Careers](https://www.firecrawl.dev/careers) [Creator & OSS program](https://www.firecrawl.dev/creator-oss-program) [Student program](https://www.firecrawl.dev/student-program)\
\
¬© 2025 Firecrawl\
\
[Terms of Service](https://www.firecrawl.dev/terms-of-service) [Privacy Policy](https://www.firecrawl.dev/privacy-policy) [Report Abuse](mailto:help@firecrawl.com?subject=Issue:)\
\
[All systems normal](https://status.firecrawl.dev/)

## AI Engineering Resources
Introducing Spark 1 Pro and Spark 1 Mini models in /agent. [Try it now ‚Üí](https://www.firecrawl.dev/agent)

Blog

All Posts

Updates

Customers

Example Apps

Web Extraction

AI Engineering

Low Code

[5 Best Deep Research APIs for Agentic Workflows in 2026\\
\\
Compare the top deep research APIs for building AI agents and agentic workflows. From autonomous web research to structured extraction, find the right tool for your RAG systems, research agents, and data pipelines.\\
\\
![Hiba Fathima](https://www.firecrawl.dev/_next/image?url=%2Fimages%2Fauthors%2Fhiba.webp&w=48&q=75&dpl=dpl_2hQ8hmy6vNQsu8DPuBRaRM6deLpr)\\
\\
Hiba Fathima\\
\\
Feb 02, 2026](https://www.firecrawl.dev/blog/best-deep-research-apis) [Agent Tools: Building Effective Capabilities for AI Systems\\
\\
Discover the 9 core categories of AI agent tools, from web search to code execution. Learn how to design reliable tools and orchestrate them for complex workflows.\\
\\
![Ninad Pathak](https://www.firecrawl.dev/_next/image?url=%2Fimages%2Fauthors%2Fninad.webp&w=48&q=75&dpl=dpl_2hQ8hmy6vNQsu8DPuBRaRM6deLpr)\\
\\
Ninad Pathak\\
\\
Jan 30, 2026](https://www.firecrawl.dev/blog/agent-tools) [Building AI-Powered Apps with Firecrawl and Lovable: Access Live Web Data\\
\\
Step-by-step walkthrough of building a brand analyzer and trend tracker with Firecrawl + Lovable, including prompt structure, endpoints, and async handling.\\
\\
![Leonardo Grigorio](https://www.firecrawl.dev/_next/image?url=%2Fimages%2Fauthors%2Fleo.webp&w=48&q=75&dpl=dpl_2hQ8hmy6vNQsu8DPuBRaRM6deLpr)\\
\\
Leonardo Grigorio\\
\\
Jan 27, 2026](https://www.firecrawl.dev/blog/firecrawl-lovable-tutorial)

[15 Best MCP Servers You Can Add to Cursor For 10x Productivity\\
\\
Discover the top 15 Model Context Protocol (MCP) servers that can supercharge your development workflow in Cursor and other AI-powered IDEs.\\
\\
![Bex Tuychiev](https://www.firecrawl.dev/_next/image?url=%2Fblog%2Fauthors%2Fbex.jpg&w=48&q=75&dpl=dpl_2hQ8hmy6vNQsu8DPuBRaRM6deLpr)\\
\\
Bex Tuychiev\\
\\
Jan 27, 2026](https://www.firecrawl.dev/blog/best-mcp-servers-for-cursor) [Building Multi-Agent Systems With CrewAI - A Comprehensive Tutorial\\
\\
Learn how to create powerful multi-agent systems using CrewAI's role-based architecture to build a functional ChatGPT clone with specialized AI workers.\\
\\
![Bex Tuychiev](https://www.firecrawl.dev/_next/image?url=%2Fblog%2Fauthors%2Fbex.jpg&w=48&q=75&dpl=dpl_2hQ8hmy6vNQsu8DPuBRaRM6deLpr)\\
\\
Bex Tuychiev\\
\\
Jan 26, 2026](https://www.firecrawl.dev/blog/crewai-multi-agent-systems-tutorial) [Context Layer for AI Agents: Can You Automate Context Feeding into Your Agents?\\
\\
Prevent context drift by building a dedicated Context Layer for AI agents. Learn why vector databases fall short and how to automate real-time decision context ingestion using Firecrawl.\\
\\
![Ninad Pathak](https://www.firecrawl.dev/_next/image?url=%2Fimages%2Fauthors%2Fninad.webp&w=48&q=75&dpl=dpl_2hQ8hmy6vNQsu8DPuBRaRM6deLpr)\\
\\
Ninad Pathak\\
\\
Jan 21, 2026](https://www.firecrawl.dev/blog/context-layer-for-ai-agents)

[How to Build MCP Servers in Python: Complete FastMCP Tutorial for AI Developers\\
\\
Learn to build custom MCP servers in Python using FastMCP. Step-by-step tutorial covering tools, resources, prompts, debugging, and deployment for AI applications.\\
\\
![Bex Tuychiev](https://www.firecrawl.dev/_next/image?url=%2Fblog%2Fauthors%2Fbex.jpg&w=48&q=75&dpl=dpl_2hQ8hmy6vNQsu8DPuBRaRM6deLpr)\\
\\
Bex Tuychiev\\
\\
Jan 21, 2026](https://www.firecrawl.dev/blog/fastmcp-tutorial-building-mcp-servers-python) [Building a Claude Skills Generator with Firecrawl's Agent Endpoint\\
\\
Learn how we built an internal Claude Skills generator using Firecrawl's /agent endpoint. Discover why automating skill creation is a game-changer and how you can build complex AI workflows with just one API call instead of building everything from scratch.\\
\\
![Leonardo Grigorio](https://www.firecrawl.dev/_next/image?url=%2Fimages%2Fauthors%2Fleo.webp&w=48&q=75&dpl=dpl_2hQ8hmy6vNQsu8DPuBRaRM6deLpr)\\
\\
Leonardo Grigorio\\
\\
Jan 20, 2026](https://www.firecrawl.dev/blog/claude-skills-generator) [Top 10 Claude Code Plugins to Try in 2026\\
\\
Discover the best Claude Code plugins that can transform your development workflow. From autonomous coding with Ralph Loop to browser automation with Playwright, learn which plugins boost productivity and help you ship faster.\\
\\
![Musthaq Ahamad](https://www.firecrawl.dev/_next/image?url=%2Fimages%2Fauthors%2Fmusthaq.webp&w=48&q=75&dpl=dpl_2hQ8hmy6vNQsu8DPuBRaRM6deLpr)\\
\\
Musthaq Ahamad\\
\\
Jan 19, 2026](https://www.firecrawl.dev/blog/best-claude-code-plugins)

[How to Create an llms.txt File for Any Website\\
\\
Learn how to generate an llms.txt file for any website using the llms.txt Generator and Firecrawl.\\
\\
![Eric Ciarla](https://www.firecrawl.dev/_next/image?url=%2Fblog%2Fauthors%2Feric-img.jpeg&w=48&q=75&dpl=dpl_2hQ8hmy6vNQsu8DPuBRaRM6deLpr)\\
\\
Eric Ciarla\\
\\
Jan 15, 2026](https://www.firecrawl.dev/blog/How-to-Create-an-llms-txt-File-for-Any-Website) [Firecrawl MCP in ChatGPT: Web Scraping and Search Inside Your Conversations\\
\\
Learn how to set up and use the Firecrawl Model Context Protocol (MCP) server in ChatGPT to perform web scraping, crawling, and search directly within your conversations.\\
\\
![Ninad Pathak](https://www.firecrawl.dev/_next/image?url=%2Fimages%2Fauthors%2Fninad.webp&w=48&q=75&dpl=dpl_2hQ8hmy6vNQsu8DPuBRaRM6deLpr)\\
\\
Ninad Pathak\\
\\
Jan 13, 2026](https://www.firecrawl.dev/blog/firecrawl-mcp-chatgpt) [Best Semantic Search APIs for Building AI Applications in 2026\\
\\
A comprehensive guide to the best semantic search APIs in 2026, comparing Firecrawl, Exa, OpenAI, Cohere, and Pinecone for RAG and AI agents.\\
\\
![Ninad Pathak](https://www.firecrawl.dev/_next/image?url=%2Fimages%2Fauthors%2Fninad.webp&w=48&q=75&dpl=dpl_2hQ8hmy6vNQsu8DPuBRaRM6deLpr)\\
\\
Ninad Pathak\\
\\
Jan 11, 2026](https://www.firecrawl.dev/blog/best-semantic-search-apis)

[How to Create a Claude Code Skill: A Web Scraping Example with Firecrawl\\
\\
Learn how to build a Claude Code skill that adds web scraping capabilities using Firecrawl. This tutorial covers skill structure, YAML frontmatter, triggering behavior, and building a multi-feature skill for markdown extraction, screenshots, structured data, web search, and documentation crawling.\\
\\
![Bex Tuychiev](https://www.firecrawl.dev/_next/image?url=%2Fblog%2Fauthors%2Fbex.jpg&w=48&q=75&dpl=dpl_2hQ8hmy6vNQsu8DPuBRaRM6deLpr)\\
\\
Bex Tuychiev\\
\\
Jan 09, 2026](https://www.firecrawl.dev/blog/claude-code-skill) [15 Best Open-Source RAG Frameworks in 2026\\
\\
Discover the top open-source retrieval-augmented generation frameworks that enhance LLM capabilities with external knowledge retrieval for more accurate and contextual AI responses.\\
\\
![Bex Tuychiev](https://www.firecrawl.dev/_next/image?url=%2Fblog%2Fauthors%2Fbex.jpg&w=48&q=75&dpl=dpl_2hQ8hmy6vNQsu8DPuBRaRM6deLpr)\\
\\
Bex Tuychiev\\
\\
Jan 02, 2026](https://www.firecrawl.dev/blog/best-open-source-rag-frameworks) [AI Data Preparation 101: A Complete Guide for AI Practitioners\\
\\
Learn how to prepare data for AI applications with this step-by-step guide. Covers collection, cleaning, transformation, validation, and optimization for RAG systems, fine-tuning, and inference pipelines.\\
\\
![Bex Tuychiev](https://www.firecrawl.dev/_next/image?url=%2Fblog%2Fauthors%2Fbex.jpg&w=48&q=75&dpl=dpl_2hQ8hmy6vNQsu8DPuBRaRM6deLpr)\\
\\
Bex Tuychiev\\
\\
Dec 08, 2025](https://www.firecrawl.dev/blog/ai-data-preparation)

[Best LLM Observability Tools in 2025\\
\\
Compare 14 LLM observability tools across four categories. Find the best option for tracing, evaluation, cost tracking, and monitoring your AI applications.\\
\\
![Bex Tuychiev](https://www.firecrawl.dev/_next/image?url=%2Fblog%2Fauthors%2Fbex.jpg&w=48&q=75&dpl=dpl_2hQ8hmy6vNQsu8DPuBRaRM6deLpr)\\
\\
Bex Tuychiev\\
\\
Dec 02, 2025](https://www.firecrawl.dev/blog/best-llm-observability-tools) [Comprehensive Guide to Building AI Agents Using Google Agent Development Kit (ADK)\\
\\
Learn how to build powerful multi-agent systems with Google's ADK framework that can search the web, generate images, and perform complex tasks through a simple conversational interface.\\
\\
![Bex Tuychiev](https://www.firecrawl.dev/_next/image?url=%2Fblog%2Fauthors%2Fbex.jpg&w=48&q=75&dpl=dpl_2hQ8hmy6vNQsu8DPuBRaRM6deLpr)\\
\\
Bex Tuychiev\\
\\
Dec 02, 2025](https://www.firecrawl.dev/blog/google-adk-multi-agent-tutorial) [Best Hands-On Resources to Learn AI Engineering in 2025\\
\\
Discover 12 hands-on AI resources organized by skill level for building chatbots, RAG systems, and AI agents. Learn AI Engineering with free tutorials from OpenAI, Anthropic, LangChain, and more, organized from beginner to advanced.\\
\\
![Bex Tuychiev](https://www.firecrawl.dev/_next/image?url=%2Fblog%2Fauthors%2Fbex.jpg&w=48&q=75&dpl=dpl_2hQ8hmy6vNQsu8DPuBRaRM6deLpr)\\
\\
Bex Tuychiev\\
\\
Nov 21, 2025](https://www.firecrawl.dev/blog/best-ai-resources)

[Building E-Commerce Intelligence Application with GLM Coding Plan\\
\\
Build smarter, code faster. Integrate Claude Code with the $3 GLM-4.6 plan to quickly vibe-code a customer review analytics app. This app will scrape, analyze, and visualize insights in just minutes.\\
\\
![Abid Ali Awan](https://www.firecrawl.dev/_next/image?url=%2Fblog%2Fauthors%2Fabid.jpg&w=48&q=75&dpl=dpl_2hQ8hmy6vNQsu8DPuBRaRM6deLpr)\\
\\
Abid Ali Awan\\
\\
Oct 26, 2025](https://www.firecrawl.dev/blog/building-ecommerce-intelligence-app-with-glm-4-6) [Turn Any Documentation Site Into an AI Agent with LangGraph and Firecrawl\\
\\
Build a complete documentation agent from scratch using LangGraph's ReAct pattern and Firecrawl's web scraping. Learn agentic RAG, token streaming, conversation memory, and deploy a production-ready Streamlit app that turns any docs into an intelligent chatbot.\\
\\
![Bex Tuychiev](https://www.firecrawl.dev/_next/image?url=%2Fblog%2Fauthors%2Fbex.jpg&w=48&q=75&dpl=dpl_2hQ8hmy6vNQsu8DPuBRaRM6deLpr)\\
\\
Bex Tuychiev\\
\\
Oct 17, 2025](https://www.firecrawl.dev/blog/build-documentation-agent-langgraph-firecrawl) [Top 15 Python Projects to Build in 2025: From Beginner to Production\\
\\
Explore a range of Python projects tailored for beginners to advanced developers, empowering you to progressively improve your Python skills, AI automation skills, and build and deploy real-world applications.\\
\\
![Abid Ali Awan](https://www.firecrawl.dev/_next/image?url=%2Fblog%2Fauthors%2Fabid.jpg&w=48&q=75&dpl=dpl_2hQ8hmy6vNQsu8DPuBRaRM6deLpr)\\
\\
Abid Ali Awan\\
\\
Oct 16, 2025](https://www.firecrawl.dev/blog/15-python-projects-2025)

[Best Chunking Strategies for RAG in 2025\\
\\
Compare six chunking strategies for RAG systems using real benchmark data from NVIDIA and Chroma. Learn when to use recursive splitting, semantic chunking, page-level chunking, and LLM-based approaches with practical code examples and honest trade-offs.\\
\\
![Bex Tuychiev](https://www.firecrawl.dev/_next/image?url=%2Fblog%2Fauthors%2Fbex.jpg&w=48&q=75&dpl=dpl_2hQ8hmy6vNQsu8DPuBRaRM6deLpr)\\
\\
Bex Tuychiev\\
\\
Oct 10, 2025](https://www.firecrawl.dev/blog/best-chunking-strategies-rag-2025) [Best Vector Databases in 2025: A Complete Comparison Guide\\
\\
Compare 14 major vector databases with real performance benchmarks, honest trade-offs, and decision frameworks. Learn which database fits your RAG application based on scale, infrastructure, and use case‚Äîfrom Pinecone and Milvus to pgvector and Weaviate.\\
\\
![Bex Tuychiev](https://www.firecrawl.dev/_next/image?url=%2Fblog%2Fauthors%2Fbex.jpg&w=48&q=75&dpl=dpl_2hQ8hmy6vNQsu8DPuBRaRM6deLpr)\\
\\
Bex Tuychiev\\
\\
Oct 09, 2025](https://www.firecrawl.dev/blog/best-vector-databases-2025) [10 AI Projects You Can Build with Firecrawl Now\\
\\
Build 10 AI projects with Firecrawl's web scraping API: RAG systems, AI agents, price trackers, and more. Includes step-by-step tutorials, GitHub repos, and deployment guides for beginner to advanced developers.\\
\\
![Abid Ali Awan](https://www.firecrawl.dev/_next/image?url=%2Fblog%2Fauthors%2Fabid.jpg&w=48&q=75&dpl=dpl_2hQ8hmy6vNQsu8DPuBRaRM6deLpr)\\
\\
Abid Ali Awan\\
\\
Oct 02, 2025](https://www.firecrawl.dev/blog/10-ai-projects-with-firecrawl)

[Mastering Firecrawl Search Endpoint: Web Search and Data Extraction in One API Call\\
\\
Learn how to use Firecrawl's search endpoint to combine web search and content extraction in a single API call. This guide covers basic and advanced usage, filtering, and building search-powered applications.\\
\\
![Bex Tuychiev](https://www.firecrawl.dev/_next/image?url=%2Fblog%2Fauthors%2Fbex.jpg&w=48&q=75&dpl=dpl_2hQ8hmy6vNQsu8DPuBRaRM6deLpr)\\
\\
Bex Tuychiev\\
\\
Sep 19, 2025](https://www.firecrawl.dev/blog/mastering-firecrawl-search-endpoint) [11 AI Agent Projects You Can Build Today (With Guides)\\
\\
Build AI agents that reason, plan, act, and use tools to deliver results, from no/low-code platforms to advanced multi agent framework.\\
\\
![Abid Ali Awan](https://www.firecrawl.dev/_next/image?url=%2Fblog%2Fauthors%2Fabid.jpg&w=48&q=75&dpl=dpl_2hQ8hmy6vNQsu8DPuBRaRM6deLpr)\\
\\
Abid Ali Awan\\
\\
Sep 18, 2025](https://www.firecrawl.dev/blog/11-ai-agent-projects) [The Complete Guide to Web Search APIs for AI Applications in 2025\\
\\
Discover the best web search APIs for 2025. Compare features, pricing, and capabilities to find the web search API for your application.\\
\\
![Dania Durnas](https://www.firecrawl.dev/_next/image?url=%2Fimages%2Fauthors%2Fdania.jpg&w=48&q=75&dpl=dpl_2hQ8hmy6vNQsu8DPuBRaRM6deLpr)\\
\\
Dania Durnas\\
\\
Sep 12, 2025](https://www.firecrawl.dev/blog/top_web_search_api_2025)

[Mastering Firecrawl's Crawl Endpoint: A Complete Web Scraping Guide\\
\\
Learn how to use Firecrawl's crawl method for efficient web scraping. Master URL control, performance tuning, and integration with LangChain for AI-powered data extraction.\\
\\
![Bex Tuychiev](https://www.firecrawl.dev/_next/image?url=%2Fblog%2Fauthors%2Fbex.jpg&w=48&q=75&dpl=dpl_2hQ8hmy6vNQsu8DPuBRaRM6deLpr)\\
\\
Bex Tuychiev\\
\\
Sep 08, 2025](https://www.firecrawl.dev/blog/mastering-the-crawl-endpoint-in-firecrawl) [Fine-Tune OpenAI GPT-OSS 20B on the Dermatology Dataset\\
\\
Learn how to fine-tune OpenAI's GPT-OSS 20B on a dermatology Q&A dataset created with the Firecrawl web search API, with a step-by-step workflow from setup to training, evaluation, and inference.\\
\\
![Abid Ali Awan](https://www.firecrawl.dev/_next/image?url=%2Fblog%2Fauthors%2Fabid.jpg&w=48&q=75&dpl=dpl_2hQ8hmy6vNQsu8DPuBRaRM6deLpr)\\
\\
Abid Ali Awan\\
\\
Sep 05, 2025](https://www.firecrawl.dev/blog/fine_tune_openai_gpt_oss) [5 Easy Ways to Access GLM-4.5\\
\\
Discover how to access GLM-4.5 models locally, through chat applications, via the official API, and using the LLM marketplaces API for seamless integration into your workflows.\\
\\
![Abid Ali Awan](https://www.firecrawl.dev/_next/image?url=%2Fblog%2Fauthors%2Fabid.jpg&w=48&q=75&dpl=dpl_2hQ8hmy6vNQsu8DPuBRaRM6deLpr)\\
\\
Abid Ali Awan\\
\\
Aug 08, 2025](https://www.firecrawl.dev/blog/5_easy_ways_to_access_glm_4_5)

[Building a Medical AI Application with Grok 4\\
\\
Combining the power of real-time search, web scraping, and advanced AI to build a medical prescription analyzer.\\
\\
![Abid Ali Awan](https://www.firecrawl.dev/_next/image?url=%2Fblog%2Fauthors%2Fabid.jpg&w=48&q=75&dpl=dpl_2hQ8hmy6vNQsu8DPuBRaRM6deLpr)\\
\\
Abid Ali Awan\\
\\
Jul 29, 2025](https://www.firecrawl.dev/blog/building_medical_ai_application_with_grok_4) [Building a PDF RAG System with LangFlow and Firecrawl\\
\\
Learn how to build a complete Retrieval Augmented Generation (RAG) system for PDF documents using LangFlow's visual workflow and Firecrawl's document processing capabilities. This tutorial covers PDF collection, vector storage, and creating an interactive document search interface.\\
\\
![Bex Tuychiev](https://www.firecrawl.dev/_next/image?url=%2Fblog%2Fauthors%2Fbex.jpg&w=48&q=75&dpl=dpl_2hQ8hmy6vNQsu8DPuBRaRM6deLpr)\\
\\
Bex Tuychiev\\
\\
Jul 22, 2025](https://www.firecrawl.dev/blog/pdf-rag-system-langflow-firecrawl) [LangGraph Tutorial: Build a Startup Idea Validator with Interactive UI\\
\\
Learn how to create a powerful startup validation agent that analyzes market landscapes, community sentiment, and technical feasibility using LangGraph's agent framework with a responsive Streamlit interface.\\
\\
![Bex Tuychiev](https://www.firecrawl.dev/_next/image?url=%2Fblog%2Fauthors%2Fbex.jpg&w=48&q=75&dpl=dpl_2hQ8hmy6vNQsu8DPuBRaRM6deLpr)\\
\\
Bex Tuychiev\\
\\
Jun 27, 2025](https://www.firecrawl.dev/blog/langgraph-startup-validator-tutorial)

[MCP vs. A2A Protocols: What Developers Need to Know About AI's New Plumbing\\
\\
Understanding the distinction between Model Context Protocol (MCP) and Agent2Agent Protocol (A2A) - two emerging standards for connecting AI to the outside world and enabling AI systems to collaborate.\\
\\
![Caleb Peffer](https://www.firecrawl.dev/_next/image?url=%2Fblog%2Fauthors%2Fcaleb.jpg&w=48&q=75&dpl=dpl_2hQ8hmy6vNQsu8DPuBRaRM6deLpr)\\
\\
Caleb Peffer\\
\\
Apr 25, 2025](https://www.firecrawl.dev/blog/mcp-vs-a2a-protocols) [Fine-tuning Llama 4 on a Custom Dataset With Transformers And Firecrawl\\
\\
Learn how to fine-tune Llama 4 on a custom dataset using Unsloth and Firecrawl to improve model performance for specific tasks.\\
\\
![Bex Tuychiev](https://www.firecrawl.dev/_next/image?url=%2Fblog%2Fauthors%2Fbex.jpg&w=48&q=75&dpl=dpl_2hQ8hmy6vNQsu8DPuBRaRM6deLpr)\\
\\
Bex Tuychiev\\
\\
Apr 24, 2025](https://www.firecrawl.dev/blog/fine-tuning-llama4-custom-dataset-firecrawl) [The Best Open Source Frameworks For Building AI Agents in 2025\\
\\
Discover the top open source frameworks for building powerful AI agents with advanced reasoning, multi-agent collaboration, and tool integration capabilities to transform your enterprise workflows.\\
\\
![Bex Tuychiev](https://www.firecrawl.dev/_next/image?url=%2Fblog%2Fauthors%2Fbex.jpg&w=48&q=75&dpl=dpl_2hQ8hmy6vNQsu8DPuBRaRM6deLpr)\\
\\
Bex Tuychiev\\
\\
Apr 23, 2025](https://www.firecrawl.dev/blog/best-open-source-agent-frameworks-2025)

[The Best Pre-Built Enterprise RAG Platforms in 2025\\
\\
Explore the top enterprise Retrieval-Augmented Generation platforms of 2025, comparing features, security capabilities, and integration options to help you select the ideal solution for your organization's AI needs.\\
\\
![Bex Tuychiev](https://www.firecrawl.dev/_next/image?url=%2Fblog%2Fauthors%2Fbex.jpg&w=48&q=75&dpl=dpl_2hQ8hmy6vNQsu8DPuBRaRM6deLpr)\\
\\
Bex Tuychiev\\
\\
Apr 22, 2025](https://www.firecrawl.dev/blog/best-enterprise-rag-platforms-2025) [Fine-tuning Gemma 3 on a Custom Web Dataset With Firecrawl and Unsloth AI\\
\\
Learn how to efficiently fine-tune Google's Gemma 3 language model on your custom dataset using Firecrawl for data collection and Unsloth AI for optimization.\\
\\
![Bex Tuychiev](https://www.firecrawl.dev/_next/image?url=%2Fblog%2Fauthors%2Fbex.jpg&w=48&q=75&dpl=dpl_2hQ8hmy6vNQsu8DPuBRaRM6deLpr)\\
\\
Bex Tuychiev\\
\\
Mar 26, 2025](https://www.firecrawl.dev/blog/gemma-3-fine-tuning-firecrawl-unsloth) [Converting Entire Websites into Agents with Firecrawl's LLMs.txt Endpoint and OpenAI Agents SDK\\
\\
Learn how to transform any website into an interactive conversational agent by combining Firecrawl's LLMs.txt endpoint with OpenAI Agents SDK.\\
\\
![Bex Tuychiev](https://www.firecrawl.dev/_next/image?url=%2Fblog%2Fauthors%2Fbex.jpg&w=48&q=75&dpl=dpl_2hQ8hmy6vNQsu8DPuBRaRM6deLpr)\\
\\
Bex Tuychiev\\
\\
Mar 17, 2025](https://www.firecrawl.dev/blog/website-to-agent-with-firecrawl-openai)

[Modern Tech Stack for Retrieval Augmented Generation (RAG)\\
\\
Learn about the essential components and tools for building effective RAG systems that enhance LLM capabilities with external knowledge retrieval, including when to build from scratch versus using existing solutions.\\
\\
![Bex Tuychiev](https://www.firecrawl.dev/_next/image?url=%2Fblog%2Fauthors%2Fbex.jpg&w=48&q=75&dpl=dpl_2hQ8hmy6vNQsu8DPuBRaRM6deLpr)\\
\\
Bex Tuychiev\\
\\
Mar 10, 2025](https://www.firecrawl.dev/blog/modern-rag-tech-stack) [LLM API Engine: How to Build a Dynamic API Generation Engine Powered by Firecrawl\\
\\
Build a dynamic API generation engine that transforms web data into structured APIs using natural language instead of code.\\
\\
![Bex Tuychiev](https://www.firecrawl.dev/_next/image?url=%2Fblog%2Fauthors%2Fbex.jpg&w=48&q=75&dpl=dpl_2hQ8hmy6vNQsu8DPuBRaRM6deLpr)\\
\\
Bex Tuychiev\\
\\
Feb 26, 2025](https://www.firecrawl.dev/blog/llm-api-engine-dynamic-api-generation-explainer) [How to Create Custom Instruction Datasets for LLM Fine-tuning\\
\\
A comprehensive guide to creating instruction datasets for fine-tuning LLMs, including best practices and a practical code documentation example.\\
\\
![Bex Tuychiev](https://www.firecrawl.dev/_next/image?url=%2Fblog%2Fauthors%2Fbex.jpg&w=48&q=75&dpl=dpl_2hQ8hmy6vNQsu8DPuBRaRM6deLpr)\\
\\
Bex Tuychiev\\
\\
Feb 18, 2025](https://www.firecrawl.dev/blog/custom-instruction-datasets-llm-fine-tuning)

[Fine-tuning DeepSeek R1 on a Custom Instructions Dataset\\
\\
Learn how to fine-tune DeepSeek R1 language models using custom instruction datasets.\\
\\
![Bex Tuychiev](https://www.firecrawl.dev/_next/image?url=%2Fblog%2Fauthors%2Fbex.jpg&w=48&q=75&dpl=dpl_2hQ8hmy6vNQsu8DPuBRaRM6deLpr)\\
\\
Bex Tuychiev\\
\\
Feb 18, 2025](https://www.firecrawl.dev/blog/fine-tuning-deepseek) [Building an Intelligent Code Documentation RAG Assistant with DeepSeek and Firecrawl\\
\\
A guide to building a documentation assistant that uses DeepSeek and RAG to intelligently answer questions about any documentation website.\\
\\
![Bex Tuychiev](https://www.firecrawl.dev/_next/image?url=%2Fblog%2Fauthors%2Fbex.jpg&w=48&q=75&dpl=dpl_2hQ8hmy6vNQsu8DPuBRaRM6deLpr)\\
\\
Bex Tuychiev\\
\\
Feb 10, 2025](https://www.firecrawl.dev/blog/deepseek-rag-documentation-assistant) [Evaluating Web Data Extraction with CrawlBench\\
\\
An in-depth exploration of CrawlBench, a benchmark for testing LLM-based web data extraction.\\
\\
![Swyx](https://www.firecrawl.dev/_next/image?url=%2Fblog%2Fauthors%2Fswyx.jpg&w=48&q=75&dpl=dpl_2hQ8hmy6vNQsu8DPuBRaRM6deLpr)\\
\\
Swyx\\
\\
Dec 09, 2024](https://www.firecrawl.dev/blog/crawlbench-llm-extraction)

[Getting Started with OpenAI's Predicted Outputs for Faster LLM Responses\\
\\
A guide to leveraging Predicted Outputs to speed up LLM tasks with GPT-4o models.\\
\\
![Eric Ciarla](https://www.firecrawl.dev/_next/image?url=%2Fblog%2Fauthors%2Feric-img.jpeg&w=48&q=75&dpl=dpl_2hQ8hmy6vNQsu8DPuBRaRM6deLpr)\\
\\
Eric Ciarla\\
\\
Nov 05, 2024](https://www.firecrawl.dev/blog/getting-started-with-predicted-outputs-openai) [Getting Started with Grok-2: Setup and Web Crawler Example\\
\\
A detailed guide on setting up Grok-2 and building a web crawler using Firecrawl.\\
\\
![Nicolas Camara](https://www.firecrawl.dev/_next/image?url=%2Fblog%2Fauthors%2Fnick-img.jpeg&w=48&q=75&dpl=dpl_2hQ8hmy6vNQsu8DPuBRaRM6deLpr)\\
\\
Nicolas Camara\\
\\
Oct 21, 2024](https://www.firecrawl.dev/blog/grok-2-setup-and-web-crawler-example) [OpenAI Swarm Tutorial: Create Marketing Campaigns for Any Website\\
\\
A guide to building a multi-agent system using OpenAI Swarm and Firecrawl for AI-driven marketing strategies\\
\\
![Nicolas Camara](https://www.firecrawl.dev/_next/image?url=%2Fblog%2Fauthors%2Fnick-img.jpeg&w=48&q=75&dpl=dpl_2hQ8hmy6vNQsu8DPuBRaRM6deLpr)\\
\\
Nicolas Camara\\
\\
Oct 12, 2024](https://www.firecrawl.dev/blog/openai-swarm-agent-tutorial)

[Using OpenAI's Realtime API and Firecrawl to Talk with Any Website\\
\\
Build a real-time conversational agent that interacts with any website using OpenAI's Realtime API and Firecrawl.\\
\\
![Nicolas Camara](https://www.firecrawl.dev/_next/image?url=%2Fblog%2Fauthors%2Fnick-img.jpeg&w=48&q=75&dpl=dpl_2hQ8hmy6vNQsu8DPuBRaRM6deLpr)\\
\\
Nicolas Camara\\
\\
Oct 11, 2024](https://www.firecrawl.dev/blog/How-to-Talk-with-Any-Website-Using-OpenAIs-Realtime-API-and-Firecrawl) [How to Use OpenAI's o1 Reasoning Models in Your Applications\\
\\
Learn how to harness OpenAI's latest o1 series models for complex reasoning tasks in your apps.\\
\\
![Eric Ciarla](https://www.firecrawl.dev/_next/image?url=%2Fblog%2Fauthors%2Feric-img.jpeg&w=48&q=75&dpl=dpl_2hQ8hmy6vNQsu8DPuBRaRM6deLpr)\\
\\
Eric Ciarla\\
\\
Sep 16, 2024](https://www.firecrawl.dev/blog/how-to-use-openai-o1-reasoning-models-in-applications) [How to Use Prompt Caching and Cache Control with Anthropic Models\\
\\
Learn how to cache large context prompts with Anthropic Models like Opus, Sonnet, and Haiku for faster and cheaper chats that analyze website data.\\
\\
![Eric Ciarla](https://www.firecrawl.dev/_next/image?url=%2Fblog%2Fauthors%2Feric-img.jpeg&w=48&q=75&dpl=dpl_2hQ8hmy6vNQsu8DPuBRaRM6deLpr)\\
\\
Eric Ciarla\\
\\
Aug 14, 2024](https://www.firecrawl.dev/blog/using-prompt-caching-with-anthropic)

[How to Use OpenAI's Structured Outputs and JSON Strict Mode\\
\\
A guide for getting structured data from the latest OpenAI models.\\
\\
![Eric Ciarla](https://www.firecrawl.dev/_next/image?url=%2Fblog%2Fauthors%2Feric-img.jpeg&w=48&q=75&dpl=dpl_2hQ8hmy6vNQsu8DPuBRaRM6deLpr)\\
\\
Eric Ciarla\\
\\
Aug 07, 2024](https://www.firecrawl.dev/blog/using-structured-output-and-json-strict-mode-openai) [Build a 'Chat with website' using Groq Llama 3\\
\\
Learn how to use Firecrawl, Groq Llama 3, and Langchain to build a 'Chat with your website' bot.\\
\\
![Nicolas Camara](https://www.firecrawl.dev/_next/image?url=%2Fblog%2Fauthors%2Fnick-img.jpeg&w=48&q=75&dpl=dpl_2hQ8hmy6vNQsu8DPuBRaRM6deLpr)\\
\\
Nicolas Camara\\
\\
May 22, 2024](https://www.firecrawl.dev/blog/chat-with-website) [Extract website data using LLMs\\
\\
Learn how to use Firecrawl and Groq to extract structured data from a web page in a few lines of code.\\
\\
![Nicolas Camara](https://www.firecrawl.dev/_next/image?url=%2Fblog%2Fauthors%2Fnick-img.jpeg&w=48&q=75&dpl=dpl_2hQ8hmy6vNQsu8DPuBRaRM6deLpr)\\
\\
Nicolas Camara\\
\\
May 20, 2024](https://www.firecrawl.dev/blog/data-extraction-using-llms)

[Build an agent that checks for website contradictions\\
\\
Using Firecrawl and Claude to scrape your website's data and look for contradictions.\\
\\
![Eric Ciarla](https://www.firecrawl.dev/_next/image?url=%2Fblog%2Fauthors%2Feric-img.jpeg&w=48&q=75&dpl=dpl_2hQ8hmy6vNQsu8DPuBRaRM6deLpr)\\
\\
Eric Ciarla\\
\\
May 19, 2024](https://www.firecrawl.dev/blog/contradiction-agent)

FOOTER

The easiest way to extract

data from the web

Backed by

Y Combinator

[Linkedin](https://www.linkedin.com/company/firecrawl) [Github](https://github.com/firecrawl/firecrawl) [YouTube](https://www.youtube.com/@Firecrawl_dev)

SOC II ¬∑ Type 2

AICPA

SOC 2

[X (Twitter)](https://x.com/firecrawl) [Discord](https://discord.gg/gSmWdAkdwd)

Products

[Playground](https://www.firecrawl.dev/playground) [Agent](https://www.firecrawl.dev/agent) [Pricing](https://www.firecrawl.dev/pricing) [Templates](https://www.firecrawl.dev/templates) [Changelog](https://www.firecrawl.dev/changelog)

Use Cases

[AI Platforms](https://www.firecrawl.dev/use-cases/ai-platforms) [Lead Enrichment](https://www.firecrawl.dev/use-cases/lead-enrichment) [SEO Teams](https://www.firecrawl.dev/use-cases/seo-teams) [Deep Research](https://www.firecrawl.dev/use-cases/deep-research) [Competitive Intelligence](https://www.firecrawl.dev/use-cases/competitive-intelligence)

Documentation

[Getting started](https://docs.firecrawl.dev/introduction) [API Reference](https://docs.firecrawl.dev/api-reference/introduction) [Integrations](https://www.firecrawl.dev/app) [Examples](https://docs.firecrawl.dev/use-cases/overview) [SDKs](https://docs.firecrawl.dev/sdks/overview)

Company

[Blog](https://www.firecrawl.dev/blog) [Careers](https://www.firecrawl.dev/careers) [Creator & OSS program](https://www.firecrawl.dev/creator-oss-program) [Student program](https://www.firecrawl.dev/student-program)

¬© 2025 Firecrawl

[Terms of Service](https://www.firecrawl.dev/terms-of-service) [Privacy Policy](https://www.firecrawl.dev/privacy-policy) [Report Abuse](mailto:help@firecrawl.com?subject=Issue:)

[All systems normal](https://status.firecrawl.dev/)

## AI Chat Support
Introducing the Firecrawl Skill + CLI for Agents. [Learn more ‚Üí](https://docs.firecrawl.dev/sdks/cli)

[2 Months Free ‚Äî Annually](https://www.firecrawl.dev/pricing)

# AI Agents &   Knowledge Bases

Stop hand-uploading knowledge bases.

Crawl and extract docs, help centers, and product sites with Firecrawl.

[Start for free](https://www.firecrawl.dev/app/playground) [View Docs](https://docs.firecrawl.dev/introduction)

//

Used by over 500,000 developers

//

Trusted by 80,000+

companies of all sizes

![Logo 17](https://www.firecrawl.dev/assets-original/logocloud/17.png)

![Logo 18](https://www.firecrawl.dev/assets-original/logocloud/18.png)

![Logo 1](https://www.firecrawl.dev/assets-original/logocloud/1.png)

![Logo 2](https://www.firecrawl.dev/assets-original/logocloud/2.png)

![Logo 3](https://www.firecrawl.dev/assets-original/logocloud/3.png)

![Logo 5](https://www.firecrawl.dev/assets-original/logocloud/5.png)

![Logo 6](https://www.firecrawl.dev/assets-original/logocloud/6.png)

![Logo 7](https://www.firecrawl.dev/assets-original/logocloud/7.png)

![Logo 8](https://www.firecrawl.dev/assets-original/logocloud/8.png)

![Logo 9](https://www.firecrawl.dev/assets-original/logocloud/9.png)

![Logo 10](https://www.firecrawl.dev/assets-original/logocloud/10.png)

![Logo 11](https://www.firecrawl.dev/assets-original/logocloud/11.png)

![Logo 12](https://www.firecrawl.dev/assets-original/logocloud/12.png)

![Logo 13](https://www.firecrawl.dev/assets-original/logocloud/13.png)

![Logo 14](https://www.firecrawl.dev/assets-original/logocloud/14.png)

![Logo 15](https://www.firecrawl.dev/assets-original/logocloud/15.png)

![Logo 16](https://www.firecrawl.dev/assets-original/logocloud/16.png)

![Logo 17](https://www.firecrawl.dev/assets-original/logocloud/17.png)

![Logo 18](https://www.firecrawl.dev/assets-original/logocloud/18.png)

![Logo 19](https://www.firecrawl.dev/assets-original/logocloud/19.png)

![Logo 20](https://www.firecrawl.dev/assets-original/logocloud/20.png)

![Logo 21](https://www.firecrawl.dev/assets-original/logocloud/21.png)

![Logo 17](https://www.firecrawl.dev/assets-original/logocloud/17.png)

![Logo 18](https://www.firecrawl.dev/assets-original/logocloud/18.png)

![Logo 1](https://www.firecrawl.dev/assets-original/logocloud/1.png)

![Logo 2](https://www.firecrawl.dev/assets-original/logocloud/2.png)

![Logo 3](https://www.firecrawl.dev/assets-original/logocloud/3.png)

![Logo 5](https://www.firecrawl.dev/assets-original/logocloud/5.png)

![Logo 6](https://www.firecrawl.dev/assets-original/logocloud/6.png)

![Logo 7](https://www.firecrawl.dev/assets-original/logocloud/7.png)

![Logo 8](https://www.firecrawl.dev/assets-original/logocloud/8.png)

![Logo 9](https://www.firecrawl.dev/assets-original/logocloud/9.png)

![Logo 10](https://www.firecrawl.dev/assets-original/logocloud/10.png)

![Logo 11](https://www.firecrawl.dev/assets-original/logocloud/11.png)

![Logo 12](https://www.firecrawl.dev/assets-original/logocloud/12.png)

![Logo 13](https://www.firecrawl.dev/assets-original/logocloud/13.png)

![Logo 14](https://www.firecrawl.dev/assets-original/logocloud/14.png)

![Logo 15](https://www.firecrawl.dev/assets-original/logocloud/15.png)

![Logo 16](https://www.firecrawl.dev/assets-original/logocloud/16.png)

![Logo 17](https://www.firecrawl.dev/assets-original/logocloud/17.png)

![Logo 18](https://www.firecrawl.dev/assets-original/logocloud/18.png)

![Logo 19](https://www.firecrawl.dev/assets-original/logocloud/19.png)

![Logo 20](https://www.firecrawl.dev/assets-original/logocloud/20.png)

![Logo 21](https://www.firecrawl.dev/assets-original/logocloud/21.png)

10x

faster knowledge base setup

99.9%

content accuracy vs manual uploads

24/7

automatic refresh schedules

### Perfect for

#### Customer support chatbots

Deflect tickets with grounded answers from your docs, FAQs, and troubleshooting guides, with citations back to source pages.

#### AI agent builders

Keep agents synced with the latest product docs, help center updates, and changelogs without manual exports or brittle scrapers.

#### Sales and solutions assistants

Answer product and pricing questions accurately using up to date public pages and integration docs, not stale PDFs.

#### Internal enablement copilots

Power employee facing assistants with scoped knowledge bases so teams only access the content they are allowed to use.

\[ 01 / 03 \]

¬∑

Use Cases

![AI Assistant](https://www.firecrawl.dev/assets-original/ai/bot.png)

AI Assistant

withFirecrawl

Real-time¬∑Updated 2 min ago

Ask anything...

### How it works

#### Crawl your content sources

Crawl docs, help centers, and product sites into structured markdown or JSON. Your AI assistants start from the same source-of-truth content your customers see.

[Crawl endpoint](https://docs.firecrawl.dev/features/crawl)

#### Extract with rich metadata

Attach URLs, section titles, and metadata to every chunk so chatbots can show citations and 'read more' links instead of opaque answers support teams can't audit.

[Extract endpoint](https://docs.firecrawl.dev/features/extract)

#### Schedule automatic refreshes

Schedule Firecrawl crawls for customer-facing sites so AI chatbots and RAG knowledge bases refresh automatically before launches, campaigns, or support spikes.

[Scheduling guide](https://docs.firecrawl.dev/features/batch-scrape)

#### Scope content by tenant

Scope Firecrawl jobs by domain and path per workspace or tenant so each AI assistant only loads the content it is allowed to use.

#### Feed into your RAG stack

Feed Firecrawl output directly into your RAG pipelines, vector stores, or AI search stack so assistants answer long-tail questions from product documentation.

[RAG tutorial](https://www.firecrawl.dev/blog/best-chunking-strategies-rag-2025)

#### Discover new content

Combine Firecrawl search and crawl jobs so you can discover new relevant pages over time and close knowledge gaps in your AI chat knowledge base.

[Search API](https://docs.firecrawl.dev/features/search)

\[ 02 / 03 \]

¬∑

What Our Customers Say

//

Community

//

## People love    building with Firecrawl

Discover why developers choose Firecrawl every day.

[![Morgan Linton](https://www.firecrawl.dev/assets-original/testimonials/morgan-linton.png)Morgan Linton@morganlinton"If you're coding with AI, and haven't discovered @firecrawl yet, prepare to have your mind blown ü§Ø"](https://x.com/morganlinton/status/1839454165703204955) [![Chris DeWeese](https://www.firecrawl.dev/assets-original/testimonials/chris-deweese.png)Chris DeWeese@chrisdeweese\_"Started using @firecrawl for a project, I wish I used this sooner."](https://x.com/chrisdeweese_/status/1853587120406876601) [![Alex Reibman](https://www.firecrawl.dev/assets-original/testimonials/alex-reibman.png)Alex Reibman@AlexReibman"Moved our internal agent's web scraping tool from Apify to Firecrawl because it benchmarked 50x faster with AgentOps."](https://x.com/AlexReibman/status/1780299595484131836) [![Tom - Morpho](https://www.firecrawl.dev/assets-original/testimonials/tom-morpho.png)Tom - Morpho@TomReppelin"I found gold today. Thank you @firecrawl"](https://x.com/TomReppelin/status/1844382491014201613)

[![Morgan Linton](https://www.firecrawl.dev/assets-original/testimonials/morgan-linton.png)Morgan Linton@morganlinton"If you're coding with AI, and haven't discovered @firecrawl yet, prepare to have your mind blown ü§Ø"](https://x.com/morganlinton/status/1839454165703204955) [![Chris DeWeese](https://www.firecrawl.dev/assets-original/testimonials/chris-deweese.png)Chris DeWeese@chrisdeweese\_"Started using @firecrawl for a project, I wish I used this sooner."](https://x.com/chrisdeweese_/status/1853587120406876601) [![Alex Reibman](https://www.firecrawl.dev/assets-original/testimonials/alex-reibman.png)Alex Reibman@AlexReibman"Moved our internal agent's web scraping tool from Apify to Firecrawl because it benchmarked 50x faster with AgentOps."](https://x.com/AlexReibman/status/1780299595484131836) [![Tom - Morpho](https://www.firecrawl.dev/assets-original/testimonials/tom-morpho.png)Tom - Morpho@TomReppelin"I found gold today. Thank you @firecrawl"](https://x.com/TomReppelin/status/1844382491014201613)

[![Bardia](https://www.firecrawl.dev/assets-original/testimonials/bardia.png)Bardia@thepericulum"The Firecrawl team ships. I wanted types for their node SDK, and less than an hour later, I got them."](https://x.com/thepericulum/status/1781397799487078874) [![Matt Busigin](https://www.firecrawl.dev/assets-original/testimonials/matt-busigin.png)Matt Busigin@mbusigin"Firecrawl is dope. Congrats guys üëè"](https://x.com/mbusigin/status/1836065372010656069) [![Sumanth](https://www.firecrawl.dev/assets-original/testimonials/sumanth.png)Sumanth@Sumanth\_077"Web scraping will never be the same!\\
\\
Firecrawl is an open-source framework that takes a URL, crawls it, and conver..."](https://x.com/Sumanth_077/status/1940049003074478511) [![Steven Tey](https://www.firecrawl.dev/assets-original/testimonials/steven-tey.png)Steven Tey@steventey"Open-source Clay alternative just dropped\\
\\
Upload a CSV of emails and..."](https://x.com/steventey/status/1932945651761098889)

[![Bardia](https://www.firecrawl.dev/assets-original/testimonials/bardia.png)Bardia@thepericulum"The Firecrawl team ships. I wanted types for their node SDK, and less than an hour later, I got them."](https://x.com/thepericulum/status/1781397799487078874) [![Matt Busigin](https://www.firecrawl.dev/assets-original/testimonials/matt-busigin.png)Matt Busigin@mbusigin"Firecrawl is dope. Congrats guys üëè"](https://x.com/mbusigin/status/1836065372010656069) [![Sumanth](https://www.firecrawl.dev/assets-original/testimonials/sumanth.png)Sumanth@Sumanth\_077"Web scraping will never be the same!\\
\\
Firecrawl is an open-source framework that takes a URL, crawls it, and conver..."](https://x.com/Sumanth_077/status/1940049003074478511) [![Steven Tey](https://www.firecrawl.dev/assets-original/testimonials/steven-tey.png)Steven Tey@steventey"Open-source Clay alternative just dropped\\
\\
Upload a CSV of emails and..."](https://x.com/steventey/status/1932945651761098889)

### How Firecrawl compares to alternatives

| Feature | Firecrawl | Manual CSV uploads | Browser extensions | Generic scrapers |
| --- | --- | --- | --- | --- |
| Structured markdown output |  |  |  |  |
| Automatic scheduling & refresh |  |  |  |  |
| JavaScript rendering |  |  |  |  |
| URL metadata preserved |  |  |  |  |
| Multi-tenant scoping |  |  |  |  |
| API-first integration |  |  |  |  |
| Built-in rate limiting & retries |  |  |  |  |
| No manual intervention required |  |  |  |  |

### All Customer Stories

[![Answer HQ](https://www.firecrawl.dev/images/blog/how-answer-hq-powers-ai-customer-support-with-firecrawl/image.webp)\\
\\
Answer HQ\\
\\
How Answer HQ Powers AI Customer Support with Firecrawl\\
\\
Discover how Answer HQ uses Firecrawl to help small businesses import their website data and build intelligent support assistants.](https://www.firecrawl.dev/blog/how-answer-hq-powers-ai-customer-support-with-firecrawl) [![Botpress](https://www.firecrawl.dev/images/blog/botpress-customer-story.webp)\\
\\
Botpress\\
\\
How Botpress Enhances Knowledge Base Creation with Firecrawl\\
\\
Discover how Botpress uses Firecrawl to streamline knowledge base population and improve user experience.](https://www.firecrawl.dev/blog/how-botpress-enhances-knowledge-base-creation-with-firecrawl) [![Stack AI](https://www.firecrawl.dev/images/blog/customer-story-stackai.jpg)\\
\\
Stack AI\\
\\
How Stack AI Uses Firecrawl to Power AI Agents\\
\\
Discover how Stack AI leverages Firecrawl to seamlessly feed agentic AI workflows with high-quality web data.](https://www.firecrawl.dev/blog/how-stack-ai-uses-firecrawl-to-power-ai-agents)

### Tutorials & Guides

[![Building an Intelligent Code Documentation RAG Assistant with DeepSeek and Firecrawl](https://www.firecrawl.dev/_next/image?url=%2Fimages%2Fblog%2Fdeepseek_rag%2Fdeepseek-rag-documentation-assistant.jpg&w=3840&q=75&dpl=dpl_2hQ8hmy6vNQsu8DPuBRaRM6deLpr)\\
\\
**Building an Intelligent Code Documentation RAG Assistant with DeepSeek and Firecrawl** \\
\\
A guide to building a documentation assistant that uses DeepSeek and RAG to intelligently answer questions about any documentation website.\\
\\
Read tutorial ‚Üí](https://www.firecrawl.dev/blog/deepseek-rag-documentation-assistant) [![Best Chunking Strategies for RAG in 2025](https://www.firecrawl.dev/_next/image?url=%2Fimages%2Fblog%2Fbest-chunking-strategies-rag-2025%2Fbest-chunking-strategies-rag-2025.webp&w=3840&q=75&dpl=dpl_2hQ8hmy6vNQsu8DPuBRaRM6deLpr)\\
\\
**Best Chunking Strategies for RAG in 2025** \\
\\
Compare six chunking strategies for RAG systems using real benchmark data with practical LangChain and LlamaIndex code examples.\\
\\
Read tutorial ‚Üí](https://www.firecrawl.dev/blog/best-chunking-strategies-rag-2025) [![10 AI Projects You Can Build with Firecrawl Now](https://www.firecrawl.dev/_next/image?url=%2Fimages%2Fblog%2F10-ai-projects-with-firecrawl%2F10-ai-projects-with-firecrawl.webp&w=3840&q=75&dpl=dpl_2hQ8hmy6vNQsu8DPuBRaRM6deLpr)\\
\\
**10 AI Projects You Can Build with Firecrawl Now** \\
\\
Discover 10 practical AI projects you can build with Firecrawl, from chatbots to data enrichment tools.\\
\\
Read tutorial ‚Üí](https://www.firecrawl.dev/blog/10-ai-projects-with-firecrawl)

//

FAQ

//

## Frequently    asked questions

Everything you need to know about this use case.

General

How does Firecrawl help my AI chatbot access real-time information?

Firecrawl runs before retrieval, turning your docs, help centers, and product sites into clean markdown or JSON with URLs attached. Your chatbot or AI search stack then uses that output as the source for embeddings, retrieval, and context windows instead of raw HTML or manual uploads.

What types of knowledge bases work best with Firecrawl?

Firecrawl works especially well with documentation portals, help centers, FAQs, status pages, and product sites‚Äîanywhere your source-of-truth content lives on the web. You choose which domains and paths to crawl based on what each assistant should know.

Technical

Can I control which pages each assistant or workspace can access?

Yes. You scope Firecrawl jobs by domain, path, or custom rules per workspace or customer. That way, multi-tenant platforms can keep each AI assistant grounded only in the content it is allowed to reference.

How often should I refresh my AI chatbot knowledge base with Firecrawl?

Most teams schedule daily or weekly crawls for core docs and help centers, plus on-demand crawls around major launches. Firecrawl supports both scheduled jobs and real-time calls for urgent updates.

Integration

How do I prevent my chatbot from hallucinating outdated information?

By constraining retrieval to Firecrawl-collected content with clear URLs, headings, and timestamps, you make it explicit what the model should trust. You can also surface citations in the UI so users see exactly which pages each answer comes from.

Why Firecrawl?

What is Firecrawl's scrape quality and coverage like?

The world's most comprehensive web data API. Our custom browser stack and semantic index deliver superior data quality across any website, handling more content types and edge cases than any competitor.

How does Firecrawl handle complex websites?

JavaScript rendering, dynamic content, and robust request handling built-in.

Can Firecrawl scrape at enterprise scale?

Process millions of pages with automatic rate limiting, caching, and distributed infrastructure.

How fast is Firecrawl scraping?

Optimized scraping engine with parallel processing and smart caching for instant results.

Is Firecrawl built for developers?

Comprehensive docs, SDKs for all major languages, and dedicated support to help you succeed.

\[ 03 / 03 \]

¬∑

Pricing

//

Transparent

//

## Flexible pricing

Explore transparent pricing built for real-world scraping.  Start for free, then scale as you grow.

üá≥üá¥NOK

Free Plan

A lightweight way to try scraping.

No cost, no card, no hassle.

500 credits (one-time)

kr0123456789

one-time

Get started

Scrape 500 pages

2 concurrent requests

Low rate limits

Hobby

Great for side projects and small tools.

Fast, simple, no overkill.

3,000 credits / month

kr012345678901234567890123456789

/monthly

Billed yearly

2 months free

Subscribe

Scrape 3,000 pages

5 concurrent requests

Basic support

kr87 per extra 1k credits

Standard

Most popular

Perfect for scaling with less effort.

Simple, solid, dependable.

100,000 credits / month

kr012345678901234567890123456789

/monthly

Billed yearly

2 months free

Subscribe

Scrape 100,000 pages

50 concurrent requests

Standard support

kr454 per extra 35k credits

Growth

Built for high volume and speed.

Firecrawl at full force.

500,000 credits / month

kr0123456789.0123456789k

/monthly

Billed yearly

2 months free

Subscribe

Scrape 500,000 pages

100 concurrent requests

Priority support

kr1,711 per extra 175k credits

Extra credits are available via auto-recharge packs. [Enable](https://www.firecrawl.dev/signin?view=signup)

Actual price may vary based on the exchange rate in place between USD and NOK at the time of payment processing or invoicing. Prices exclude all taxes, levies and duties and are paid in USD.

## Scale Plans

High-volume plans for teams that need more power and dedicated support. Get access to higher rate limits, more concurrent browsers, and priority support.

[Need more? Contact us](https://fk4bvu0n5qp.typeform.com/to/Ej6oydlg)

Scale

For teams scaling their data pipelines

1,000,000 credits

kr5,790per month

Billed yearly

2 months free

Subscribe

Scrape 1,000,000 pages

150 concurrent requests

Priority support

Enterprise

Power at your pace with custom solutions

Custom credits

Custom

[Get Started](https://fk4bvu0n5qp.typeform.com/to/Ej6oydlg)

Scrape unlimited pages

Custom concurrent requests

Dedicated support & SLA

Bulk discounts

Zero-data retention

SSO & advanced security

\[ CTA \]

\[ CRAWL \]

\[ SCRAPE \]

\[ CTA \]

//

Get started

//

Ready to power your AI assistants?

Start building intelligent chatbots with real-time web data today.

[Start for free](https://www.firecrawl.dev/app/playground)

FOOTER

The easiest way to extract

data from the web

Backed by

Y Combinator

[Linkedin](https://www.linkedin.com/company/firecrawl) [Github](https://github.com/firecrawl/firecrawl) [YouTube](https://www.youtube.com/@Firecrawl_dev)

SOC II ¬∑ Type 2

AICPA

SOC 2

[X (Twitter)](https://x.com/firecrawl) [Discord](https://discord.gg/gSmWdAkdwd)

Products

[Playground](https://www.firecrawl.dev/playground) [Agent](https://www.firecrawl.dev/agent) [Pricing](https://www.firecrawl.dev/pricing) [Templates](https://www.firecrawl.dev/templates) [Changelog](https://www.firecrawl.dev/changelog)

Use Cases

[AI Platforms](https://www.firecrawl.dev/use-cases/ai-platforms) [Lead Enrichment](https://www.firecrawl.dev/use-cases/lead-enrichment) [SEO Teams](https://www.firecrawl.dev/use-cases/seo-teams) [Deep Research](https://www.firecrawl.dev/use-cases/deep-research) [Competitive Intelligence](https://www.firecrawl.dev/use-cases/competitive-intelligence)

Documentation

[Getting started](https://docs.firecrawl.dev/introduction) [API Reference](https://docs.firecrawl.dev/api-reference/introduction) [Integrations](https://www.firecrawl.dev/app) [Examples](https://docs.firecrawl.dev/use-cases/overview) [SDKs](https://docs.firecrawl.dev/sdks/overview)

Company

[Blog](https://www.firecrawl.dev/blog) [Careers](https://www.firecrawl.dev/careers) [Creator & OSS program](https://www.firecrawl.dev/creator-oss-program) [Student program](https://www.firecrawl.dev/student-program)

¬© 2025 Firecrawl

[Terms of Service](https://www.firecrawl.dev/terms-of-service) [Privacy Policy](https://www.firecrawl.dev/privacy-policy) [Report Abuse](mailto:help@firecrawl.com?subject=Issue:)

[All systems normal](https://status.firecrawl.dev/)

StripeM-Inner

## Best Web Extraction Tool
Introducing Parallel Agents - Run multiple /agent queries simultaneously. [Read more ‚Üí](https://www.firecrawl.dev/blog/introducing-parallel-agents)

//

Get started

//

### Ready to build?

Start getting Web Data for free and scale seamlessly as your project expands.No credit card needed.

[Start for free](https://www.firecrawl.dev/signin) [See our plans](https://www.firecrawl.dev/pricing)

#### All Questions

[Glossary](https://www.firecrawl.dev/glossary)/ [Web Extraction APIs](https://www.firecrawl.dev/glossary/web-extraction-apis)/Questions

[What is the easiest way to get structured JSON data from a bunch of different URLs?](https://www.firecrawl.dev/glossary/web-extraction-apis/get-structured-json-data-from-urls)

# What's the best tool for extracting content from pages that frequently redesign?

## TL;DR

Firecrawl's LLM-powered extraction handles frequent redesigns by understanding content semantically rather than relying on brittle CSS selectors. Define what data you want with a schema, and Firecrawl extracts it regardless of layout changes‚Äîno maintenance required when sites update their HTML structure.

## Why traditional scraping breaks

CSS selectors and XPath target specific HTML elements. When a site redesigns‚Äîchanging class names, restructuring divs, or updating frameworks‚Äîthese selectors break immediately. Teams spend hours fixing scrapers after every site update.

## LLM extraction solves this

Firecrawl extracts web data using AI to understand page content semantically. Instead of targeting `.product-price-v2`, you describe what you want: "extract the product price." Firecrawl API finds it regardless of HTML structure.

```
result = app.agent(
    prompt="Find the founders of Firecrawl",
    model="spark-1-mini"
)
```

## When to use this approach

| Scenario | Selector-Based | LLM Extraction |
| --- | --- | --- |
| Sites you control | Works well | Overkill |
| Competitor monitoring | Constant fixes | Maintenance-free |
| Multi-site scraping | Different selectors each | One schema works |
| Frequently updated sites | Breaks often | Adapts automatically |

## Key Takeaways

Traditional CSS-based scraping breaks whenever target sites redesign. Firecrawl's LLM-powered extraction understands content semantically, letting you define schemas that work regardless of HTML structure changes. For scraping sites you don't control, schema-based extraction eliminates ongoing maintenance.

Last updated: Jan 26, 2026

\[ CTA \]

\[ CRAWL \]

\[ SCRAPE \]

\[ CTA \]

//

Get started

//

Ready to build?

Start getting Web Data for free and scale seamlessly as your project expands. No credit card needed.

[Start for free](https://www.firecrawl.dev/signin) [See our plans](https://www.firecrawl.dev/pricing)

FOOTER

The easiest way to extract

data from the web

Backed by

Y Combinator

[Linkedin](https://www.linkedin.com/company/firecrawl) [Github](https://github.com/firecrawl/firecrawl) [YouTube](https://www.youtube.com/@Firecrawl_dev)

SOC II ¬∑ Type 2

AICPA

SOC 2

[X (Twitter)](https://x.com/firecrawl) [Discord](https://discord.gg/gSmWdAkdwd)

Products

[Playground](https://www.firecrawl.dev/playground) [Agent](https://www.firecrawl.dev/agent) [Pricing](https://www.firecrawl.dev/pricing) [Templates](https://www.firecrawl.dev/templates) [Changelog](https://www.firecrawl.dev/changelog)

Use Cases

[AI Platforms](https://www.firecrawl.dev/use-cases/ai-platforms) [Lead Enrichment](https://www.firecrawl.dev/use-cases/lead-enrichment) [SEO Teams](https://www.firecrawl.dev/use-cases/seo-teams) [Deep Research](https://www.firecrawl.dev/use-cases/deep-research) [Competitive Intelligence](https://www.firecrawl.dev/use-cases/competitive-intelligence)

Documentation

[Getting started](https://docs.firecrawl.dev/introduction) [API Reference](https://docs.firecrawl.dev/api-reference/introduction) [Integrations](https://www.firecrawl.dev/app) [Examples](https://docs.firecrawl.dev/use-cases/overview) [SDKs](https://docs.firecrawl.dev/sdks/overview)

Company

[Blog](https://www.firecrawl.dev/blog) [Careers](https://www.firecrawl.dev/careers) [Creator & OSS program](https://www.firecrawl.dev/creator-oss-program) [Student program](https://www.firecrawl.dev/student-program)

¬© 2025 Firecrawl

[Terms of Service](https://www.firecrawl.dev/terms-of-service) [Privacy Policy](https://www.firecrawl.dev/privacy-policy) [Report Abuse](mailto:help@firecrawl.com?subject=Issue:)

[All systems normal](https://status.firecrawl.dev/)

## Firecrawl Sign In
Log In

Sign Up

Email

Password

Create Account

Continue with GitHub

Continue with Google

By signing up, you agree to our [Terms of Service](https://www.firecrawl.dev/terms-of-service) and [Privacy Policy](https://www.firecrawl.dev/privacy-policy)

reCAPTCHA

Recaptcha requires verification.

[Privacy](https://www.google.com/intl/en/policies/privacy/) \- [Terms](https://www.google.com/intl/en/policies/terms/)

protected by **reCAPTCHA**

[Privacy](https://www.google.com/intl/en/policies/privacy/) \- [Terms](https://www.google.com/intl/en/policies/terms/)

## Instant Chatbot Creation
Introducing Parallel Agents - Run multiple /agent queries simultaneously. [Read more ‚Üí](https://www.firecrawl.dev/blog/introducing-parallel-agents)

//

Get started

//

### Ready to build?

Start getting Web Data for free and scale seamlessly as your project expands.No credit card needed.

[Start for free](https://www.firecrawl.dev/signin) [See our plans](https://www.firecrawl.dev/pricing)

#### Table of Contents

[Blog](https://www.firecrawl.dev/blog)

Announcing Firestarter, our open source tool that turns any website into a chatbot

![placeholder](https://www.firecrawl.dev/_next/image?url=%2Fblog%2Fauthors%2Feric-img.jpeg&w=48&q=75&dpl=dpl_2hQ8hmy6vNQsu8DPuBRaRM6deLpr)Eric Ciarla

Jun 18, 2025

![Announcing Firestarter, our open source tool that turns any website into a chatbot image](https://www.firecrawl.dev/_next/image?url=%2Fimages%2Fblog%2Fannouncing-firestarter-our-open-source-tool-that-turns-any-website-into-a-chatbot%2Fimage.webp&w=3840&q=75&dpl=dpl_2hQ8hmy6vNQsu8DPuBRaRM6deLpr)

Every developer, product manager, and support team has felt this pressure. Your documentation is great, your website is packed with information, but users still ask the same questions over and over.

You know the solution: a smart, AI-powered chatbot that can answer questions based on your content.

But building a production-grade retrieval-augmented generation (RAG) pipeline is a massive undertaking. It involves scraping, cleaning, chunking, embedding, storing, retrieving, and generating. Third-party services can help, but they often come with limitations (like locking you into their ecosystem).

So, we asked ourselves: **What if you could create a production-ready RAG pipeline and a ready-to-use chatbot for any website in under 60 seconds?**

This is the story of Firestarter.

## **Enter a URL. Get a chatbot.**

Firestarter is a complete Next.js chatbot-building platform that we've made as simple as possible. It's a new addition to our [open-source AI toolbox](https://www.firecrawl.dev/blog/fire-enrich), designed to make chatbot creation accessible to everyone:

1. Enter any website URL (e.g., [https://docs.firecrawl.dev](https://docs.firecrawl.dev/))
2. **Click "Start"** and watch as it crawls and indexes the content in real-time
3. **Instantly get** a full-featured chat interface and a developer-ready, OpenAI-compatible API

Behind this simple UI is a sophisticated, pre-built RAG pipeline that handles the entire workflow from raw website to intelligent, queryable data source, powered by Firecrawl for web scraping and Upstash for serverless vector search.

The system is architected to let you build and deploy multiple chatbots based on as many websites as you'd like‚Äîeach one completely independent with its own data namespace and API endpoint.

## **How it works: From website to wisdom**

Firestarter isn't just a simple script; it's a complete, two-phase system for creating and interacting with knowledge bases.

### **Phase 1: The indexing engine**

When you enter a URL, Firestarter kicks off a meticulous process:

1. **Smart Crawling**: It uses Firecrawl to navigate the site, fetching the clean, structured Markdown content of each page. This bypasses the need to deal with raw HTML, ads, and other noise.

\
2. **Intelligent Indexing**: The content is streamed directly to an [Upstash search index](https://upstash.com/docs/search/overall/getstarted). Upstash automatically chunks the text, creates vector embeddings, and stores them in a high-performance, serverless vector database.

\
3. **Namespace Creation**: The entire crawl is isolated under a unique namespace (e.g., firecrawl-dev-1718394041), ensuring each chatbot's data is separate and secure.

\

### **Phase 2: The RAG-Powered Brain**

Once indexed, your chatbot is live. When a user asks a question:

1. **[Semantic Search](https://www.firecrawl.dev/blog/best-semantic-search-apis)**: Firestarter queries the Upstash index, searching for the most relevant document chunks based on the _meaning_ of the question, not just keywords.

\
2. **Context-Aware Prompting**: The most relevant chunks are compiled into a context block. This, along with the original question, is sent to your choice of LLM‚ÄîOpenAI, Anthropic, Groq, or any LLM you like. Built with the Vercel AI SDK, there's full flexibility to customize and use any LLM provider you decide to use.

\
3. **Streaming Response**: The LLM generates the answer, which is streamed back to the UI in real-time using the Vercel AI SDK, providing a smooth, human-like chat experience.

\

**The best part?** Every step is transparent.

And for developers, Firestarter creates something truly special: an **OpenAI-compatible API endpoint** for every single chatbot.

This means you can use the official OpenAI libraries in any language to programmatically query your website's content, treating it like a structured, intelligent database.

## **This is just the beginning**

Production-grade RAG is complex. Our goal with Firestarter isn't to be a closed, perfect-out-of-the-box solution.

Instead, we want to build a powerful, open source foundation that anyone can use, understand, and contribute to.

The version you see in this repository is our first major step. It works, it provides immense value, but we know there's room to grow. By open-sourcing it, we're inviting you to join us on this journey.

### **How you can contribute**

- **Want to add a new vector DB?** Fork the repo and show us what you've got
- **Think the RAG prompt can be improved?** Open a pull request
- **Have an idea for a new feature?** Start a discussion in the issues

We believe that by building in public, we can create a tool that is not only accessible and affordable but also more robust and adaptable, thanks to the collective intelligence of the open-source community.

We built Firestarter with extensibility at its core. Whether you want to swap in your own services, integrate different LLMs, or customize the crawling logic in firestarter.config.ts, we've made it easy to adapt the tool to your specific needs.

## **Get started today**

We invite you to explore Firestarter. See what it can do, and then dive into the code to see how it's done.

- **Try the tool**: [Firestarter Demo](https://tools.firecrawl.dev/firestarter)
- **Explore the code**: [View on GitHub](https://github.com/firecrawl/firestarter)

We built Firestarter to make custom AI chatbots accessible to everyone. No massive engineering teams required. Just enter a URL and get started.

**Let's build the future of intelligent interfaces. Together.**

\[ CTA \]

\[ CRAWL \]

\[ SCRAPE \]

\[ CTA \]

//

Get started

//

Ready to build?

Start getting Web Data for free and scale seamlessly as your project expands. No credit card needed.

[Start for free](https://www.firecrawl.dev/signin) [See our plans](https://www.firecrawl.dev/pricing)

![placeholder](https://www.firecrawl.dev/_next/image?url=%2Fblog%2Fauthors%2Feric-img.jpeg&w=128&q=75&dpl=dpl_2hQ8hmy6vNQsu8DPuBRaRM6deLpr)

Eric Ciarla [@ericciarla](https://x.com/ericciarla)

CMO of Firecrawl

About the Author

Eric Ciarla is the cofounder and Chief Marketing Officer (CMO) of Firecrawl. He also worked on Mendable.ai and sold it to companies like Snapchat, Coinbase, and MongoDB. Previously worked at Ford and Fracta as a Data Scientist. Eric also co-founded SideGuide, a tool for learning code within VS Code with 50,000 users.

More articles by Eric Ciarla

[Extract Web Data at Scale With Parallel Agents](https://www.firecrawl.dev/blog/introducing-parallel-agents) [Introducing the Firecrawl Skill and CLI - Give Agents Real-Time Web Data](https://www.firecrawl.dev/blog/introducing-firecrawl-skill-and-cli) [How Credal Extracts 6M+ URLs Monthly to Power Production AI Agents](https://www.firecrawl.dev/blog/credal-firecrawl-ai-agents) [How to Create an llms.txt File for Any Website](https://www.firecrawl.dev/blog/How-to-Create-an-llms-txt-File-for-Any-Website) [Introducing Spark 1 Pro and Spark 1 Mini](https://www.firecrawl.dev/blog/introducing-spark-1) [Introducing /agent: Gather Data Wherever It Lives on the Web](https://www.firecrawl.dev/blog/introducing-agent) [Retell‚Äôs AI phone agents get LLM-ready content from Firecrawl](https://www.firecrawl.dev/blog/retell-firecrawl-ai-phone-agents) [Introducing Firecrawl v2.5 - The World's Best Web Data API](https://www.firecrawl.dev/blog/the-worlds-best-web-data-api-v25) [Why Firecrawl Beats Octoparse for AI Web Scraping](https://www.firecrawl.dev/blog/firecrawl-vs-octoparse-data-extraction) [Introducing Firecrawl Observer, Our Open-Source Website Monitoring Tool](https://www.firecrawl.dev/blog/introducing-firecrawl-observer)

FOOTER

The easiest way to extract

data from the web

Backed by

Y Combinator

[Linkedin](https://www.linkedin.com/company/firecrawl) [Github](https://github.com/firecrawl/firecrawl) [YouTube](https://www.youtube.com/@Firecrawl_dev)

SOC II ¬∑ Type 2

AICPA

SOC 2

[X (Twitter)](https://x.com/firecrawl) [Discord](https://discord.gg/gSmWdAkdwd)

Products

[Playground](https://www.firecrawl.dev/playground) [Agent](https://www.firecrawl.dev/agent) [Pricing](https://www.firecrawl.dev/pricing) [Templates](https://www.firecrawl.dev/templates) [Changelog](https://www.firecrawl.dev/changelog)

Use Cases

[AI Platforms](https://www.firecrawl.dev/use-cases/ai-platforms) [Lead Enrichment](https://www.firecrawl.dev/use-cases/lead-enrichment) [SEO Teams](https://www.firecrawl.dev/use-cases/seo-teams) [Deep Research](https://www.firecrawl.dev/use-cases/deep-research) [Competitive Intelligence](https://www.firecrawl.dev/use-cases/competitive-intelligence)

Documentation

[Getting started](https://docs.firecrawl.dev/introduction) [API Reference](https://docs.firecrawl.dev/api-reference/introduction) [Integrations](https://www.firecrawl.dev/app) [Examples](https://docs.firecrawl.dev/use-cases/overview) [SDKs](https://docs.firecrawl.dev/sdks/overview)

Company

[Blog](https://www.firecrawl.dev/blog) [Careers](https://www.firecrawl.dev/careers) [Creator & OSS program](https://www.firecrawl.dev/creator-oss-program) [Student program](https://www.firecrawl.dev/student-program)

¬© 2025 Firecrawl

[Terms of Service](https://www.firecrawl.dev/terms-of-service) [Privacy Policy](https://www.firecrawl.dev/privacy-policy) [Report Abuse](mailto:help@firecrawl.com?subject=Issue:)

[All systems normal](https://status.firecrawl.dev/)

## CSS Selectors in Scraping
Introducing the Firecrawl Skill + CLI for Agents. [Learn more ‚Üí](https://docs.firecrawl.dev/sdks/cli)

//

Get started

//

### Ready to build?

Start getting Web Data for free and scale seamlessly as your project expands. No credit card needed.

[Start for free](https://www.firecrawl.dev/signin) [See our plans](https://www.firecrawl.dev/pricing)

#### All Questions

[Glossary](https://www.firecrawl.dev/glossary)/ [Web Extraction APIs](https://www.firecrawl.dev/glossary/web-extraction-apis)/Questions

[How can I extract data from tables, lists, and nested HTML structures?](https://www.firecrawl.dev/glossary/web-extraction-apis/extract-data-tables-lists-nested-html-structures)

# What is a CSS selector in web scraping?

## TL;DR

CSS selectors let you pinpoint specific HTML elements on a webpage to extract their data. Instead of parsing an entire page, you use patterns like `.product-title` or `#price` to grab exactly what you need. This makes your scraper faster, more reliable, and easier to maintain when website structures change.

## What is a CSS selector in web scraping?

A CSS selector is a pattern that identifies specific HTML elements on a webpage for data extraction. Originally designed for styling websites, CSS selectors provide a clean syntax for navigating HTML structure. Web scrapers use these same patterns with [HTML parsers](https://www.firecrawl.dev/glossary/web-extraction-apis/what-is-html-parser) to locate and extract text, prices, images, links, or any other data nested within page elements.

## Common CSS Selectors for Web Scraping

| Selector | Example | What It Targets |
| --- | --- | --- |
| `.class` | `.product-title` | Elements with specific class |
| `#id` | `#price` | Element with specific ID |
| `element` | `h1` or `div` | All elements of that type |
| `element.class` | `h4.card-title` | Specific element with class |
| `[attribute]` | `[href]` | Elements with that attribute |
| `parent > child` | `div > h4` | Direct child elements |
| `parent descendant` | `div p` | Any nested descendant |

## Why CSS Selectors Matter for Scraping

CSS selectors make web scraping more precise and maintainable. When you target elements by class or ID instead of position, your scraper survives minor page layout changes. A selector like `h4.price` is far more resilient than grabbing the fourth paragraph element.

The syntax is readable and concise. A single line like `response.css('div.product > h4.title::text')` clearly shows you're extracting title text from product divs. This makes debugging easier and helps team members understand your extraction logic quickly.

Most scraping libraries support CSS selectors natively. [BeautifulSoup](https://www.crummy.com/software/BeautifulSoup/bs4/doc/), Scrapy, Puppeteer, and Selenium all provide built-in CSS selector support. This consistency across tools means your selector knowledge transfers between projects and programming languages.

Learn more: [MDN CSS Selectors Reference](https://developer.mozilla.org/en-US/docs/Web/CSS/CSS_Selectors)

## When CSS Selectors Fall Short

CSS selectors cannot traverse upward to parent elements or select elements by their text content. If you need to find a product container based on inner text or navigate from child to parent, you'll need [XPath selectors](https://www.firecrawl.dev/glossary/web-extraction-apis/what-is-xpath-selector-in-web-scraping) instead. CSS also struggles with complex conditions like selecting elements based on sibling count or depth in the document tree.

Dynamic websites that load content via [JavaScript rendering](https://www.firecrawl.dev/glossary/web-scraping-apis/what-is-javascript-rendering-web-scraping) require waiting for elements to appear. CSS selectors alone can't handle timing, you need to combine them with wait conditions or use headless browser tools that support dynamic content rendering.

## Key Takeaways

CSS selectors provide a simple, readable way to extract specific data from web pages. They work by targeting HTML elements through patterns based on classes, IDs, attributes, and element relationships. While CSS selectors handle most scraping tasks efficiently, complex scenarios like parent navigation or text-based selection require [XPath selectors](https://www.firecrawl.dev/glossary/web-extraction-apis/what-is-xpath-selector-in-web-scraping). Choose CSS selectors for speed and simplicity, switch to XPath when you need more power.

Last updated: Jan 26, 2026

\[ CTA \]

\[ CRAWL \]

\[ SCRAPE \]

\[ CTA \]

//

Get started

//

Ready to build?

Start getting Web Data for free and scale seamlessly as your project expands. No credit card needed.

[Start for free](https://www.firecrawl.dev/signin) [See our plans](https://www.firecrawl.dev/pricing)

FOOTER

The easiest way to extract

data from the web

Backed by

Y Combinator

[Linkedin](https://www.linkedin.com/company/firecrawl) [Github](https://github.com/firecrawl/firecrawl) [YouTube](https://www.youtube.com/@Firecrawl_dev)

SOC II ¬∑ Type 2

AICPA

SOC 2

[X (Twitter)](https://x.com/firecrawl) [Discord](https://discord.gg/gSmWdAkdwd)

Products

[Playground](https://www.firecrawl.dev/playground) [Agent](https://www.firecrawl.dev/agent) [Pricing](https://www.firecrawl.dev/pricing) [Templates](https://www.firecrawl.dev/templates) [Changelog](https://www.firecrawl.dev/changelog)

Use Cases

[AI Platforms](https://www.firecrawl.dev/use-cases/ai-platforms) [Lead Enrichment](https://www.firecrawl.dev/use-cases/lead-enrichment) [SEO Teams](https://www.firecrawl.dev/use-cases/seo-teams) [Deep Research](https://www.firecrawl.dev/use-cases/deep-research) [Competitive Intelligence](https://www.firecrawl.dev/use-cases/competitive-intelligence)

Documentation

[Getting started](https://docs.firecrawl.dev/introduction) [API Reference](https://docs.firecrawl.dev/api-reference/introduction) [Integrations](https://www.firecrawl.dev/app) [Examples](https://docs.firecrawl.dev/use-cases/overview) [SDKs](https://docs.firecrawl.dev/sdks/overview)

Company

[Blog](https://www.firecrawl.dev/blog) [Careers](https://www.firecrawl.dev/careers) [Creator & OSS program](https://www.firecrawl.dev/creator-oss-program) [Student program](https://www.firecrawl.dev/student-program)

¬© 2025 Firecrawl

[Terms of Service](https://www.firecrawl.dev/terms-of-service) [Privacy Policy](https://www.firecrawl.dev/privacy-policy) [Report Abuse](mailto:help@firecrawl.com?subject=Issue:)

[All systems normal](https://status.firecrawl.dev/)

## Enterprise Data Solutions
Introducing the Firecrawl Skill + CLI for Agents. [Learn more ‚Üí](https://docs.firecrawl.dev/sdks/cli)

//

Enterprise Solutions

//

# Scale with confidence

Enterprise-grade reliability and scale for mission-critical applications.

Trusted by leading companies worldwide.

[Contact sales](https://fk4bvu0n5qp.typeform.com/to/Ej6oydlg) [Explore docs](https://www.firecrawl.dev/docs)

Trusted by leading

enterprises worldwide

![Logo 1](https://www.firecrawl.dev/assets-original/logocloud-enterprise/1.png)

![Logo 2](https://www.firecrawl.dev/assets-original/logocloud-enterprise/2.png)

![Logo 3](https://www.firecrawl.dev/assets-original/logocloud-enterprise/3.png)

![Logo 4](https://www.firecrawl.dev/assets-original/logocloud-enterprise/4.png)

![Logo 5](https://www.firecrawl.dev/assets-original/logocloud-enterprise/5.png)

![Logo 6](https://www.firecrawl.dev/assets-original/logocloud-enterprise/6.png)

![Logo 1](https://www.firecrawl.dev/assets-original/logocloud-enterprise/1.png)

![Logo 2](https://www.firecrawl.dev/assets-original/logocloud-enterprise/2.png)

![Logo 3](https://www.firecrawl.dev/assets-original/logocloud-enterprise/3.png)

![Logo 4](https://www.firecrawl.dev/assets-original/logocloud-enterprise/4.png)

![Logo 5](https://www.firecrawl.dev/assets-original/logocloud-enterprise/5.png)

![Logo 6](https://www.firecrawl.dev/assets-original/logocloud-enterprise/6.png)

\[ 01 / 04 \]

¬∑

Enterprise Features

### Core Features

Available across all tiers

API and MCP access

Markdown & JSON extraction

Crawl, Scrape, Map, Search operations

Email and live chat support

Basic dashboard analytics

### Scale Features

Enhanced capabilities for growing teams

100-150 concurrent browsers

Dedicated Slack channel

Cost-effective auto-charge packs

Up to 2x monthly rollover cap

Advanced dashboard analytics

### Enterprise Features

Maximum performance and security

Custom concurrent browsers

Priority support SLA

Zero-data retention

Whitelisted IP addresses

Up to 3x monthly rollover cap

\[ 02 / 04 \]

¬∑

Security & Compliance

### Enterprise Security & Compliance

Your data security is our top priority. We maintain the highest standards of protection with industry-leading certifications and comprehensive security measures.

AICPA

SOC 2

#### SOC 2 Type II Certified

Independently audited security controls ensuring the highest standards of data protection and operational security

#### Zero Day Retention

Your data is processed and immediately deleted. We don't store your scraped content, ensuring complete privacy and compliance with strict data retention policies.

\[ 03 / 04 \]

¬∑

Auto-Charge Packs

### Never Run Out of Credits

Auto-charge packs ensure your applications never stop working. Automatic credit purchasing with volume discounts and seamless billing.

#### How It Works

1

##### Low Balance Detection

System monitors your credit balance automatically

2

##### Auto-Purchase Triggered

Credit pack is purchased when threshold is reached

3

##### Instant Credit Addition

Credits are immediately added to your account

4

##### Continued Operation

Your services continue without interruption

#### Key Benefits

##### Automatic Activation

Credits are automatically purchased when balance is low

##### Volume Discounts

Get better rates with bulk credit purchases

##### No Service Interruption

Your applications keep running without downtime

##### 12-Month Validity

All auto-charged credits are valid for a full year

\[ 04 / 04 \]

¬∑

Customer Testimonials

### What Our Enterprise Customers Say

See how leading companies use Firecrawl to power their mission-critical applications.

[![Andrew Gardner](https://www.firecrawl.dev/assets-original/testimonials/andrew-gardner.png)\\
\\
Andrew Gardner\\
\\
Sr. Engineer, Zapier\\
\\
> "Firecrawl allows our customers to pull the web information they need directly in our product."](https://www.firecrawl.dev/blog/how-zapier-uses-firecrawl-to-power-chatbots) [![Michael Masson](https://www.firecrawl.dev/assets-original/testimonials/michael-masson.png)\\
\\
Michael Masson\\
\\
Director of Engineering, Botpress\\
\\
> "Firecrawl is the easiest way to extract relevant content from a website."](https://www.firecrawl.dev/blog/how-botpress-enhances-knowledge-base-creation-with-firecrawl) [![Zhen Li](https://www.firecrawl.dev/assets-original/testimonials/zhen-li.png)\\
\\
Zhen Li\\
\\
Staff AI Engineer, Replit\\
\\
> "If your agent or LLM needs web content, Firecrawl delivers the best-formatted results."](https://www.firecrawl.dev/blog/how-replit-uses-firecrawl-to-power-ai-agents)

### We'd love to chat!

Join leading companies who trust Firecrawl for their mission-critical data extraction needs. Get enterprise-grade reliability, security, and support.

[Contact sales](https://fk4bvu0n5qp.typeform.com/to/Ej6oydlg) [Explore docs](https://www.firecrawl.dev/docs)

FOOTER

The easiest way to extract

data from the web

Backed by

Y Combinator

[Linkedin](https://www.linkedin.com/company/firecrawl) [Github](https://github.com/firecrawl/firecrawl) [YouTube](https://www.youtube.com/@Firecrawl_dev)

SOC II ¬∑ Type 2

AICPA

SOC 2

[X (Twitter)](https://x.com/firecrawl) [Discord](https://discord.gg/gSmWdAkdwd)

Products

[Playground](https://www.firecrawl.dev/playground) [Agent](https://www.firecrawl.dev/agent) [Pricing](https://www.firecrawl.dev/pricing) [Templates](https://www.firecrawl.dev/templates) [Changelog](https://www.firecrawl.dev/changelog)

Use Cases

[AI Platforms](https://www.firecrawl.dev/use-cases/ai-platforms) [Lead Enrichment](https://www.firecrawl.dev/use-cases/lead-enrichment) [SEO Teams](https://www.firecrawl.dev/use-cases/seo-teams) [Deep Research](https://www.firecrawl.dev/use-cases/deep-research) [Competitive Intelligence](https://www.firecrawl.dev/use-cases/competitive-intelligence)

Documentation

[Getting started](https://docs.firecrawl.dev/introduction) [API Reference](https://docs.firecrawl.dev/api-reference/introduction) [Integrations](https://www.firecrawl.dev/app) [Examples](https://docs.firecrawl.dev/use-cases/overview) [SDKs](https://docs.firecrawl.dev/sdks/overview)

Company

[Blog](https://www.firecrawl.dev/blog) [Careers](https://www.firecrawl.dev/careers) [Creator & OSS program](https://www.firecrawl.dev/creator-oss-program) [Student program](https://www.firecrawl.dev/student-program)

¬© 2025 Firecrawl

[Terms of Service](https://www.firecrawl.dev/terms-of-service) [Privacy Policy](https://www.firecrawl.dev/privacy-policy) [Report Abuse](mailto:help@firecrawl.com?subject=Issue:)

[All systems normal](https://status.firecrawl.dev/)

## Proxy in Web Scraping
Introducing Parallel Agents - Run multiple /agent queries simultaneously. [Read more ‚Üí](https://www.firecrawl.dev/blog/introducing-parallel-agents)

//

Get started

//

### Ready to build?

Start getting Web Data for free and scale seamlessly as your project expands. No credit card needed.

[Start for free](https://www.firecrawl.dev/signin) [See our plans](https://www.firecrawl.dev/pricing)

#### All Questions

[Glossary](https://www.firecrawl.dev/glossary)/ [Web Scraping APIs](https://www.firecrawl.dev/glossary/web-scraping-apis)/Questions

[What is a CSS selector in web scraping?](https://www.firecrawl.dev/glossary/web-scraping-apis/what-is-css-selector-web-scraping)

[What is a residential proxy vs datacenter proxy?](https://www.firecrawl.dev/glossary/web-scraping-apis/what-is-residential-proxy-vs-datacenter-proxy)

# What is a proxy in web scraping?

## TL;DR

A proxy in web scraping is an intermediary server that routes your requests through different IP addresses, distributing load and managing geographic requirements. Proxies help distribute requests across multiple addresses, access geo-specific content by using IPs from specific regions, and enable high-volume scraping with proper rate limit management. Residential proxies provide authentic geographic presence while datacenter proxies offer speed and affordability for most scraping projects.

## What Is a Proxy in Web Scraping?

A [proxy server](https://en.wikipedia.org/wiki/Proxy_server) acts as a gateway between your scraper and target websites. When you send a request through a proxy, the website sees the proxy's IP address instead of yours. This intermediary layer allows you to make requests appear as if they come from different users or locations.

Without proxies, scraping at scale quickly leads to IP bans. Websites track request patterns and block addresses making too many requests too quickly through [detection systems](https://www.firecrawl.dev/glossary/web-scraping-apis/how-do-websites-detect-web-scrapers). A proxy pool distributes those requests across dozens or thousands of different IP addresses, making detection significantly harder and maintaining access to target sites.

## Core Proxy Types

Residential proxies use IP addresses assigned to real homes by internet service providers. These provide authentic geographic presence for accessing region-specific content. Residential proxies cost more but offer higher reliability for accessing complex web infrastructure.

Datacenter proxies come from cloud hosting providers and data centers rather than residential networks. They're faster, cheaper, and more stable than residential options but easier for websites to identify and block. For most scraping projects, datacenter proxies with proper rotation provide excellent value. Learn more about [residential vs datacenter proxy differences](https://www.firecrawl.dev/glossary/web-extraction-apis/what-is-residential-proxy-vs-datacenter-proxy).

Mobile proxies route requests through cellular networks using IP addresses from mobile carriers. These are the most expensive option but nearly impossible to block since websites can't ban entire mobile carrier IP ranges without affecting legitimate users.

## Why Proxies Matter for Web Scraping

Rate limits restrict how many requests a single IP can make within a timeframe. Without proxies, scrapers hit these limits quickly, especially when extracting data from thousands of pages, often triggering [429 rate limit errors](https://www.firecrawl.dev/glossary/web-scraping-apis/what-is-429-error-web-scraping). Proxy rotation spreads requests across many IPs, staying well below per-IP rate limits while maintaining overall throughput.

Geo-specific content varies based on location. Many websites show different content based on visitor geography. Proxies with IPs from specific countries enable access to region-specific pricing, availability, or content variations for legitimate data collection.

Rate limits and access restrictions can affect individual IP addresses. Proxy pools provide redundancy and load distribution, ensuring continuous operation for legitimate data collection projects.

## Proxy Pool Management

Effective proxy usage requires managing [pools of IP addresses](https://www.zyte.com/learn/use-proxies-for-web-scraping/) rather than single proxies. A pool contains hundreds or thousands of IPs that rotate for each request or session. This distribution prevents any single IP from bearing excessive load and triggering detection.

Rotation strategies vary by use case. Some scrapers change IPs with every request for maximum anonymity. Others maintain sticky sessions using the same IP for related requests, necessary when scraping sites requiring login or session continuity.

Health monitoring tracks which proxies work and which get blocked. Failed requests indicate burnt proxies that need removal from rotation. Proxy management systems automatically test IPs, detect bans through response patterns, and cycle out problematic addresses while routing traffic to healthy proxies.

## Choosing Between Proxy Types

Use residential proxies when accessing sites with complex infrastructure like social media platforms, classified sites, or high-traffic retailers. The premium cost pays off through higher reliability and authentic geographic presence.

Choose datacenter proxies for general web scraping where speed and cost matter more than perfect anonymity. E-commerce price monitoring, search engine result tracking, and news aggregation work well with datacenter proxies paired with proper rotation and request spacing.

Consider proxy services or APIs that handle rotation, monitoring, and replacement automatically. Building custom proxy management systems consumes engineering time better spent on extraction logic and data processing.

## Key Takeaways

Proxies route scraping requests through different IP addresses, distributing load and enabling access to geo-specific content. Residential proxies provide authentic geographic presence but cost more, while datacenter proxies offer speed and affordability for most projects. Proxy pools with hundreds of IPs distribute requests to manage rate limits and provide redundancy. Effective proxy management requires rotation strategies, health monitoring, and automatic IP cycling. Choose residential proxies for sites with complex infrastructure and datacenter proxies for general scraping where cost and speed matter. Proxy services that handle rotation and monitoring automatically save significant development time compared to building custom management systems.

Last updated: Jan 26, 2026

\[ CTA \]

\[ CRAWL \]

\[ SCRAPE \]

\[ CTA \]

//

Get started

//

Ready to build?

Start getting Web Data for free and scale seamlessly as your project expands. No credit card needed.

[Start for free](https://www.firecrawl.dev/signin) [See our plans](https://www.firecrawl.dev/pricing)

FOOTER

The easiest way to extract

data from the web

Backed by

Y Combinator

[Linkedin](https://www.linkedin.com/company/firecrawl) [Github](https://github.com/firecrawl/firecrawl) [YouTube](https://www.youtube.com/@Firecrawl_dev)

SOC II ¬∑ Type 2

AICPA

SOC 2

[X (Twitter)](https://x.com/firecrawl) [Discord](https://discord.gg/gSmWdAkdwd)

Products

[Playground](https://www.firecrawl.dev/playground) [Agent](https://www.firecrawl.dev/agent) [Pricing](https://www.firecrawl.dev/pricing) [Templates](https://www.firecrawl.dev/templates) [Changelog](https://www.firecrawl.dev/changelog)

Use Cases

[AI Platforms](https://www.firecrawl.dev/use-cases/ai-platforms) [Lead Enrichment](https://www.firecrawl.dev/use-cases/lead-enrichment) [SEO Teams](https://www.firecrawl.dev/use-cases/seo-teams) [Deep Research](https://www.firecrawl.dev/use-cases/deep-research) [Competitive Intelligence](https://www.firecrawl.dev/use-cases/competitive-intelligence)

Documentation

[Getting started](https://docs.firecrawl.dev/introduction) [API Reference](https://docs.firecrawl.dev/api-reference/introduction) [Integrations](https://www.firecrawl.dev/app) [Examples](https://docs.firecrawl.dev/use-cases/overview) [SDKs](https://docs.firecrawl.dev/sdks/overview)

Company

[Blog](https://www.firecrawl.dev/blog) [Careers](https://www.firecrawl.dev/careers) [Creator & OSS program](https://www.firecrawl.dev/creator-oss-program) [Student program](https://www.firecrawl.dev/student-program)

¬© 2025 Firecrawl

[Terms of Service](https://www.firecrawl.dev/terms-of-service) [Privacy Policy](https://www.firecrawl.dev/privacy-policy) [Report Abuse](mailto:help@firecrawl.com?subject=Issue:)

[All systems normal](https://status.firecrawl.dev/)

## Web Integration Solutions
Introducing the Firecrawl Skill + CLI for Agents. [Learn more ‚Üí](https://docs.firecrawl.dev/sdks/cli)

# Find an Integration

Use your favorite tools with Firecrawl.

Categories

## Featured

3 featured

[Claude\\
\\
Claude Code\\
\\
Add web scraping to Claude Code.](https://www.firecrawl.dev/integrations/mcp/claude-code) [Cursor\\
\\
Cursor\\
\\
Add web scraping to Cursor.](https://www.firecrawl.dev/integrations/mcp/cursor) [n8n\\
\\
n8n\\
\\
Build custom workflows with visual automation.](https://www.firecrawl.dev/integrations/workflow-automation/n8n)

## AI Development

8

[Anthropic\\
\\
Anthropic Claude\\
\\
Build AI agents with web data access.](https://docs.firecrawl.dev/developer-guides/llm-sdks-and-frameworks/anthropic) [Gemini\\
\\
Google Gemini\\
\\
Integrate web scraping with Gemini AI.](https://docs.firecrawl.dev/developer-guides/llm-sdks-and-frameworks/gemini) [LangChain\\
\\
LangChain\\
\\
Python and JavaScript document loaders for RAG applications.](https://docs.firecrawl.dev/developer-guides/llm-sdks-and-frameworks/langchain) [LangGraph\\
\\
LangGraph\\
\\
Build agentic workflows with web data.](https://docs.firecrawl.dev/developer-guides/llm-sdks-and-frameworks/langgraph) [LlamaIndex\\
\\
LlamaIndex\\
\\
Data connector for building knowledge bases.](https://docs.firecrawl.dev/developer-guides/llm-sdks-and-frameworks/llamaindex) [Mastra\\
\\
Mastra\\
\\
Build intelligent workflows.](https://docs.firecrawl.dev/developer-guides/llm-sdks-and-frameworks/mastra) [OpenAI\\
\\
OpenAI\\
\\
Web scraping workflows with GPT models.](https://docs.firecrawl.dev/developer-guides/llm-sdks-and-frameworks/openai) [Vercel\\
\\
Vercel AI SDK\\
\\
Stream AI responses with web context.](https://docs.firecrawl.dev/developer-guides/llm-sdks-and-frameworks/vercel-ai-sdk)

## Workflow Automation

4

[Dify\\
\\
Dify\\
\\
Build AI applications with no-code workflows.](https://www.firecrawl.dev/integrations/workflow-automation/dify) [Make\\
\\
Make\\
\\
Create powerful integrations with drag-and-drop.](https://www.firecrawl.dev/integrations/workflow-automation/make) [n8n\\
\\
n8n\\
\\
Build custom workflows with visual automation.](https://www.firecrawl.dev/integrations/workflow-automation/n8n) [Zapier\\
\\
Zapier\\
\\
Connect Firecrawl with 7,000+ apps via Zapier automation.](https://www.firecrawl.dev/integrations/workflow-automation/zapier)

## MCP

33

[Claude\\
\\
Claude Code\\
\\
Add web scraping to Claude Code.](https://www.firecrawl.dev/integrations/mcp/claude-code) [Claude\\
\\
Claude Desktop\\
\\
Setup Firecrawl on Claude Desktop.](https://docs.firecrawl.dev/mcp-server) [Cline\\
\\
Cline\\
\\
Enhance Cline with Firecrawl.](https://docs.firecrawl.dev/mcp-server) [Cursor\\
\\
Cursor\\
\\
Add web scraping to Cursor.](https://www.firecrawl.dev/integrations/mcp/cursor) [Gemini\\
\\
Gemini CLI\\
\\
Integrate with Gemini CLI.](https://docs.firecrawl.dev/mcp-server) [OpenAI\\
\\
OpenAI Codex\\
\\
Integrate with OpenAI Codex.](https://docs.firecrawl.dev/mcp-server) [Qwen\\
\\
Qwen Coder\\
\\
Add web scraping to Qwen Coder.](https://docs.firecrawl.dev/mcp-server) [Smithery\\
\\
Smithery\\
\\
Install Firecrawl MCP via Smithery.](https://docs.firecrawl.dev/mcp-server) [Github\\
\\
VS Code\\
\\
Add web scraping to VS Code.](https://docs.firecrawl.dev/mcp-server) [Windsurf\\
\\
Windsurf\\
\\
Integrate with Windsurf editor.](https://www.firecrawl.dev/integrations/mcp/windsurf) [Amazon Q Developer CLI\\
\\
Integrate with Amazon Q.](https://docs.firecrawl.dev/mcp-server) [Amp\\
\\
Enhance Amp with Firecrawl.](https://docs.firecrawl.dev/mcp-server) [Augment Code\\
\\
Enhance Augment Code with Firecrawl.](https://docs.firecrawl.dev/mcp-server) [BoltAI\\
\\
Add web scraping to BoltAI.](https://docs.firecrawl.dev/mcp-server) [Bun or Deno\\
\\
Setup with Bun or Deno.](https://docs.firecrawl.dev/mcp-server) [Copilot Coding Agent\\
\\
Enhance Copilot with Firecrawl.](https://docs.firecrawl.dev/mcp-server) [Crush\\
\\
Enhance Crush with Firecrawl.](https://docs.firecrawl.dev/mcp-server) [Desktop Extension\\
\\
Use the Desktop Extension.](https://docs.firecrawl.dev/mcp-server) [Docker\\
\\
Deploy with Docker.](https://docs.firecrawl.dev/mcp-server) [JetBrains AI Assistant\\
\\
Add web scraping to JetBrains.](https://docs.firecrawl.dev/mcp-server) [Kiro\\
\\
Enhance Kiro with Firecrawl.](https://docs.firecrawl.dev/mcp-server) [LM Studio\\
\\
Integrate with LM Studio.](https://docs.firecrawl.dev/mcp-server) [Opencode\\
\\
Add web scraping to Opencode.](https://docs.firecrawl.dev/mcp-server) [Perplexity Desktop\\
\\
Add web scraping to Perplexity.](https://docs.firecrawl.dev/mcp-server) [Qodo Gen\\
\\
Enhance Qodo Gen with Firecrawl.](https://docs.firecrawl.dev/mcp-server) [Roo Code\\
\\
Add web scraping to Roo Code.](https://docs.firecrawl.dev/mcp-server) [Rovo Dev CLI\\
\\
Integrate with Rovo Dev CLI.](https://docs.firecrawl.dev/mcp-server) [Trae\\
\\
Add web scraping to Trae.](https://docs.firecrawl.dev/mcp-server) [Visual Studio\\
\\
Add web scraping to Visual Studio.](https://docs.firecrawl.dev/mcp-server) [Warp\\
\\
Add web scraping to Warp.](https://docs.firecrawl.dev/mcp-server) [Windows\\
\\
Setup on Windows.](https://docs.firecrawl.dev/mcp-server) [Zed\\
\\
Add web scraping to Zed.](https://docs.firecrawl.dev/mcp-server) [Zencoder\\
\\
Add web scraping to Zencoder.](https://docs.firecrawl.dev/mcp-server)

\[ CTA \]

\[ CRAWL \]

\[ SCRAPE \]

\[ CTA \]

//

Partner with us

//

Ready to partner?

Join our integration ecosystem and help developers build powerful applications with clean web data.

[Get in touch](mailto:eric@firecrawl.dev)

FOOTER

The easiest way to extract

data from the web

Backed by

Y Combinator

[Linkedin](https://www.linkedin.com/company/firecrawl) [Github](https://github.com/firecrawl/firecrawl) [YouTube](https://www.youtube.com/@Firecrawl_dev)

SOC II ¬∑ Type 2

AICPA

SOC 2

[X (Twitter)](https://x.com/firecrawl) [Discord](https://discord.gg/gSmWdAkdwd)

Products

[Playground](https://www.firecrawl.dev/playground) [Agent](https://www.firecrawl.dev/agent) [Pricing](https://www.firecrawl.dev/pricing) [Templates](https://www.firecrawl.dev/templates) [Changelog](https://www.firecrawl.dev/changelog)

Use Cases

[AI Platforms](https://www.firecrawl.dev/use-cases/ai-platforms) [Lead Enrichment](https://www.firecrawl.dev/use-cases/lead-enrichment) [SEO Teams](https://www.firecrawl.dev/use-cases/seo-teams) [Deep Research](https://www.firecrawl.dev/use-cases/deep-research) [Competitive Intelligence](https://www.firecrawl.dev/use-cases/competitive-intelligence)

Documentation

[Getting started](https://docs.firecrawl.dev/introduction) [API Reference](https://docs.firecrawl.dev/api-reference/introduction) [Integrations](https://www.firecrawl.dev/app) [Examples](https://docs.firecrawl.dev/use-cases/overview) [SDKs](https://docs.firecrawl.dev/sdks/overview)

Company

[Blog](https://www.firecrawl.dev/blog) [Careers](https://www.firecrawl.dev/careers) [Creator & OSS program](https://www.firecrawl.dev/creator-oss-program) [Student program](https://www.firecrawl.dev/student-program)

¬© 2025 Firecrawl

[Terms of Service](https://www.firecrawl.dev/terms-of-service) [Privacy Policy](https://www.firecrawl.dev/privacy-policy) [Report Abuse](mailto:help@firecrawl.com?subject=Issue:)

[All systems normal](https://status.firecrawl.dev/)

## Crawl Delay Explanation
Introducing the Firecrawl Skill + CLI for Agents. [Learn more ‚Üí](https://docs.firecrawl.dev/sdks/cli)

//

Get started

//

### Ready to build?

Start getting Web Data for free and scale seamlessly as your project expands.No credit card needed.

[Start for free](https://www.firecrawl.dev/signin) [See our plans](https://www.firecrawl.dev/pricing)

#### All Questions

[Glossary](https://www.firecrawl.dev/glossary)/ [Web Crawling APIs](https://www.firecrawl.dev/glossary/web-crawling-apis)/Questions

[What is crawl budget?](https://www.firecrawl.dev/glossary/web-crawling-apis/what-is-crawl-budget)

[What is deep research in web scraping?](https://www.firecrawl.dev/glossary/web-crawling-apis/what-is-deep-research-web-scraping)

# What is crawl delay?

## TL;DR

Crawl delay is an unofficial [robots.txt](https://www.firecrawl.dev/glossary/web-crawling-apis/what-is-robots-txt-protocol) directive that tells [web crawlers](https://www.firecrawl.dev/glossary/web-crawling-apis/how-does-a-web-crawler-work) how many seconds to wait between page requests. It prevents server overload by spacing out crawler visits, though major search engines like Google ignore this directive entirely. Bing and Yandex support crawl delay with different interpretations, making it an inconsistent but sometimes useful tool for managing crawler traffic on resource-limited servers.

## What Is Crawl Delay?

Crawl delay is a time-based directive in robots.txt files that instructs crawlers to pause between successive requests. The directive appears as Crawl-delay followed by a number representing seconds. Website owners use this to throttle aggressive crawlers that might overwhelm server resources.

The directive enforces [politeness](https://www.firecrawl.dev/glossary/web-crawling-apis/what-is-polite-crawling) by spacing crawler requests, protecting servers from excessive load. However, its unofficial status means crawler support varies widely with different interpretations across search engines.

## How Different Crawlers Interpret Crawl Delay

[Google ignores the crawl delay directive](https://developers.google.com/search/blog/2017/01/what-crawl-budget-means-for-googlebot) completely. Google crawlers determine their own request rates based on server response times and don't honor robots.txt timing instructions. Website owners must use Google Search Console to adjust Googlebot's crawl rate instead.

Bing interprets crawl delay as [time windows](https://blogs.bing.com/webmaster/2012/05/03/to-crawl-or-not-to-crawl-that-is-bingbots-question/). A setting of Crawl-delay 10 creates ten-second windows where Bingbot crawls maximum one page per window. This effectively limits Bing to approximately 8,640 pages daily. Bing also provides crawl rate controls through Bing Webmaster Tools.

Yandex treats the number as minimum seconds between requests. Setting Crawl-delay 10 means Yandex waits at least ten seconds before requesting the next URL. Like Bing, Yandex offers webmaster tools for managing crawl rates that override robots.txt settings.

## When to Use Crawl Delay

Use crawl delay on resource-limited shared servers where crawler traffic causes performance issues. If multiple crawlers simultaneously accessing your site leads to slowdowns, crawl delay provides temporary relief by spreading requests over longer periods.

Sites experiencing server stress can throttle non-essential crawlers while allowing trusted bots unrestricted access. This prioritizes [crawl budget](https://www.firecrawl.dev/glossary/web-crawling-apis/what-is-crawl-budget) for search engines driving actual traffic. Avoid crawl delay on sites needing fast indexing, as delays mean fewer pages crawled daily.

## Alternatives and Better Solutions

Upgrade server resources to handle crawler traffic efficiently rather than using crawl delay. Better hosting with adequate bandwidth eliminates the need for request throttling.

For Google, return HTTP 503 or 429 status codes temporarily during server issues, or file overcrawling reports through Google Search Console. Use webmaster tools from major search engines to set crawl rates centrally with more reliable results than robots.txt directives.

## Key Takeaways

Crawl delay is an unofficial robots.txt directive specifying wait time between crawler requests, designed to prevent server overload. Major search engines interpret it inconsistently with Google ignoring it completely, Bing using time windows, and Yandex treating it as minimum wait time. Use crawl delay only on resource-limited servers experiencing genuine crawler-related performance issues. Better solutions include upgrading hosting, using search engine webmaster tools for official crawl rate controls, or returning appropriate HTTP status codes during server stress. For most modern websites with adequate hosting, crawl delay is unnecessary and potentially harmful to indexing speed.

Last updated: Jan 26, 2026

\[ CTA \]

\[ CRAWL \]

\[ SCRAPE \]

\[ CTA \]

//

Get started

//

Ready to build?

Start getting Web Data for free and scale seamlessly as your project expands. No credit card needed.

[Start for free](https://www.firecrawl.dev/signin) [See our plans](https://www.firecrawl.dev/pricing)

FOOTER

The easiest way to extract

data from the web

Backed by

Y Combinator

[Linkedin](https://www.linkedin.com/company/firecrawl) [Github](https://github.com/firecrawl/firecrawl) [YouTube](https://www.youtube.com/@Firecrawl_dev)

SOC II ¬∑ Type 2

AICPA

SOC 2

[X (Twitter)](https://x.com/firecrawl) [Discord](https://discord.gg/gSmWdAkdwd)

Products

[Playground](https://www.firecrawl.dev/playground) [Agent](https://www.firecrawl.dev/agent) [Pricing](https://www.firecrawl.dev/pricing) [Templates](https://www.firecrawl.dev/templates) [Changelog](https://www.firecrawl.dev/changelog)

Use Cases

[AI Platforms](https://www.firecrawl.dev/use-cases/ai-platforms) [Lead Enrichment](https://www.firecrawl.dev/use-cases/lead-enrichment) [SEO Teams](https://www.firecrawl.dev/use-cases/seo-teams) [Deep Research](https://www.firecrawl.dev/use-cases/deep-research) [Competitive Intelligence](https://www.firecrawl.dev/use-cases/competitive-intelligence)

Documentation

[Getting started](https://docs.firecrawl.dev/introduction) [API Reference](https://docs.firecrawl.dev/api-reference/introduction) [Integrations](https://www.firecrawl.dev/app) [Examples](https://docs.firecrawl.dev/use-cases/overview) [SDKs](https://docs.firecrawl.dev/sdks/overview)

Company

[Blog](https://www.firecrawl.dev/blog) [Careers](https://www.firecrawl.dev/careers) [Creator & OSS program](https://www.firecrawl.dev/creator-oss-program) [Student program](https://www.firecrawl.dev/student-program)

¬© 2025 Firecrawl

[Terms of Service](https://www.firecrawl.dev/terms-of-service) [Privacy Policy](https://www.firecrawl.dev/privacy-policy) [Report Abuse](mailto:help@firecrawl.com?subject=Issue:)

[All systems normal](https://status.firecrawl.dev/)

## Fireplexity AI Engine
Introducing Parallel Agents - Run multiple /agent queries simultaneously. [Read more ‚Üí](https://www.firecrawl.dev/blog/introducing-parallel-agents)

//

Get started

//

### Ready to build?

Start getting Web Data for free and scale seamlessly as your project expands.No credit card needed.

[Start for free](https://www.firecrawl.dev/signin) [See our plans](https://www.firecrawl.dev/pricing)

[Blog](https://www.firecrawl.dev/blog)

Announcing Fireplexity: Our Open Source AI Answer Engine

![placeholder](https://www.firecrawl.dev/_next/image?url=%2Fblog%2Fauthors%2Feric-img.jpeg&w=48&q=75&dpl=dpl_2hQ8hmy6vNQsu8DPuBRaRM6deLpr)Eric Ciarla

Jun 24, 2025

![Announcing Fireplexity: Our Open Source AI Answer Engine image](https://www.firecrawl.dev/_next/image?url=%2Fimages%2Fblog%2Ffireplexity%2Ffireplexity_firecrawl.webp&w=3840&q=75&dpl=dpl_2hQ8hmy6vNQsu8DPuBRaRM6deLpr)

[Perplexity](https://www.perplexity.ai/) proved that search could be better. Instead of a list of links, you could get a direct answer with citations. That simple idea kicked off a race, with every major player trying to bolt web search onto their AI. **Today, we‚Äôre releasing [Fireplexity](https://tools.firecrawl.dev/fireplexity), an open source Next.js application that lets you build and host your own AI powered answer engine.**

### **What is Fireplexity?**

Fireplexity is an open source Perplexity clone for developers who want to build their own custom AI search experiences for any niche. We built it to be production ready from day one.

- **Deploy in 5 minutes:** Get a running answer engine, fast.
- **No vendor lock in:** It‚Äôs open source. You get full access to the code and control your own destiny.
- **Real time intelligence:** It uses Firecrawl for reliable web scraping, intelligently selects the best content, and synthesizes answers with citations.

### **How It Works (The Tech)**

Getting direct answers instead of links requires a few things to work together perfectly. Here‚Äôs a look under the hood:

- **Firecrawl for Web Search:** We use our own tool, Firecrawl, to handle JavaScript rendering and reliably scrape the content needed for answers. It handles the hard stuff.
- **Smart Content Selection:** Simple keyword searches aren't enough. Our algorithms score content for relevance and find the most important information on a page.
- **Streaming AI Synthesis:** Answers are generated in real time with inline citations using GPT-4o-mini, but you can swap it for any OpenAI compatible endpoint.
- **Interactive Citations:** Every part of an answer is backed by a source. Users can hover over a citation to preview it instantly.

We even built in live stock chart detection for over 180 companies to show what‚Äôs possible when you control the entire pipeline.

### **Build Your Own Today**

Stop waiting for someone else to build the tool you need. Use Fireplexity to power an internal knowledge base, create a specialized research tool, or build any domain specific answer engine you can imagine.

It‚Äôs available [now on GitHub](https://github.com/firecrawl/fireplexity) and [our live demo is here](https://tools.firecrawl.dev/fireplexity). Clone the repository, add your API keys, and get started.

\[ CTA \]

\[ CRAWL \]

\[ SCRAPE \]

\[ CTA \]

//

Get started

//

Ready to build?

Start getting Web Data for free and scale seamlessly as your project expands. No credit card needed.

[Start for free](https://www.firecrawl.dev/signin) [See our plans](https://www.firecrawl.dev/pricing)

![placeholder](https://www.firecrawl.dev/_next/image?url=%2Fblog%2Fauthors%2Feric-img.jpeg&w=128&q=75&dpl=dpl_2hQ8hmy6vNQsu8DPuBRaRM6deLpr)

Eric Ciarla [@ericciarla](https://x.com/ericciarla)

CMO of Firecrawl

About the Author

Eric Ciarla is the cofounder and Chief Marketing Officer (CMO) of Firecrawl. He also worked on Mendable.ai and sold it to companies like Snapchat, Coinbase, and MongoDB. Previously worked at Ford and Fracta as a Data Scientist. Eric also co-founded SideGuide, a tool for learning code within VS Code with 50,000 users.

More articles by Eric Ciarla

[Extract Web Data at Scale With Parallel Agents](https://www.firecrawl.dev/blog/introducing-parallel-agents) [Introducing the Firecrawl Skill and CLI - Give Agents Real-Time Web Data](https://www.firecrawl.dev/blog/introducing-firecrawl-skill-and-cli) [How Credal Extracts 6M+ URLs Monthly to Power Production AI Agents](https://www.firecrawl.dev/blog/credal-firecrawl-ai-agents) [How to Create an llms.txt File for Any Website](https://www.firecrawl.dev/blog/How-to-Create-an-llms-txt-File-for-Any-Website) [Introducing Spark 1 Pro and Spark 1 Mini](https://www.firecrawl.dev/blog/introducing-spark-1) [Introducing /agent: Gather Data Wherever It Lives on the Web](https://www.firecrawl.dev/blog/introducing-agent) [Retell‚Äôs AI phone agents get LLM-ready content from Firecrawl](https://www.firecrawl.dev/blog/retell-firecrawl-ai-phone-agents) [Introducing Firecrawl v2.5 - The World's Best Web Data API](https://www.firecrawl.dev/blog/the-worlds-best-web-data-api-v25) [Why Firecrawl Beats Octoparse for AI Web Scraping](https://www.firecrawl.dev/blog/firecrawl-vs-octoparse-data-extraction) [Introducing Firecrawl Observer, Our Open-Source Website Monitoring Tool](https://www.firecrawl.dev/blog/introducing-firecrawl-observer)

FOOTER

The easiest way to extract

data from the web

Backed by

Y Combinator

[Linkedin](https://www.linkedin.com/company/firecrawl) [Github](https://github.com/firecrawl/firecrawl) [YouTube](https://www.youtube.com/@Firecrawl_dev)

SOC II ¬∑ Type 2

AICPA

SOC 2

[X (Twitter)](https://x.com/firecrawl) [Discord](https://discord.gg/gSmWdAkdwd)

Products

[Playground](https://www.firecrawl.dev/playground) [Agent](https://www.firecrawl.dev/agent) [Pricing](https://www.firecrawl.dev/pricing) [Templates](https://www.firecrawl.dev/templates) [Changelog](https://www.firecrawl.dev/changelog)

Use Cases

[AI Platforms](https://www.firecrawl.dev/use-cases/ai-platforms) [Lead Enrichment](https://www.firecrawl.dev/use-cases/lead-enrichment) [SEO Teams](https://www.firecrawl.dev/use-cases/seo-teams) [Deep Research](https://www.firecrawl.dev/use-cases/deep-research) [Competitive Intelligence](https://www.firecrawl.dev/use-cases/competitive-intelligence)

Documentation

[Getting started](https://docs.firecrawl.dev/introduction) [API Reference](https://docs.firecrawl.dev/api-reference/introduction) [Integrations](https://www.firecrawl.dev/app) [Examples](https://docs.firecrawl.dev/use-cases/overview) [SDKs](https://docs.firecrawl.dev/sdks/overview)

Company

[Blog](https://www.firecrawl.dev/blog) [Careers](https://www.firecrawl.dev/careers) [Creator & OSS program](https://www.firecrawl.dev/creator-oss-program) [Student program](https://www.firecrawl.dev/student-program)

¬© 2025 Firecrawl

[Terms of Service](https://www.firecrawl.dev/terms-of-service) [Privacy Policy](https://www.firecrawl.dev/privacy-policy) [Report Abuse](mailto:help@firecrawl.com?subject=Issue:)

[All systems normal](https://status.firecrawl.dev/)

## Crawl Webhooks Overview
Introducing Spark 1 Pro and Spark 1 Mini models in /agent. [Try it now ‚Üí](https://www.firecrawl.dev/agent)

//

Get started

//

### Ready to build?

Start getting Web Data for free and scale seamlessly as your project expands.No credit card needed.

[Start for free](https://www.firecrawl.dev/signin) [See our plans](https://www.firecrawl.dev/pricing)

#### Table of Contents

[Blog](https://www.firecrawl.dev/blog)

Launch Week I / Day 7: Crawl Webhooks (v1)

![placeholder](https://www.firecrawl.dev/_next/image?url=%2Fblog%2Fauthors%2Fnick-img.jpeg&w=48&q=75&dpl=dpl_2hQ8hmy6vNQsu8DPuBRaRM6deLpr)Nicolas Camara

Sep 01, 2024

![Launch Week I / Day 7: Crawl Webhooks (v1) image](https://www.firecrawl.dev/_next/image?url=%2Fimages%2Fblog%2Fwebhooks.png&w=3840&q=75&dpl=dpl_2hQ8hmy6vNQsu8DPuBRaRM6deLpr)

Welcome to Day 7 of Firecrawl's Launch Week! We're excited to introduce new /crawl webhook support.

## Crawl Webhook

You can now pass a `webhook` parameter to the `/crawl` endpoint. This will send a POST request to the URL you specify when the crawl is started, updated and completed.

The webhook will now trigger for every page crawled and not just the whole result at the end.

![Webhook](https://www.firecrawl.dev/images/blog/webhook-v1.png)

### Webhook Events

There are now 4 types of events:

- `crawl.started` \- Triggered when the crawl is started.
- `crawl.page` \- Triggered for every page crawled.
- `crawl.completed` \- Triggered when the crawl is completed to let you know it's done.
- `crawl.failed` \- Triggered when the crawl fails.

### Webhook Response

- `success` \- If the webhook was successful in crawling the page correctly.
- `type` \- The type of event that occurred.
- `id` \- The ID of the crawl.
- `data` \- The data that was scraped (Array). This will only be non empty on `crawl.page` and will contain 1 item if the page was scraped successfully. The response is the same as the `/scrape` endpoint.
- `error` \- If the webhook failed, this will contain the error message.

## Learn More

Learn more about the webhook in our [documentation](https://docs.firecrawl.dev/features/crawl#crawl-webhook).

\[ CTA \]

\[ CRAWL \]

\[ SCRAPE \]

\[ CTA \]

//

Get started

//

Ready to build?

Start getting Web Data for free and scale seamlessly as your project expands. No credit card needed.

[Start for free](https://www.firecrawl.dev/signin) [See our plans](https://www.firecrawl.dev/pricing)

![placeholder](https://www.firecrawl.dev/_next/image?url=%2Fblog%2Fauthors%2Fnick-img.jpeg&w=128&q=75&dpl=dpl_2hQ8hmy6vNQsu8DPuBRaRM6deLpr)

Nicolas Camara [@nickscamara\_](https://x.com/nickscamara_)

CTO of Firecrawl

About the Author

Nicolas Camara is the Chief Technology Officer (CTO) at Firecrawl. He previously built and scaled Mendable, one of the pioneering "chat with your documents" apps, which had major Fortune 500 customers like Snapchat, Coinbase, and MongoDB. Prior to that, Nicolas built SideGuide, the first code-learning tool inside VS Code, and grew a community of 50,000 users. Nicolas studied Computer Science and has over 10 years of experience in building software.

More articles by Nicolas Camara

[Firecrawl + Lovable - Build Web Data Apps Without Writing Code](https://www.firecrawl.dev/blog/firecrawl-lovable-integration) [Announcing Deep Research API](https://www.firecrawl.dev/blog/deep-research-api) [Getting Started with Grok-2: Setup and Web Crawler Example](https://www.firecrawl.dev/blog/grok-2-setup-and-web-crawler-example) [OpenAI Swarm Tutorial: Create Marketing Campaigns for Any Website](https://www.firecrawl.dev/blog/openai-swarm-agent-tutorial) [Using OpenAI's Realtime API and Firecrawl to Talk with Any Website](https://www.firecrawl.dev/blog/How-to-Talk-with-Any-Website-Using-OpenAIs-Realtime-API-and-Firecrawl) [Launch Week I / Day 7: Crawl Webhooks (v1)](https://www.firecrawl.dev/blog/launch-week-i-day-7-webhooks) [Launch Week I / Day 6: LLM Extract (v1)](https://www.firecrawl.dev/blog/launch-week-i-day-6-llm-extract) [Firecrawl June 2024 Updates](https://www.firecrawl.dev/blog/firecrawl-june-2024-updates) [Build a 'Chat with website' using Groq Llama 3](https://www.firecrawl.dev/blog/chat-with-website) [Extract website data using LLMs](https://www.firecrawl.dev/blog/data-extraction-using-llms)

FOOTER

The easiest way to extract

data from the web

Backed by

Y Combinator

[Linkedin](https://www.linkedin.com/company/firecrawl) [Github](https://github.com/firecrawl/firecrawl) [YouTube](https://www.youtube.com/@Firecrawl_dev)

SOC II ¬∑ Type 2

AICPA

SOC 2

[X (Twitter)](https://x.com/firecrawl) [Discord](https://discord.gg/gSmWdAkdwd)

Products

[Playground](https://www.firecrawl.dev/playground) [Agent](https://www.firecrawl.dev/agent) [Pricing](https://www.firecrawl.dev/pricing) [Templates](https://www.firecrawl.dev/templates) [Changelog](https://www.firecrawl.dev/changelog)

Use Cases

[AI Platforms](https://www.firecrawl.dev/use-cases/ai-platforms) [Lead Enrichment](https://www.firecrawl.dev/use-cases/lead-enrichment) [SEO Teams](https://www.firecrawl.dev/use-cases/seo-teams) [Deep Research](https://www.firecrawl.dev/use-cases/deep-research) [Competitive Intelligence](https://www.firecrawl.dev/use-cases/competitive-intelligence)

Documentation

[Getting started](https://docs.firecrawl.dev/introduction) [API Reference](https://docs.firecrawl.dev/api-reference/introduction) [Integrations](https://www.firecrawl.dev/app) [Examples](https://docs.firecrawl.dev/use-cases/overview) [SDKs](https://docs.firecrawl.dev/sdks/overview)

Company

[Blog](https://www.firecrawl.dev/blog) [Careers](https://www.firecrawl.dev/careers) [Creator & OSS program](https://www.firecrawl.dev/creator-oss-program) [Student program](https://www.firecrawl.dev/student-program)

¬© 2025 Firecrawl

[Terms of Service](https://www.firecrawl.dev/terms-of-service) [Privacy Policy](https://www.firecrawl.dev/privacy-policy) [Report Abuse](mailto:help@firecrawl.com?subject=Issue:)

[All systems normal](https://status.firecrawl.dev/)

## Website Contradictions Agent
Introducing Spark 1 Pro and Spark 1 Mini models in /agent. [Try it now ‚Üí](https://www.firecrawl.dev/agent)

//

Get started

//

### Ready to build?

Start getting Web Data for free and scale seamlessly as your project expands.No credit card needed.

[Start for free](https://www.firecrawl.dev/signin) [See our plans](https://www.firecrawl.dev/pricing)

#### Table of Contents

[Blog](https://www.firecrawl.dev/blog)

Build an agent that checks for website contradictions

![placeholder](https://www.firecrawl.dev/_next/image?url=%2Fblog%2Fauthors%2Feric-img.jpeg&w=48&q=75&dpl=dpl_2hQ8hmy6vNQsu8DPuBRaRM6deLpr)Eric Ciarla

May 19, 2024

![Build an agent that checks for website contradictions image](https://www.firecrawl.dev/_next/image?url=%2Fimages%2Fblog%2Fg1.png&w=3840&q=75&dpl=dpl_2hQ8hmy6vNQsu8DPuBRaRM6deLpr)

In this quick tutorial you will learn how to use Firecrawl and Claude to scrape your website's data and look for contradictions and inconsistencies in a few lines of code. When you are shipping fast, data is bound to get stale, with Firecrawl and LLMs you can make sure your public web data is always consistent! We will be using Opus's huge 200k context window and Firecrawl's parellization, making this process accurate and fast.

## Setup

Install our python dependencies, including anthropic and firecrawl-py.

```
pip install firecrawl-py anthropic
```

## Getting your Claude and Firecrawl API Keys

To use Claude Opus and Firecrawl, you will need to get your API keys. You can get your Anthropic API key from [here](https://www.anthropic.com/) and your Firecrawl API key from [here](https://firecrawl.dev/).

## Load website with Firecrawl

To be able to get all the data from our website page put it into an easy to read format for the LLM, we will use [Firecrawl](https://firecrawl.dev/). It handles by-passing JS-blocked websites, extracting the main content, and outputting in a LLM-readable format for increased accuracy.

Here is how we will scrape a website url using Firecrawl-py

```
from firecrawl import FirecrawlApp

app = FirecrawlApp(api_key="YOUR-KEY")

crawl_result = app.crawl_url('mendable.ai', {'crawlerOptions': {'excludes': ['blog/.+','usecases/.+']}})

print(crawl_result)
```

With all of the web data we want scraped and in a clean format, we can move onto the next step.

## Combination and Generation

Now that we have the website data, let's pair up every page and run every combination through Opus for analysis.

```
from itertools import combinations

page_combinations = []

for first_page, second_page in combinations(crawl_result, 2):
    combined_string = "First Page:\n" + first_page['markdown'] + "\n\nSecond Page:\n" + second_page['markdown']
    page_combinations.append(combined_string)

import anthropic

client = anthropic.Anthropic(
    # defaults to os.environ.get("ANTHROPIC_API_KEY")
    api_key="YOUR-KEY",
)

final_output = []

for page_combination in page_combinations:

    prompt = "Here are two pages from a companies website, your job is to find any contradictions or differences in opinion between the two pages, this could be caused by outdated information or other. If you find any contradictions, list them out and provide a brief explanation of why they are contradictory or differing. Make sure the explanation is specific and concise. It is okay if you don't find any contradictions, just say 'No contradictions found' and nothing else. Here are the pages: " + "\n\n".join(page_combination)

    message = client.messages.create(
        model="claude-3-opus-20240229",
        max_tokens=1000,
        temperature=0.0,
        system="You are an assistant that helps find contradictions or differences in opinion between pages in a company website and knowledge base. This could be caused by outdated information in the knowledge base.",
        messages=[\
            {"role": "user", "content": prompt}\
        ]
    )
    final_output.append(message.content)

```

## That's about it!

You have now built an agent that looks at your website and spots any inconsistencies it might have.

If you have any questions or need help, feel free to reach out to us at [Firecrawl](https://firecrawl.dev/).

\[ CTA \]

\[ CRAWL \]

\[ SCRAPE \]

\[ CTA \]

//

Get started

//

Ready to build?

Start getting Web Data for free and scale seamlessly as your project expands. No credit card needed.

[Start for free](https://www.firecrawl.dev/signin) [See our plans](https://www.firecrawl.dev/pricing)

![placeholder](https://www.firecrawl.dev/_next/image?url=%2Fblog%2Fauthors%2Feric-img.jpeg&w=128&q=75&dpl=dpl_2hQ8hmy6vNQsu8DPuBRaRM6deLpr)

Eric Ciarla [@ericciarla](https://x.com/ericciarla)

CMO of Firecrawl

About the Author

Eric Ciarla is the cofounder and Chief Marketing Officer (CMO) of Firecrawl. He also worked on Mendable.ai and sold it to companies like Snapchat, Coinbase, and MongoDB. Previously worked at Ford and Fracta as a Data Scientist. Eric also co-founded SideGuide, a tool for learning code within VS Code with 50,000 users.

More articles by Eric Ciarla

[Extract Web Data at Scale With Parallel Agents](https://www.firecrawl.dev/blog/introducing-parallel-agents) [Introducing the Firecrawl Skill and CLI - Give Agents Real-Time Web Data](https://www.firecrawl.dev/blog/introducing-firecrawl-skill-and-cli) [How Credal Extracts 6M+ URLs Monthly to Power Production AI Agents](https://www.firecrawl.dev/blog/credal-firecrawl-ai-agents) [How to Create an llms.txt File for Any Website](https://www.firecrawl.dev/blog/How-to-Create-an-llms-txt-File-for-Any-Website) [Introducing Spark 1 Pro and Spark 1 Mini](https://www.firecrawl.dev/blog/introducing-spark-1) [Introducing /agent: Gather Data Wherever It Lives on the Web](https://www.firecrawl.dev/blog/introducing-agent) [Retell‚Äôs AI phone agents get LLM-ready content from Firecrawl](https://www.firecrawl.dev/blog/retell-firecrawl-ai-phone-agents) [Introducing Firecrawl v2.5 - The World's Best Web Data API](https://www.firecrawl.dev/blog/the-worlds-best-web-data-api-v25) [Why Firecrawl Beats Octoparse for AI Web Scraping](https://www.firecrawl.dev/blog/firecrawl-vs-octoparse-data-extraction) [Introducing Firecrawl Observer, Our Open-Source Website Monitoring Tool](https://www.firecrawl.dev/blog/introducing-firecrawl-observer)

FOOTER

The easiest way to extract

data from the web

Backed by

Y Combinator

[Linkedin](https://www.linkedin.com/company/firecrawl) [Github](https://github.com/firecrawl/firecrawl) [YouTube](https://www.youtube.com/@Firecrawl_dev)

SOC II ¬∑ Type 2

AICPA

SOC 2

[X (Twitter)](https://x.com/firecrawl) [Discord](https://discord.gg/gSmWdAkdwd)

Products

[Playground](https://www.firecrawl.dev/playground) [Agent](https://www.firecrawl.dev/agent) [Pricing](https://www.firecrawl.dev/pricing) [Templates](https://www.firecrawl.dev/templates) [Changelog](https://www.firecrawl.dev/changelog)

Use Cases

[AI Platforms](https://www.firecrawl.dev/use-cases/ai-platforms) [Lead Enrichment](https://www.firecrawl.dev/use-cases/lead-enrichment) [SEO Teams](https://www.firecrawl.dev/use-cases/seo-teams) [Deep Research](https://www.firecrawl.dev/use-cases/deep-research) [Competitive Intelligence](https://www.firecrawl.dev/use-cases/competitive-intelligence)

Documentation

[Getting started](https://docs.firecrawl.dev/introduction) [API Reference](https://docs.firecrawl.dev/api-reference/introduction) [Integrations](https://www.firecrawl.dev/app) [Examples](https://docs.firecrawl.dev/use-cases/overview) [SDKs](https://docs.firecrawl.dev/sdks/overview)

Company

[Blog](https://www.firecrawl.dev/blog) [Careers](https://www.firecrawl.dev/careers) [Creator & OSS program](https://www.firecrawl.dev/creator-oss-program) [Student program](https://www.firecrawl.dev/student-program)

¬© 2025 Firecrawl

[Terms of Service](https://www.firecrawl.dev/terms-of-service) [Privacy Policy](https://www.firecrawl.dev/privacy-policy) [Report Abuse](mailto:help@firecrawl.com?subject=Issue:)

[All systems normal](https://status.firecrawl.dev/)

## E-Commerce Intelligence App
Introducing Spark 1 Pro and Spark 1 Mini models in /agent. [Try it now ‚Üí](https://www.firecrawl.dev/agent)

//

Get started

//

### Ready to build?

Start getting Web Data for free and scale seamlessly as your project expands. No credit card needed.

[Start for free](https://www.firecrawl.dev/signin) [See our plans](https://www.firecrawl.dev/pricing)

#### Table of Contents

[Blog](https://www.firecrawl.dev/blog)

Building E-Commerce Intelligence Application with GLM Coding Plan

![placeholder](https://www.firecrawl.dev/_next/image?url=%2Fblog%2Fauthors%2Fabid.jpg&w=48&q=75&dpl=dpl_2hQ8hmy6vNQsu8DPuBRaRM6deLpr)Abid Ali Awan

Oct 26, 2025

![Building E-Commerce Intelligence Application with GLM Coding Plan image](https://www.firecrawl.dev/_next/image?url=%2Fimages%2Fblog%2Fbuilding-ecommerce-intelligence-app-with-glm-4-6%2Fbuilding-ecommerce-intelligence-app-with-glm-4-6.webp&w=3840&q=75&dpl=dpl_2hQ8hmy6vNQsu8DPuBRaRM6deLpr)

Hitting Claude Code limits and burning cash? Meet the **$3 GLM Coding Plan**. Designed as a powerful yet affordable solution, the GLM Coding Plan pairs Claude Code's intuitive workflow with the open-source strength of GLM-4.6, giving you near-Claude-level coding performance at a fraction of the price.

[**GLM-4.6**](https://z.ai/blog/glm-4.6) pushes real capability upgrades over GLM-4.5, from a longer 200K-token context window to stronger reasoning, faster tool use, and significantly better coding performance. Across eight public benchmarks in reasoning, agents, and coding, it consistently outperforms GLM-4.5 and competes closely with top-tier models like **DeepSeek-V3.2-Exp** and **Claude Sonnet 4**, though it still trails **Sonnet 4.5** in raw code generation strength.

![eight public benchmarks in reasoning, agents, and coding](https://www.firecrawl.dev/images/blog/building-ecommerce-intelligence-app-with-glm-4-6/building-ecommerce-intelligence-app-with-glm-4-6-1.webp)

In this tutorial, we will walk through how to subscribe to the $3 GLM Coding Plan, connect it with Claude Code, and vibe-code a smart E-Commerce Intelligence App, one that scrapes product reviews using Firecrawl, analyzes them with GPT-5-mini, caches results in SQLite, and visualizes insights through an interactive Streamlit dashboard. By the end, you'll see exactly where GLM-4.6 excels, where it struggles, and how to optimize it for your own coding flow.

## What Is the GLM Coding Plan?

The [GLM Coding Plan](https://z.ai/subscribe) is Z.ai's subscription service that provides access to the latest GLM-4.6 model, which has been optimized for advanced agent-like behavior, reasoning, and coding. This plan integrates directly into your existing developer tools, starting at $3 per month.

It seamlessly combines with popular workflows like Claude Code, Cline, and OpenCode (among others), allowing you to enhance your coding assistant without needing to change your editor or command-line interface (CLI) setup.

Developers are drawn to this plan because it offers predictable, low-cost pricing along with strong performance and wide tool compatibility. The entry-level Lite tier typically provides around 120 prompts per 5-hour cycle for about $3, while the Pro tier increases that to approximately 600 prompts per 5-hour cycle. This structure is designed to accommodate frequent coding sessions without the complexity of per-token charges.

## Setting Up Claude Code with the GLM Coding Plan

Claude Code is an agentic coding tool that lives in your terminal, understands your codebase, and helps you code faster by executing routine tasks, explaining complex code, and handling git workflows, all through natural language commands. It acts like a hands-on engineering partner that can run commands, edit files, and reason about your repo structure from the CLI.

**Why use Claude Code with GLM Coding Plan?** We chose this setup because the official Claude Code plans are expensive and have strict usage limits. Many developers report hitting these limits within an hour, which disrupts productivity. To solve this, we'll be using a more cost-effective and flexible alternative. With this setup, you only need to change the model and the base URL to switch to a fully functional, Anthropic-compatible backend without sacrificing performance.

### 1) Install Claude Code

If you are new to Claude Code, start by launching your terminal. Ensure that Node.js is installed on your system. Then, install the official CLI globally by running:

```
npm install -g @anthropic-ai/claude-code
```

Next, navigate to your project directory using:

```
cd ECom-Intel
```

Finally, initialize Claude Code by typing:

```
claude
```

![Launch Claude Code](https://www.firecrawl.dev/images/blog/building-ecommerce-intelligence-app-with-glm-4-6/building-ecommerce-intelligence-app-with-glm-4-6-2.webp)

### 2) Sign up for the GLM Coding Plan (GLM-4.6)

Visit the [Z.AI Open Platform](http://z.ai/) and either register or log in to your account. Subscribe to the Lite [GLM Coding Plan](https://z.ai/subscribe), which costs $3. After connecting your credit card and completing the subscription, go to the API keys management page. Create a new API key and copy it, as you'll need it in the next configuration step.

![GLM Coding Plan](https://www.firecrawl.dev/images/blog/building-ecommerce-intelligence-app-with-glm-4-6/building-ecommerce-intelligence-app-with-glm-4-6-3.webp)

### 3) Configure environment variables

Set up your environment variables so that Claude Code uses Z.AI as its Anthropic-compatible backend. On macOS or Linux (bash/zsh), run:

```
export ANTHROPIC_AUTH_TOKEN='your_zai_api_key'
export ANTHROPIC_BASE_URL='https://api.z.ai/api/anthropic'
```

### 4) Add Firecrawl (MCP tool) for web data

Next, integrate [Firecrawl remote MCP](https://docs.firecrawl.dev/mcp-server) designed to fetch the latest tech stack details, code snippets, and documentation for your project. Firecrawl is a Web Data API for AI that can connect to Claude Code through MCP. Start by creating a free [Firecrawl](https://www.firecrawl.dev/) account and generating an API key. Then, add Firecrawl as an MCP tool using:

```
claude mcp add --transport http firecrawl https://mcp.firecrawl.dev/{FIRECRAWL_API_KEY}/v2/mcp
```

This enables Claude Code to access live web data for more accurate and context-aware coding assistance.

### 5) Use Claude Code with GLM-4.6 in your project

Return to your project directory and launch Claude Code using the GLM-4.6 model:

```
cd ECom-Intel
claude --model glm-4.6
```

![Use Claude Code with GLM-4.6 in your project](https://www.firecrawl.dev/images/blog/building-ecommerce-intelligence-app-with-glm-4-6/building-ecommerce-intelligence-app-with-glm-4-6-4.webp)

You can verify that the setup is correct by using the `/status` command. It should display the Z.AI endpoint as the base URL and indicate that the active model is `glm-4.6`.

![/status command](https://www.firecrawl.dev/images/blog/building-ecommerce-intelligence-app-with-glm-4-6/building-ecommerce-intelligence-app-with-glm-4-6-5.webp)

To confirm the Firecrawl MCP connection, you can also ask Claude to test connectivity.

![testing Firecrawl MCP](https://www.firecrawl.dev/images/blog/building-ecommerce-intelligence-app-with-glm-4-6/building-ecommerce-intelligence-app-with-glm-4-6-6.webp)

For the best experience, use [Alacritty](https://alacritty.org/), a cross-platform OpenGL-based terminal emulator. It provides exceptional performance, smooth rendering, and better support for tools like Claude Code, enhancing your overall coding workflow.

## Vibe-Coding the E-Commerce Intelligence Application

With everything now configured, it's time to _vibe code_ our E-Commerce Intelligence Application: a compact, end-to-end project that brings together data scraping, sentiment analysis, caching, and visualization into one smooth workflow.

This application uses **Firecrawl** to automatically search for and scrape customer reviews from relevant pages. The collected reviews are then analyzed using **OpenAI's AI model**, which classifies overall sentiment, identifies recurring themes, and extracts useful insights such as customer satisfaction levels or feature-related feedback.

To make the process efficient, all scraped and analyzed data is stored locally in an **SQLite database**, ensuring that results are cached for quick access. Finally, the insights are displayed through an elegant **Streamlit dashboard**, giving users an interactive and visual overview of sentiment trends and summarized findings.

### 1\. Plan mode

Go to your project folder and launch the terminal. Once inside, run the following command to start Claude Code with the GLM-4.6 model:

```
claude --model glm-4.6
```

Press **Alt + M** twice to activate _Planning Mode_. This mode allows GLM-4.6 to create a detailed project plan before generating or editing any files.

**Here's the initial prompt:**

```
Create a Python application that takes a product URL, uses Firecrawl to search and scrape reviews, analyzes the reviews using OpenAI GPT-5-mini, caches the results in an SQLite database, and displays insights on a Streamlit web dashboard. Keep the project short.
```

![the initial prompt in claude code](https://www.firecrawl.dev/images/blog/building-ecommerce-intelligence-app-with-glm-4-6/building-ecommerce-intelligence-app-with-glm-4-6-7.webp)

Once the plan is generated, accept it. Within seconds, Claude Code will begin building the project structure and core components based on the plan.

![Claude Code plan mode](https://www.firecrawl.dev/images/blog/building-ecommerce-intelligence-app-with-glm-4-6/building-ecommerce-intelligence-app-with-glm-4-6-8.webp)

### 2\. Edit mode

In _Edit Mode_, Claude Code automatically breaks down the project into smaller, manageable tasks and executes them one by one.

![Claude Code edit mode todo list](https://www.firecrawl.dev/images/blog/building-ecommerce-intelligence-app-with-glm-4-6/building-ecommerce-intelligence-app-with-glm-4-6-9.webp)

Within about five minutes, it creates all necessary files and provides installation steps to set up and launch the application.

![project setup instructions](https://www.firecrawl.dev/images/blog/building-ecommerce-intelligence-app-with-glm-4-6/building-ecommerce-intelligence-app-with-glm-4-6-10.webp)

While we can ask Claude Code to install dependencies automatically, some configurations, such as adding your OpenAI and Firecrawl API keys must be done manually to complete the setup.

## Testing Our E-Commerce Intelligence Application

Now that our project is complete, it is time to test the E-Commerce Intelligence App and see it in action.

### 1\. Install dependencies

Run the following command to install all required packages:

```
pip install -r requirements.txt
```

### 2\. Set up API keys

Make sure you have generated both your OpenAI and Firecrawl API keys. Ensure you have at least $5 in your OpenAI account balance for API calls to work properly. Some models on OpenAI may also require organization verification, so complete that step before running the app.

Next, copy the environment template:

```
cp .env.example .env
```

Then, open the `.env` file and add your OpenAI and Firecrawl API keys.

### 3\. Run the app

Launch the Streamlit application by running:

```
streamlit run app.py
```

Output:

```
You can now view your Streamlit app in your browser.

 Local URL: http://localhost:8501
 Network URL: http://192.168.100.94:8501
```

The app should load perfectly, it's impressive how well it works right out of the box.

![E-Commerce Intelligence Application dashboard](https://www.firecrawl.dev/images/blog/building-ecommerce-intelligence-app-with-glm-4-6/building-ecommerce-intelligence-app-with-glm-4-6-11.webp)

### 4\. Testing with the URL

To test it, search for a random product on Amazon and copy its URL, for example: `https://www.amazon.com/SAMSUNG-Unlocked-Smartphone-Charging-Expandable/dp/B0DLHNWHRF?th=1`

![product on Amazon](https://www.firecrawl.dev/images/blog/building-ecommerce-intelligence-app-with-glm-4-6/building-ecommerce-intelligence-app-with-glm-4-6-12.webp)

Paste the URL into the app and click the Analyze Reviews button.

![click the Analyze Reviews button](https://www.firecrawl.dev/images/blog/building-ecommerce-intelligence-app-with-glm-4-6/building-ecommerce-intelligence-app-with-glm-4-6-13.webp)

### 5\. Visualizing the Results

Within seconds, you'll see detailed visualizations showing total reviews, sentiment analysis, rating distributions, and more.

![detailed visualizations](https://www.firecrawl.dev/images/blog/building-ecommerce-intelligence-app-with-glm-4-6/building-ecommerce-intelligence-app-with-glm-4-6-14.webp)

The report comes with the key highlights, what customers love, and common complaints.

![key highlights](https://www.firecrawl.dev/images/blog/building-ecommerce-intelligence-app-with-glm-4-6/building-ecommerce-intelligence-app-with-glm-4-6-15.webp)

In the end, it has provided recommendations on how you can improve the product information.

![recommendations](https://www.firecrawl.dev/images/blog/building-ecommerce-intelligence-app-with-glm-4-6/building-ecommerce-intelligence-app-with-glm-4-6-16.webp)

If you refresh the page, the app will show your past searches.

![past searches](https://www.firecrawl.dev/images/blog/building-ecommerce-intelligence-app-with-glm-4-6/building-ecommerce-intelligence-app-with-glm-4-6-17.webp)

When you analyze the same URL again, results appear almost instantly because of cached data stored in SQLite.

![cached data stored in SQLite](https://www.firecrawl.dev/images/blog/building-ecommerce-intelligence-app-with-glm-4-6/building-ecommerce-intelligence-app-with-glm-4-6-18.webp)

All source code, documentation, and demo results are available on GitHub: [kingabzpro/ECom-Intel: Product Review Analyzer](https://github.com/kingabzpro/ECom-Intel)

## Final Thoughts

It took me a bit of time to get the hang of Claude Code, from setting up the MCP to crafting the perfect prompts and understanding its various modes.

**The biggest takeaway?** Don't overcomplicate your instructions. When you pack too many constraints, specify exact libraries, or overdefine the process, the model tends to produce messy, error-prone code. Instead, describe the goal clearly and give it creative freedom to decide how to build it. Let Claude Code plan, review its approach, and refine only where needed, that's when it truly shines.

### The Good and the not-so-good

There were a few hiccups. It defaulted to GPT-4o-mini instead of GPT-5-mini and relied on an older API, which made the responses a bit slower. But honestly, the fact that the app worked right out of the box made up for it. All I had to do was install dependencies, set up the environment variables, and run the app, no manual debugging or complex setup needed.

### What I would improve next

If I were to rebuild this project, I would make it faster and more efficient. This would involve switching to the latest OpenAI SDK and response API, optimizing Firecrawl queries for quicker data retrieval, and enhancing caching to ensure results are almost instant. Additionally, I was pleasantly surprised by how well GLM-4.6 managed the user interface. It generated a clean and functional design for both real-time and cached data, something that many AI coding tools struggle to achieve.

### My recommendation

If you are new to Claude Code or the GLM Coding Plan, keep it simple. Start in Plan Mode and let it generate the project plan. If you like the plan, accept it and let GLM-4.6 build the whole project; if you want changes, edit the plan first and then let it work its magic. Once the base app is ready, test it, spot the gaps, and refine it manually, especially if you are comfortable with Python. Tweak, optimize, and personalize. That's the fastest path from a solid AI-generated MVP to something genuinely exceptional.

\[ CTA \]

\[ CRAWL \]

\[ SCRAPE \]

\[ CTA \]

//

Get started

//

Ready to build?

Start getting Web Data for free and scale seamlessly as your project expands. No credit card needed.

[Start for free](https://www.firecrawl.dev/signin) [See our plans](https://www.firecrawl.dev/pricing)

![placeholder](https://www.firecrawl.dev/_next/image?url=%2Fblog%2Fauthors%2Fabid.jpg&w=128&q=75&dpl=dpl_2hQ8hmy6vNQsu8DPuBRaRM6deLpr)

Abid Ali Awan [@1abidaliawan](https://x.com/1abidaliawan)

Technical Writer at Firecrawl

About the Author

Abid Ali Awan is a Technical Writer at Firecrawl and a certified data scientist who enjoys building machine learning applications and writing blogs on data science. He is currently focusing on content creation, editing, and working with large language models.

More articles by Abid Ali Awan

[Building E-Commerce Intelligence Application with GLM Coding Plan](https://www.firecrawl.dev/blog/building-ecommerce-intelligence-app-with-glm-4-6) [Building AI Agents with OpenAI Agent Builders & Firecrawl](https://www.firecrawl.dev/blog/openai-agent-builders-and-firecrawl) [Top 15 Python Projects to Build in 2025: From Beginner to Production](https://www.firecrawl.dev/blog/15-python-projects-2025) [10 Essential Python Libraries Every Data Analyst Should Know](https://www.firecrawl.dev/blog/python-libraries-for-data-analysts) [10 AI Projects You Can Build with Firecrawl Now](https://www.firecrawl.dev/blog/10-ai-projects-with-firecrawl) [11 AI Agent Projects You Can Build Today (With Guides)](https://www.firecrawl.dev/blog/11-ai-agent-projects) [Fine-Tune OpenAI GPT-OSS 20B on the Dermatology Dataset](https://www.firecrawl.dev/blog/fine_tune_openai_gpt_oss) [How to Create a Dermatology Q&A Dataset with OpenAI Harmony & Firecrawl Search](https://www.firecrawl.dev/blog/creating_dermatology_dataset_with_openai_harmony_firecrawl_search) [5 Easy Ways to Access GLM-4.5](https://www.firecrawl.dev/blog/5_easy_ways_to_access_glm_4_5) [Building AI Applications with Kimi K2: A Complete Travel Deal Finder Tutorial](https://www.firecrawl.dev/blog/building-ai-applications-kimi-k2-travel-deal-finder)

FOOTER

The easiest way to extract

data from the web

Backed by

Y Combinator

[Linkedin](https://www.linkedin.com/company/firecrawl) [Github](https://github.com/firecrawl/firecrawl) [YouTube](https://www.youtube.com/@Firecrawl_dev)

SOC II ¬∑ Type 2

AICPA

SOC 2

[X (Twitter)](https://x.com/firecrawl) [Discord](https://discord.gg/gSmWdAkdwd)

Products

[Playground](https://www.firecrawl.dev/playground) [Agent](https://www.firecrawl.dev/agent) [Pricing](https://www.firecrawl.dev/pricing) [Templates](https://www.firecrawl.dev/templates) [Changelog](https://www.firecrawl.dev/changelog)

Use Cases

[AI Platforms](https://www.firecrawl.dev/use-cases/ai-platforms) [Lead Enrichment](https://www.firecrawl.dev/use-cases/lead-enrichment) [SEO Teams](https://www.firecrawl.dev/use-cases/seo-teams) [Deep Research](https://www.firecrawl.dev/use-cases/deep-research) [Competitive Intelligence](https://www.firecrawl.dev/use-cases/competitive-intelligence)

Documentation

[Getting started](https://docs.firecrawl.dev/introduction) [API Reference](https://docs.firecrawl.dev/api-reference/introduction) [Integrations](https://www.firecrawl.dev/app) [Examples](https://docs.firecrawl.dev/use-cases/overview) [SDKs](https://docs.firecrawl.dev/sdks/overview)

Company

[Blog](https://www.firecrawl.dev/blog) [Careers](https://www.firecrawl.dev/careers) [Creator & OSS program](https://www.firecrawl.dev/creator-oss-program) [Student program](https://www.firecrawl.dev/student-program)

¬© 2025 Firecrawl

[Terms of Service](https://www.firecrawl.dev/terms-of-service) [Privacy Policy](https://www.firecrawl.dev/privacy-policy) [Report Abuse](mailto:help@firecrawl.com?subject=Issue:)

[All systems normal](https://status.firecrawl.dev/)

## Spark Models Overview
Introducing Spark 1 Pro and Spark 1 Mini models in /agent. [Try it now ‚Üí](https://www.firecrawl.dev/agent)

FOOTER

The easiest way to extract

data from the web

Backed by

Y Combinator

[Linkedin](https://www.linkedin.com/company/firecrawl) [Github](https://github.com/firecrawl/firecrawl) [YouTube](https://www.youtube.com/@Firecrawl_dev)

SOC II ¬∑ Type 2

AICPA

SOC 2

[X (Twitter)](https://x.com/firecrawl) [Discord](https://discord.gg/gSmWdAkdwd)

Products

[Playground](https://www.firecrawl.dev/playground) [Agent](https://www.firecrawl.dev/agent) [Pricing](https://www.firecrawl.dev/pricing) [Templates](https://www.firecrawl.dev/templates) [Changelog](https://www.firecrawl.dev/changelog)

Use Cases

[AI Platforms](https://www.firecrawl.dev/use-cases/ai-platforms) [Lead Enrichment](https://www.firecrawl.dev/use-cases/lead-enrichment) [SEO Teams](https://www.firecrawl.dev/use-cases/seo-teams) [Deep Research](https://www.firecrawl.dev/use-cases/deep-research) [Competitive Intelligence](https://www.firecrawl.dev/use-cases/competitive-intelligence)

Documentation

[Getting started](https://docs.firecrawl.dev/introduction) [API Reference](https://docs.firecrawl.dev/api-reference/introduction) [Integrations](https://www.firecrawl.dev/app) [Examples](https://docs.firecrawl.dev/use-cases/overview) [SDKs](https://docs.firecrawl.dev/sdks/overview)

Company

[Blog](https://www.firecrawl.dev/blog) [Careers](https://www.firecrawl.dev/careers) [Creator & OSS program](https://www.firecrawl.dev/creator-oss-program) [Student program](https://www.firecrawl.dev/student-program)

¬© 2025 Firecrawl

[Terms of Service](https://www.firecrawl.dev/terms-of-service) [Privacy Policy](https://www.firecrawl.dev/privacy-policy) [Report Abuse](mailto:help@firecrawl.com?subject=Issue:)

[All systems normal](https://status.firecrawl.dev/)

reCAPTCHA

Recaptcha requires verification.

[Privacy](https://www.google.com/intl/en/policies/privacy/) \- [Terms](https://www.google.com/intl/en/policies/terms/)

protected by **reCAPTCHA**

[Privacy](https://www.google.com/intl/en/policies/privacy/) \- [Terms](https://www.google.com/intl/en/policies/terms/)

## Email Confirmation Page
# Confirm Email

Please check your email for a confirmation link. Once confirmed, you may sign in.

[Back to sign in](https://www.firecrawl.dev/signin?view=signin_email_password)

reCAPTCHA

Recaptcha requires verification.

[Privacy](https://www.google.com/intl/en/policies/privacy/) \- [Terms](https://www.google.com/intl/en/policies/terms/)

protected by **reCAPTCHA**

[Privacy](https://www.google.com/intl/en/policies/privacy/) \- [Terms](https://www.google.com/intl/en/policies/terms/)

## Web Data Extraction Calculator
Introducing Spark 1 Pro and Spark 1 Mini models in /agent. [Try it now ‚Üí](https://www.firecrawl.dev/agent)

# Extract Calculator

Estimate credit usage for your data extraction needs.

No agent

FIRE-1 agent

Standard processing without dynamic interaction with the website. Suitable for simple data extraction tasks.

Extract example output:

Base cost:

20 credits

Output cost:

4 credits

Total estimated credits:

24credits

FOOTER

The easiest way to extract

data from the web

Backed by

Y Combinator

[Linkedin](https://www.linkedin.com/company/firecrawl) [Github](https://github.com/firecrawl/firecrawl) [YouTube](https://www.youtube.com/@Firecrawl_dev)

SOC II ¬∑ Type 2

AICPA

SOC 2

[X (Twitter)](https://x.com/firecrawl) [Discord](https://discord.gg/gSmWdAkdwd)

Products

[Playground](https://www.firecrawl.dev/playground) [Agent](https://www.firecrawl.dev/agent) [Pricing](https://www.firecrawl.dev/pricing) [Templates](https://www.firecrawl.dev/templates) [Changelog](https://www.firecrawl.dev/changelog)

Use Cases

[AI Platforms](https://www.firecrawl.dev/use-cases/ai-platforms) [Lead Enrichment](https://www.firecrawl.dev/use-cases/lead-enrichment) [SEO Teams](https://www.firecrawl.dev/use-cases/seo-teams) [Deep Research](https://www.firecrawl.dev/use-cases/deep-research) [Competitive Intelligence](https://www.firecrawl.dev/use-cases/competitive-intelligence)

Documentation

[Getting started](https://docs.firecrawl.dev/introduction) [API Reference](https://docs.firecrawl.dev/api-reference/introduction) [Integrations](https://www.firecrawl.dev/app) [Examples](https://docs.firecrawl.dev/use-cases/overview) [SDKs](https://docs.firecrawl.dev/sdks/overview)

Company

[Blog](https://www.firecrawl.dev/blog) [Careers](https://www.firecrawl.dev/careers) [Creator & OSS program](https://www.firecrawl.dev/creator-oss-program) [Student program](https://www.firecrawl.dev/student-program)

¬© 2025 Firecrawl

[Terms of Service](https://www.firecrawl.dev/terms-of-service) [Privacy Policy](https://www.firecrawl.dev/privacy-policy) [Report Abuse](mailto:help@firecrawl.com?subject=Issue:)

[All systems normal](https://status.firecrawl.dev/)

## Multi-Agent Systems Tutorial
Introducing Parallel Agents - Run multiple /agent queries simultaneously. [Read more ‚Üí](https://www.firecrawl.dev/blog/introducing-parallel-agents)

//

Get started

//

### Ready to build?

Start getting Web Data for free and scale seamlessly as your project expands.No credit card needed.

[Start for free](https://www.firecrawl.dev/signin) [See our plans](https://www.firecrawl.dev/pricing)

#### Table of Contents

[Blog](https://www.firecrawl.dev/blog)

Building Multi-Agent Systems With CrewAI - A Comprehensive Tutorial

![placeholder](https://www.firecrawl.dev/_next/image?url=%2Fblog%2Fauthors%2Fbex.jpg&w=48&q=75&dpl=dpl_2hQ8hmy6vNQsu8DPuBRaRM6deLpr)Bex Tuychiev

Jan 26, 2026(updated)

![Building Multi-Agent Systems With CrewAI - A Comprehensive Tutorial image](https://www.firecrawl.dev/_next/image?url=%2Fimages%2Fblog%2Fcrewai-tutorial%2Fcrewai-tutorial.webp&w=3840&q=75&dpl=dpl_2hQ8hmy6vNQsu8DPuBRaRM6deLpr)

## Agent Building Frameworks in 2026

The AI agent market continues to expand in 2026, with strong growth projections for the rest of the decade. The ecosystem has also matured: teams now prioritize production reliability, evals, and tool governance alongside raw capability. [Several open-source frameworks](https://www.firecrawl.dev/blog/best-open-source-agent-frameworks-2025) are now available to developers: LangGraph provides stateful orchestration, Dify offers a low-code approach, and CrewAI ‚Äî the focus of this tutorial ‚Äî has gained momentum with its role-based architecture and streamlined setup process.

This tutorial demonstrates how to use CrewAI to build a multi-agent ChatGPT clone. We'll walk through project initialization, agent definition, task creation, crew orchestration, testing, and UI development. You'll learn to implement CrewAI's role-playing agent system to develop a ChatGPT clone (with a Streamlit UI), providing you with the knowledge to create functional multi-agent systems for practical applications.

## TL;DR

- **CrewAI makes multi-agent systems practical** \- Define specialized roles, goals, and backstories to keep behavior consistent and debuggable
- **Project-based setup scales better** \- Use YAML configs for agents/tasks to separate configuration from code
- **[Agent Tools](https://www.firecrawl.dev/blog/agent-tools) are the real power** \- Firecrawl adds search, deep research, and extraction without managing scraping infrastructure
- **Crew orchestration handles the workflow** \- Coordinate agents and tasks with sequential or deterministic flows
- **A simple Streamlit UI is enough** \- Wrap your crew with a chat interface and iterate quickly

## Overview of CrewAI's Features and Capabilities

CrewAI offers a comprehensive framework built independently from other agent systems, with features designed to address real-world production challenges. Its role-based agent architecture allows developers to create specialized AI workers with defined expertise and responsibilities, enabling complex tasks to be naturally decomposed in ways that reduce maintenance overhead and simplify debugging in production environments.

Key capabilities that translate directly to production value include:

- **Role-Based Agents** \- Specialized workers that maintain consistent behavior across multiple runs, improving system reliability
- **Flexible Tool Integration** \- Connection to external services without brittle dependencies, ensuring deployment stability
- **Intelligent Collaboration** \- Coordinated task management that reduces prompt engineering complexity
- **Dual Workflow Management** \- Options for both autonomous operation and deterministic control flow
- **Enterprise-Ready Design** \- Security-focused architecture with optimized token usage for cost efficiency

The framework's distinguishing characteristic is its dual approach to workflow management. Crews provide autonomous collaboration for scenarios requiring adaptive problem-solving, while Flows offer deterministic, event-driven orchestration with fine-grained state management, ensuring predictable execution paths that satisfy enterprise requirements for auditability and reliability. This balanced approach allows development teams to implement production systems that combine structured processes with intelligent decision-making, optimizing both computational resources and maintainability for enterprise-grade deployments.

## Getting Started With CrewAI

To start building multi-agent systems with CrewAI, we'll create a simple example that searches for flights and processes the results. The following script demonstrates the core components of CrewAI: Agents, Tasks, and a Crew.

### Installation and API Setup

First, install CrewAI and required dependencies:

```
# Install required packages
pip install crewai 'crewai[tools]' firecrawl-py python-dotenv
```

For the Firecrawl search tool, you'll need to:

1. Create a free account at [Firecrawl.dev](https://firecrawl.dev/)

2. Navigate to your account dashboard and generate an API key

3. Create a `.env` file in your project directory with:
























```
FIRECRAWL_API_KEY=fc-your-api-key-here
```


### Step-by-Step Example

Let's break down a basic CrewAI implementation that searches for flights:

```
import warnings
warnings.filterwarnings("ignore")

from crewai import Crew, Task, Agent
from crewai_tools import FirecrawlSearchTool
from dotenv import load_dotenv

# Load environment variables from .env file
load_dotenv()
```

This section imports the necessary libraries and suppresses warnings. We're using CrewAI's core components, the FirecrawlSearchTool for web searches, and dotenv to manage environment variables (like API keys) securely.

```
# Create our tools
flight_search = FirecrawlSearchTool()
```

Here we initialize the FirecrawlSearchTool without specifying a default query. This allows the agent to formulate its own search queries based on the task requirements.

```
# Define our specialized agents
flights_agent = Agent(
    role="Travel Search Specialist",
    goal="Find optimal flight options based on price and convenience",
    backstory="I specialize in discovering the best flight deals across multiple airlines and booking platforms.",
    tools=[flight_search],
    allow_delegation=False,
)

summarize_agent = Agent(
    role="Travel Consultant",
    goal="Create clear, actionable travel recommendations",
    backstory="I translate complex travel data into personalized recommendations that save travelers time and money.",
    allow_delegation=False,
)
```

In this section, we create two specialized agents:

- The Travel Search Specialist finds flight options using the Firecrawl tool
- The Travel Consultant organizes and presents the information

Each agent has a role, goal, and backstory that shape its behavior and responses. The `allow_delegation=False` parameter prevents the agent from delegating tasks to other agents.

```
# Define the tasks our agents will perform
search_task = Task(
    description=(
        "Search for {trip_type} flights from {origin} to {destination} around {travel_date}"
    ),
    expected_output="""
    Top 3 flight options from Chicago to Miami on January 15:
    1. United Airlines: Departs 08:15, Arrives 12:05, Duration: 3h 50m, Price: $178
    2. American Airlines: Departs 10:30, Arrives 14:10, Duration: 3h 40m, Price: $195
    3. Southwest: Departs 13:45, Arrives 17:20, Duration: 3h 35m, Price: $210
    """,
    agent=flights_agent,
)

booking_options_task = Task(
    description="Analyze booking options for the flights found and recommend the best overall value",
    expected_output="""
    Recommended booking options for Chicago to Miami (Jan 15):

    BEST VALUE: United Airlines
    - Departure: 08:15 (ORD)
    - Arrival: 12:05 (MIA)
    - Duration: 3h 50m
    - Price: $178
    - Booking: Direct through [United.com](https://www.united.com) offers free carry-on
    - Additional: Economy Plus upgrade available for $45

    FASTEST OPTION: Southwest
    - Departure: 13:45 (MDW)
    - Arrival: 17:20 (MIA)
    - Price: $210
    - Booking: [Southwest.com](https://www.southwest.com) includes 2 free checked bags
    """,
    agent=summarize_agent,
)
```

Here we define two tasks with a clear division of responsibilities:

1. The `flights_agent` handles searching for flight information
2. The `summarize_agent` analyzes the options and creates customer-friendly recommendations

The task description accepts variables in curly braces like `{origin}`, which will be filled in when the crew runs. The expected\_output provides a template that helps guide the agent's response format.

```
# Assemble the crew with our agents and tasks
crew = Crew(
    agents=[flights_agent, summarize_agent],
    tasks=[search_task, booking_options_task],
    verbose=True,  # Show detailed execution logs
)
```

The Crew brings together our agents and tasks. It manages the workflow and coordinates how tasks are executed. We've set `verbose=True` to show detailed logs during execution, which helps with monitoring and debugging.

```
# Execute the crew's work
if __name__ == "__main__":
    result = crew.kickoff(
        inputs={
            "trip_type": "one-way",
            "origin": "New York",
            "destination": "London",
            "travel_date": "June 15th, 2026",
        }
    )

    print(result)
```

Finally, we execute our crew with the `kickoff()` method, providing specific inputs for an international flight from New York to London. The crew will handle the sequential execution of tasks, with the flights\_agent first searching for options, and then the summarize\_agent creating a polished recommendation based on those findings.

```
Recommended booking options for New York to London (June 15, 2026):

BEST VALUE: American Airlines
- Departure: 19:00 (JFK)
- Arrival: 07:30 (+1 day) (LHR)
- Duration: 7h 30m
- Price: $285
- Booking: Direct through [American Airlines](https://www.aa.com) website offers straightforward booking and reliable service
- Additional: Competitive price with only a slight increase in duration compared to the fastest flight; good balance of cost and schedule

...
```

This example only scratches the surface of CrewAI's capabilities. The framework supports more advanced features like complex workflow management, hierarchical agent structures, memory systems for context retention, and integration with various tools and services that can dramatically enhance your multi-agent applications' power and flexibility. As you continue following along the tutorial, you will see some of these features for yourself.

## Firecrawl: the Best Friend of LLMs and Agents

Before we dive into the tutorial, let's explore the Firecrawl tool we used to search for flights. Firecrawl is an AI-powered web scraping engine that bridges the gap between complex web content and AI agents, converting websites into clean, structured data that models can process effectively.

Key capabilities that make Firecrawl valuable for agent development include:

- **Intelligent Navigation** \- Handles dynamic content, pagination, and multi-step processes
- **Format Flexibility** \- Converts web content to markdown, HTML, or structured data
- **Clean Data Extraction** \- Removes noise like ads and navigation elements
- **Search Integration** \- Processes natural language queries for contextual web results
- **Web scraping** \- Can scrape arbitrary information from open websites with just a prompt
- **API-First Design** \- Integrates with frameworks like CrewAI through standardized tooling

Using Firecrawl involves a straightforward API approach, as shown in this example:

```
from firecrawl import FirecrawlApp

app = FirecrawlApp(api_key="fc-your-api-key")

# Scrape a URL and convert it to markdown
result = app.scrape_url(
    "https://example.com/product-page",
    {
        "formats": ["markdown"],
        "onlyMainContent": True  # Remove headers, footers, navigation
    }
)

print(result["markdown"])
```

Throughout this tutorial, we'll implement Firecrawl as a tool for our CrewAI agents, providing them with web scraping, search, and research capabilities. This integration allows agents to access current information from the web while maintaining focus on their core tasks. By handling the technical aspects of web interaction, Firecrawl lets developers concentrate on enhancing agent reasoning and decision-making rather than managing web extraction complexities.

If you're interested in exploring these capabilities further, you can find additional information at [firecrawl.dev](https://firecrawl.dev/).

## Creating Multi-Agent Applications With CrewAI

In the "Getting started" section, we covered the very basics of CrewAI in a script-based environment. However, to get the full benefits of the framework, we are going to use the recommended project-based configuration to build a ChatGPT clone. Through this example, you will get a feel of how multi-agent systems are built in CrewAI by creating a more complex crew of agents with access to more custom built tools and a user-friendly UI. In the end, our application will have the following features:

- General conversation assistant
- Access to real-time information with [Firecrawl's search endpoint](https://docs.firecrawl.dev/features/search)
- Perform in-depth research and analysis with [Firecrawl's deep research endpoint](https://docs.firecrawl.dev/features/alpha/deep-research)
- Extract information with just a prompt from arbitrary websites with [Firecrawl's extract endpoint](https://docs.firecrawl.dev/features/extract)
- Generate images with OpenAI's Dall-E 3 model

Here is the application UI:

![Screenshot of the ChatGPT clone application built with CrewAI showing the conversation interface with search and research capabilities](https://www.firecrawl.dev/images/blog/crewai-tutorial/screenshot.png)

In the following steps, we will explain almost every aspect of the project. However, we may omit certain code parts or sections to reduce repetitive explanations. For this reason, we highly recommend you follow along the tutorial by opening [the project repo for this article](https://github.com/firecrawl/firecrawl-app-examples/tree/main/crewai-tutorial) in a separate tab.

With that said, let's get started!

### Step 1: Initializing and Configuring a Project

To create our ChatGPT clone using CrewAI, we first need to set up the project structure. CrewAI provides a CLI tool that generates a standardized project structure, which offers significant advantages over a script-based approach.

1. **Install CrewAI CLI and uv package manager**:
























```
pip install crewai-cli uv
```

2. **Create a new project folder with standardized structure**:
























```
crewai create crew crewai_chatgpt_clone
cd crewai_chatgpt_clone
```








This command generates the following directory structure:
























```
crewai_chatgpt_clone/
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îî‚îÄ‚îÄ crewai_chatgpt_clone/
‚îÇ       ‚îú‚îÄ‚îÄ __init__.py
‚îÇ       ‚îú‚îÄ‚îÄ main.py
‚îÇ       ‚îú‚îÄ‚îÄ crew.py
‚îÇ       ‚îú‚îÄ‚îÄ config/
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ agents.yaml   # Agent definitions in YAML
‚îÇ       ‚îÇ   ‚îî‚îÄ‚îÄ tasks.yaml    # Task definitions in YAML
‚îÇ       ‚îî‚îÄ‚îÄ tools/            # Custom tools directory
‚îî‚îÄ‚îÄ .env                      # Environment variables
```


**Benefits of this structure**:

- Separation of concerns (agents, tasks, tools)
- YAML configuration for clean, readable agent/task definitions
- Easier maintenance and collaboration
- Standardized format that follows Python packaging best practices
- Support for complex projects with multiple agents and tasks

We will talk more about these later on.

3. **Set up environment variables**:
Create a `.env` file in your project root with:
























```
# Firecrawl API key for web search, research, and extraction
FIRECRAWL_API_KEY=fc-your-api-key-here

# OpenAI API key for DALL-E image generation
OPENAI_API_KEY=sk-your-openai-key-here
```

4. **Install dependencies using uv**:
First, lock the basic CrewAI dependencies:
























```
crewai install
```








Then add project-specific dependencies:
























```
uv add streamlit firecrawl-py openai python-dotenv
```


The project-based approach with YAML configuration files makes agent systems much more maintainable than single-script solutions. The YAML files allow non-technical users to adjust agent properties without touching code, while developers can focus on implementing tools and business logic. This separation creates a clean architecture that scales well as your agent system grows in complexity.

### Step 2: Defining agents

Agents are the core building blocks of any CrewAI application. They represent specialized AI personas with specific roles, goals, and backstories that shape how they approach tasks. In our ChatGPT clone, we'll define multiple specialized agents that work together to handle different types of requests.

#### Using YAML for agent configuration

Notice that we're using YAML files to define our agents rather than directly instantiating `Agent` classes as we did in the getting started example. This approach offers several advantages:

- **Separation of concerns**: Keeps configuration separate from implementation code
- **Readability**: YAML is more human-readable and easier to maintain
- **Non-technical editing**: Team members without Python knowledge can modify agent definitions
- **Consistency**: Standardized format for all agent definitions in one place
- **Version control friendly**: Changes to agent configurations are easier to track

Here's how our `config/agents.yaml` file looks for the ChatGPT clone:

```
chat_agent:
  role: >
    Conversational Assistant
  goal: >
    Understand the user's intent and provide useful, concise, and context-aware answers by orchestrating specialized agents when necessary. Here is the user's query: {user_input}
  backstory: >
    You're the primary interface to the user. You understand conversation context, identify the type of help needed, and either answer directly or delegate to a search, research, scraping or image generation agent.
  allow_delegation: true
```

Notice the use of `{user_input}` in the `goal` field. This is a variable placeholder that will be dynamically replaced with the actual user's query when we pass inputs to our agent system later. These placeholders allow our agents to receive and process contextual information at runtime, and you'll see their importance when we start passing inputs to the system.

#### The role-goal-backstory framework

CrewAI uses a powerful framework for agent definition that consists of three key elements:

1. **role**: Defines what the agent does and their area of expertise
2. **goal**: Directs the agent's efforts and shapes their decision-making
3. **backstory**: Gives depth to the agent, influencing how they approach problems

#### Advanced agent configuration options

Beyond the basic role-goal-backstory framework, CrewAI offers several additional configuration options for fine-tuning agent behavior:

| Option | Description |
| --- | --- |
| `llm` | The model name you want to use (you must configure API key for it as well in that case) |
| `allow_delegation` | Controls whether the agent can request help from other agents (default: `False`) |
| `verbose` | Enables detailed logging of agent actions for debugging |
| `max_rpm` | Limits requests per minute to external services (`None` for unlimited) |
| `max_iter` | Maximum iterations an agent can perform for a task (default: `25`) |
| `max_execution_time` | Sets a time limit for task completion |
| `tools` | Array of tools the agent can use (defined in Python code) |
| `cache` | Determines if the agent should cache tool usage results |
| `respect_context_window` | Enables sliding context window to maintain appropriate size |
| `max_retry_limit` | Sets maximum number of retries on errors |

In our implementation, we'll connect these YAML definitions to actual tools in the `crew.py` file later in the process.

#### Understanding delegation

Delegation is a powerful capability that allows agents to collaborate by requesting assistance from other agents. In our ChatGPT clone, only the main `chat_agent` has delegation enabled:

```
chat_agent:
  # ... other configuration ...
  allow_delegation: true

search_agent:
  # ... other configuration ...
  allow_delegation: false
```

The `chat_agent` can delegate tasks to specialized agents when it recognizes that their expertise is needed. For example:

- When factual information is needed ‚Üí delegates to the `search_agent`
- For in-depth analysis ‚Üí delegates to the `research_agent`
- For extracting data from websites ‚Üí delegates to the `scraper_agent`
- For creating images ‚Üí delegates to the `image_agent`

This creates a hierarchical structure where the `chat_agent` acts as a coordinator, determining which specialized agent is best suited to handle specific parts of the user's request.

#### Specialized agents for our ChatGPT clone

Let's look at our complete set of specialized agents:

```
search_agent:
  role: >
    Real-Time Search Expert
  goal: >
    Use Firecrawl's general search capability to find accurate and current answers to specific user queries. Here is the user's query: {user_input}
  backstory: >
    You specialize in quick, high-level answers by searching the web in real-time using Firecrawl's search engine. You respond with clear summaries and citations.
  allow_delegation: false

research_agent:
  role: >
    Deep Research Analyst
  goal: >
    Use Firecrawl's deep research mode to generate detailed, structured research reports on complex topics. Here is the user's query: {user_input}
  backstory: >
    You're an analytical AI built for thorough research. You extract in-depth information from multiple sources using Firecrawl and return organized summaries and insights.
  allow_delegation: false
```

Each agent definition includes the `{user_input}` variable in the `goal` field, ensuring that all agents receive the user's query when tasks are executed.

#### Best practices for agent design

When designing your agents, follow these key principles:

1. **Specialists over generalists**: Agents perform better with specialized roles rather than general ones.
2. **The 80/20 rule**: While agent design is important, remember that 80% of your effort should go into designing tasks, and only 20% into defining agents.
3. **Complementary skills**: Design agents with distinct but complementary abilities that work well together.
4. **Clear purpose**: Each agent should have a clearly defined purpose that doesn't overlap too much with other agents.

For a full list of agent attributes and advanced options, see the [CrewAI agents documentation](https://docs.crewai.com/concepts/agents).

Remember that agent design is an iterative process. Start with these definitions, observe how they perform in practice, and refine them based on the results.

### Step 3: Defining tasks

After defining our specialized agents, the next step is to create tasks for them to perform. Tasks in CrewAI are specific assignments that are completed by agents. Each task provides the necessary instructions and context for an agent to successfully execute its work.

#### Using YAML for task configuration

Similar to our agent definitions, we'll use YAML to configure tasks in our ChatGPT clone. This approach provides the same benefits of readability, maintainability, and separation of concerns. Let's examine the `config/tasks.yaml` file:

```
answer_user_query_task:
  description: >
    Process the user's message and classify its intent into one of the following:
    1. General question (answer yourself),
    2. Real-time factual lookup (delegate to Search Agent),
    3. Comprehensive research (delegate to Research Agent),
    4. Web scraping (delegate to Scraper Agent),
    5. Image generation (delegate to Image Agent).

    Based on the intent, trigger the appropriate agent, compile their response, and deliver a final, well-structured answer to the user.
  expected_output: >
    A finalized user response. This can include:
    - Text answers
    - Image links (with short captions)
    - Research summaries
    - Scraped data in markdown or tabular format
```

#### Task attributes explained

The key components of a task definition include:

1. **`description`**: Clear instructions for what the agent needs to do. In our ChatGPT clone, the `description` guides the `chat_agent` to classify user intent and delegate to specialized agents when appropriate.

2. **`expected_output`**: A description of what the completed task should look like. This helps guide the agent's response format and content.

3. **`agent`** (optional, not shown in our example): Specifies which agent should perform the task. We'll connect our task to the appropriate agent in the `crew.py` file later.


Other optional attributes include:

- **`context`**: References to other tasks whose outputs should be used as context
- **`output_file`**: Path for saving task output to a file
- **`tools`**: Specific tools the agent can use for this particular task
- **`human_input`**: Whether human review is required before completion

For a full list of task attributes and advanced options, see the [CrewAI tasks documentation](https://docs.crewai.com/concepts/tasks).

#### Understanding our ChatGPT clone task

Our ChatGPT clone uses a single task called `answer_user_query_task`. This task is responsible for:

1. Processing the user's message and determining its intent
2. Deciding whether to answer directly or delegate to a specialized agent
3. Compiling the response and delivering it to the user

This task design leverages the delegation capability we enabled for the `chat_agent`. When a user asks about current events, for example, the `chat_agent` will recognize this requires real-time information and delegate to the `search_agent`.

#### Best practices for task design

When designing tasks for your own CrewAI applications, remember these principles:

1. **Single purpose, single output**: Each task should have a clear, specific objective.
2. **Be explicit about inputs and outputs**: Clearly define what the task receives and what it should produce.
3. **Include purpose and context**: Help the agent understand why the task matters and how it fits into the larger workflow.
4. **The 80/20 rule**: Remember that 80% of your effort should go into designing tasks, as even well-designed agents will fail with poorly designed tasks.

In the next section, we'll see how to give the actual power to our agents by implementing custom tools.

### Step 4: Implementing custom tools

Before we create our crew, we need to implement the custom tools that our specialized agents will use to interact with external services. In CrewAI, tools provide agents with capabilities to perform specific actions like searching the web, generating images, or extracting data from websites.

#### Understanding CrewAI tools

Tools in CrewAI are Python functions decorated with `@tool` that agents can invoke to accomplish specific tasks. Each tool has:

- A name that describes its purpose
- A function that performs the actual work
- A docstring that explains how to use the tool (critical for agent understanding)

For our ChatGPT clone, we'll implement four custom tools using Firecrawl and OpenAI APIs:

#### Using the @tool decorator

The simplest way to create a custom tool is using the `@tool` decorator. Let's look at our implementation of the Firecrawl search tool:

```
# src/chatgpt_clone/tools/firecrawl_search_tool.py

from crewai.tools import tool
from firecrawl import FirecrawlApp

@tool("Quick Web Search with Firecrawl")
def firecrawl_search_tool(query: str) -> str:
    """Performs a quick real-time search using Firecrawl and returns summarized results."""
    app = FirecrawlApp()
    result = app.search(query)
    if not result.success:
        return "Search failed."

    summary = "\n\n".join(
        [\
            f"{item['title']}\n{item['url']}\n{item['description']}"\
            for item in result.data[:5]\
        ]
    )
    return f"Top Search Results:\n\n{summary}"
```

The `@tool` decorator transforms our function into a tool that agents can use. The function:

1. Takes a search query as input
2. Creates a FirecrawlApp instance
3. Performs a search and formats the results
4. Returns formatted results for the agent to process

#### Custom tools for our ChatGPT clone

Let's explore the four custom tools we've implemented for our application:

1. **Firecrawl Search Tool**: Enables real-time web searches to retrieve current information
2. **Firecrawl Research Tool**: Conducts in-depth research on complex topics
3. **Firecrawl Extract Tool**: Extracts specific data from websites based on a URL and instructions
4. **OpenAI Image Tool**: Generates images using OpenAI's DALL-E API

The extract tool is particularly interesting as it handles a composite input:

```
@tool("Web Data Extraction with Firecrawl")
def firecrawl_extract_tool(input_data: str) -> str:
    """Extracts data from a website using Firecrawl.

    Input should be in the format: "URL|extraction instructions"
    Example: "https://github.com/trending|Extract the top 5 trending repositories"
    """
    parts = input_data.split("|", 1)
    if len(parts) != 2:
        return "Invalid input format. Please use: URL|extraction instructions"

    url, instructions = parts
    # Implementation details...
```

This tool parses its input to extract both a URL and instructions, allowing the agent to provide complex extraction commands.

#### Testing custom tools

It's important to test tools before integrating them with agents. We've created a `test_tools.py` file to verify each tool works correctly:

```
def test_firecrawl_search():
    print("\nüî• Testing Firecrawl Search...")
    print(firecrawl_search_tool.run("What is the capital of France?"))

def test_firecrawl_research():
    print("\nüìö Testing Firecrawl Deep Research...")
    print(
        firecrawl_research_tool.run(
            "Best Android tablets for seniors to read ebooks and watch videos"
        )
    )
```

Running this test script helps ensure our tools function properly before we connect them to our agents.

#### Best practices for custom tools

When building your own tools, follow these guidelines:

1. **Clear docstrings**: Write detailed descriptions as they guide the agent in using the tool correctly
2. **Input validation**: Validate inputs early to prevent runtime errors
3. **Error handling**: Gracefully handle failures so agents can understand what went wrong
4. **Return structured data**: Format outputs consistently to make them easier for agents to process
5. **Keep tools focused**: Each tool should do one thing well, following the single responsibility principle

For more advanced tool implementations, such as creating tools by subclassing `BaseTool` or implementing caching strategies, see the [CrewAI custom tools documentation](https://docs.crewai.com/how-to/create-custom-tools).

In the next section, we'll combine our agents, tasks, and tools by creating a crew that coordinates their work.

### Step 5: Creating a crew

Now that we've defined our agents, tasks, and implemented custom tools, it's time to bring everything together by creating a crew. In CrewAI, a crew represents a collaborative group of agents working together to accomplish tasks. The crew defines the strategy for task execution, agent collaboration, and the overall workflow.

#### Using the CrewBase decorator pattern

Our ChatGPT clone uses the recommended `@CrewBase` decorator pattern to structure our application. This approach provides a clean, organized way to define agents, tasks, and the crew itself. Let's examine our `crew.py` file:

```
@CrewBase
class ChatgptCloneCrew:
    """ChatgptCloneCrew using CrewBase for structured agent and task definition."""

    agents_config = "config/agents.yaml"
    tasks_config = "config/tasks.yaml"

    # Added type hints
    agents: List[BaseAgent]
    tasks: List[Task]
```

The `@CrewBase` decorator automatically handles many boilerplate tasks for us. Notice how we specify the paths to our YAML configuration files with `agents_config` and `tasks_config`. This connects our YAML definitions to our code.

#### Connecting agents to tools

For each agent defined in our YAML file, we create a corresponding method decorated with `@agent` that returns an `Agent` instance. This is where we connect our agents to the custom tools we created in step 4:

```
@agent
def search_agent(self) -> Agent:
    return Agent(
        config=self.agents_config["search_agent"],  # type: ignore[index]
        tools=[firecrawl_search_tool],
        verbose=True,
    )
```

Each agent method:

1. Uses the YAML configuration from our `agents.yaml` file
2. Connects the agent to its specific tools (like `firecrawl_search_tool` for the `search_agent`)
3. Sets additional parameters like `verbose=True` for detailed logging

Notice how each specialized agent is matched with the appropriate tool:

- The `search_agent` gets the `firecrawl_search_tool`
- The `research_agent` gets the `firecrawl_research_tool`
- The `scraper_agent` gets the `firecrawl_extract_tool`
- The `image_agent` gets the `openai_image_tool`

This pairing of specialized agents with specialized tools creates a powerful combination of capabilities.

#### Connecting tasks to agents

Similarly, we create methods decorated with `@task` for each task:

```
@task
def answer_user_query_task(self) -> Task:
    """Task to process the user's query, classify intent, delegate, and compile the final response."""
    return Task(
        config=self.tasks_config["answer_user_query_task"],  # type: ignore[index]
        agent=self.chat_agent(),  # This task is primarily handled by the chat_agent
    )
```

Notice how we explicitly connect the task to the `chat_agent()`. This is where we specify which agent is responsible for executing the task. In our case, the main `chat_agent` will handle the task and delegate to specialized agents as needed.

#### Assembling the crew

Finally, we create a method decorated with `@crew` that brings everything together:

```
@crew
def crew(self) -> Crew:
    return Crew(
        agents=self.agents,  # Populated by @agent decorators
        tasks=self.tasks,    # Populated by @task decorators
        process=Process.sequential,
        verbose=True,
    )
```

The `@CrewBase` decorator automatically populates `self.agents` and `self.tasks` with the agents and tasks we defined. We also specify:

- `process=Process.sequential`: Tasks are executed in order
- `verbose=True`: Detailed logging is enabled

#### Advanced crew features

CrewAI offers several powerful features that will be valuable as your application grows:

##### Execution processes

While our ChatGPT clone uses a simple sequential process, CrewAI also supports a hierarchical process:

- **Sequential Process**: Tasks are executed one after another (what we're using)
- **Hierarchical Process**: A manager agent coordinates the crew, delegating tasks and validating outcomes before proceeding

##### Flexible kickoff methods

CrewAI provides several methods for executing your crew:

```
# Standard kickoff with a single input
result = crew_instance.crew().kickoff(inputs={"user_input": user_query})

# Process multiple inputs in sequence
results = crew_instance.crew().kickoff_for_each(inputs=[{"user_input": "Query 1"}, {"user_input": "Query 2"}])

# Asynchronous execution
async_result = await crew_instance.crew().kickoff_async(inputs={"user_input": user_query})
```

These options will be valuable for scaling your application to handle multiple requests simultaneously.

##### Structured outputs

Crews return a `CrewOutput` object that provides multiple ways to access results:

```
crew_output = crew.kickoff(inputs={"user_input": "Tell me about AI"})

# Access as raw text
print(crew_output.raw)

# Access as structured data (if configured)
if crew_output.json_dict:
    print(crew_output.json_dict)
```

##### Memory and logging

For more advanced applications, you can add memory and detailed logging:

```
crew = Crew(
    # ... other parameters ...
    memory=True,  # Enable memory for learning over time
    output_log_file="chat_logs.json",  # Save detailed logs
)
```

For a complete exploration of crew capabilities, see the [CrewAI crews documentation](https://docs.crewai.com/concepts/crews).

#### Running the crew

After setting up our crew, we can execute it with the `kickoff()` method, passing any required inputs:

```
def run_chat(user_input):
    crew_instance = ChatgptCloneCrew()
    result = crew_instance.crew().kickoff(inputs={"user_input": user_input})
    return result
```

This passes the user's input to our agents through the `{user_input}` variable we defined in our YAML configurations. When executed, our custom tools will enable the specialized agents to search the web, conduct research, extract data from websites, and generate images as needed.

In the next section, we'll test our crew to see how our agents collaborate to provide responses to user queries.

### Step 6: Testing and running your crew

After building our agents, defining tasks, implementing custom tools, and creating our crew, it's time to test our ChatGPT clone and see how the agents collaborate. Let's examine how to execute our crew based on user input.

#### Understanding the main.py file

The `main.py` file serves as the entry point for our application, handling the initialization and execution of our crew:

```
#!/usr/bin/env python
import os
from crewai_chatgpt_clone.crew import ChatgptCloneCrew

os.makedirs("output", exist_ok=True)

def run():
    """Run the ChatGPT clone crew."""
    user_query = "Come up with beautiful new words for English that hold deep meaning."
    print(f"Running crew with user input: {user_query}")

    inputs = {"user_input": user_query}
    crew_instance = ChatgptCloneCrew()
    result = crew_instance.crew().kickoff(inputs=inputs)

    # Print the result
    print("\n\n=== CREW RESPONSE ===\n\n")
    if hasattr(result, "raw"):
        print(result.raw)
    else:
        print(result)

if __name__ == "__main__":
    run()
```

This file:

1. Creates an output directory for any generated files
2. Defines a hardcoded user query (which you can replace with dynamic input if you want)
3. Initializes the `ChatgptCloneCrew` instance
4. Passes the user input to the crew via the `kickoff()` method
5. Displays the result

Here, the `user_input` variable defined in the YAML files directly play a part as the name of that variable must match in this file as well.

#### Running the crew with the CrewAI CLI

The CrewAI CLI also provides convenient commands for running and testing your crew. Here's how to use them:

##### Using the crewai run command

The simplest way to run your crew is with the `crewai run` command:

```
crewai run
```

This command:

- Automatically detects your project structure
- Finds your `main.py` file and executes it
- Handles environment variables from your `.env` file
- Displays the output in your terminal

##### Advanced CLI usage

You can customize the run command with various options:

```
# Run with a specific input
crewai run --input '{"user_input": "Tell me about quantum computing"}'

# Run with verbose output for debugging
crewai run --verbose

# Specify a custom entry point
crewai run --entry-point custom_main.py
```

#### Testing individual tools

Before running the full crew, it's often helpful to test the individual tools to ensure they're working correctly. You can use the `test_tools.py` file we created earlier:

```
python -m src.crewai_chatgpt_clone.test_tools
```

This will run all the test functions, verifying that each tool:

1. Can connect to its respective API
2. Returns the expected format of data
3. Handles errors gracefully

#### Troubleshooting common issues

If you encounter problems during execution:

1. **API key issues**: Ensure your API keys are correctly set in your .env file
2. **Missing dependencies**: Run `crewai install` to ensure all dependencies are installed
3. **Rate limiting**: Check if you're hitting API rate limits (especially with the OpenAI API)
4. **Tool errors**: Look for error messages in the tool responses

By following these steps, you can effectively test and run your ChatGPT clone, making iterative improvements to enhance its capabilities. In production environments, you'd typically integrate this with a user interface like the Streamlit app we are going to build in the next section, allowing users to interact with your crew directly.

### Step 7: Building a UI around your crew

Finally, let's create a user interface to allow users to interact with our ChatGPT clone. We'll use Streamlit, a popular Python framework for building data apps, to create a chat interface that connects to our crew.

#### Creating a Streamlit chat interface

Our `app.py` script implements a chat interface similar to ChatGPT, with a message history, input field, and smooth response rendering:

```
import streamlit as st
from crewai_chatgpt_clone.crew import ChatgptCloneCrew
import time
import gc
import base64

# Session state initialization for chat history
if "messages" not in st.session_state:
    st.session_state.messages = []

    # Add initial welcome message
    welcome_message = """
Hello! I can assist you with a variety of tasks using specialized agents:

1. **General Questions** - I can answer general knowledge questions
2. **Web Search** - I can search the web for real-time information
3. **In-depth Research** - I can conduct comprehensive research on topics
4. **Web Scraping** - I can extract specific data from websites
5. **Image Generation** - I can create images based on descriptions

What would you like help with today?
"""
    st.session_state.messages.append({"role": "assistant", "content": welcome_message})
```

This code initializes the chat history and creates a welcome message explaining the capabilities of our ChatGPT clone.

#### Connecting the UI to the crew

The core functionality happens when a user submits a query. Our app processes the query using our CrewAI crew and displays the response:

```
# Check if we need to generate a response
if st.session_state.messages and st.session_state.messages[-1]["role"] == "user":
    user_query = st.session_state.messages[-1]["content"]

    with st.chat_message("assistant"):
        with st.spinner("Processing your query..."):
            crew_instance = ChatgptCloneCrew()
            inputs = {"user_input": user_query}

            try:
                result_obj = crew_instance.crew().kickoff(inputs=inputs)

                # Extract response text
                if hasattr(result_obj, "raw") and isinstance(result_obj.raw, str):
                    response_text = result_obj.raw
                elif isinstance(result_obj, str):
                    response_text = result_obj
                else:
                    response_text = str(result_obj)

                # Display response with typewriter effect
                # ...
```

This section:

1. Gets the user's query from the session state
2. Creates a ChatgptCloneCrew instance
3. Passes the query to the crew's kickoff method
4. Extracts and displays the response

#### Enhancing the user experience

Our app includes several features to enhance the user experience:

1. **Typewriter effect**: Text appears character by character, simulating typing:
























```
# Typewriter effect
message_placeholder = st.empty()
full_response = ""

for char in response_text:
       full_response += char
       message_placeholder.markdown(full_response + "‚ñå")
       time.sleep(0.01)
```

2. **Chat history**: Conversations are stored in the session state and displayed in a chat-like interface:
























```
# Display existing chat messages
for message in st.session_state.messages:
       with st.chat_message(message["role"]):
           st.markdown(message["content"])
```

3. **Reset functionality**: Users can clear the chat history with a reset button:
























```
if st.button("üóëÔ∏è", help="Clear chat history"):
       reset_chat()
       st.rerun()
```


#### Running the Streamlit app

To run the app, execute the following command:

```
streamlit run src/crewai_chatgpt_clone/app.py
```

This will start a local server and open the app in your browser. You can now interact with your ChatGPT clone through the chat interface, asking questions, searching the web, conducting research, extracting data from websites, and generating images.

The combination of CrewAI for backend intelligence and Streamlit for frontend interaction creates a powerful, user-friendly application that resembles commercial AI assistants while being fully customizable to your specific needs.

## Conclusion

Throughout this tutorial, we've built a ChatGPT clone using CrewAI's multi-agent architecture. We started with project initialization, defined specialized agents using the role-goal-backstory framework, created tasks, implemented custom tools using Firecrawl's capabilities, assembled a crew with the `CrewBase` pattern, and added a user-friendly Streamlit interface. This project demonstrates how CrewAI enables the creation of sophisticated agent systems that can handle a wide variety of user requests through specialized agents working collaboratively.

While our implementation is functional, there's significant room for enhancement. Consider exploring [CrewAI's memory capabilities](https://docs.crewai.com/concepts/memory) for context retention across conversations, implementing [custom LLM connections](https://docs.crewai.com/learn/connect-to-any-llm) for model flexibility, using [hierarchical processes](https://docs.crewai.com/learn/hierarchical-process) for more complex workflows, or adding [guardrails](https://docs.crewai.com/concepts/tasks#task-guardrails) for better output validation.

For production-grade applications, [CrewAI Flows](https://docs.crewai.com/concepts/flows) offers more deterministic orchestration with fine-grained state management. The integration with [Firecrawl](https://firecrawl.dev/) plays a crucial role in this application, providing real-time information access, structured web scraping, and in-depth research capabilities that bridge the knowledge gap between LLMs and the real world. This combination of agent orchestration with web-aware tools unlocks practical applications that can go beyond simple chatbots to truly assist users with complex, dynamic information needs.

## Frequently Asked Questions

### What is CrewAI used for?

CrewAI is used to build multi-agent systems where specialized AI workers collaborate on tasks with clear roles, goals, and workflows.

### Do I need Python to use CrewAI?

Yes. CrewAI is a Python framework, and most integrations and tooling are built around Python workflows.

### What is the difference between Crews and Flows?

Crews enable autonomous collaboration, while Flows provide deterministic, event-driven orchestration with tighter control and state management.

### How do CrewAI agents use tools?

Agents can be wired to tools that perform actions like web search, data extraction, or image generation, and tasks decide when tools are invoked.

### Can I add real-time web data to CrewAI?

Yes. You can connect tools like Firecrawl to search, scrape, and extract live web data so your agents can answer up-to-date questions.

### Is CrewAI good for production systems?

It can be, as long as you add evals, logging, and guardrails around tool usage and outputs to ensure reliability.

\[ CTA \]

\[ CRAWL \]

\[ SCRAPE \]

\[ CTA \]

//

Get started

//

Ready to build?

Start getting Web Data for free and scale seamlessly as your project expands. No credit card needed.

[Start for free](https://www.firecrawl.dev/signin) [See our plans](https://www.firecrawl.dev/pricing)

![placeholder](https://www.firecrawl.dev/_next/image?url=%2Fblog%2Fauthors%2Fbex.jpg&w=128&q=75&dpl=dpl_2hQ8hmy6vNQsu8DPuBRaRM6deLpr)

Bex Tuychiev [@bextuychiev](https://x.com/bextuychiev)

Technical Writer at Firecrawl

About the Author

Bex Tuychiev is a Technical Writer at Firecrawl and a Kaggle Master with over 15k followers. He loves writing detailed guides, tutorials, and notebooks on complex data science and machine learning topics

More articles by Bex Tuychiev

[22 Python Web Scraping Projects: From Beginner to Advanced](https://www.firecrawl.dev/blog/python-web-scraping-projects) [15 Best MCP Servers You Can Add to Cursor For 10x Productivity](https://www.firecrawl.dev/blog/best-mcp-servers-for-cursor) [Building Multi-Agent Systems With CrewAI - A Comprehensive Tutorial](https://www.firecrawl.dev/blog/crewai-multi-agent-systems-tutorial) [How to Build MCP Servers in Python: Complete FastMCP Tutorial for AI Developers](https://www.firecrawl.dev/blog/fastmcp-tutorial-building-mcp-servers-python) [Data Enrichment: A Complete Guide to Enhancing Your Data Quality](https://www.firecrawl.dev/blog/complete-guide-to-data-enrichment) [Top 10 Browser Automation Tools for Web Testing and Scraping in 2026](https://www.firecrawl.dev/blog/browser-automation-tools-comparison-2025) [How to Create a Claude Code Skill: A Web Scraping Example with Firecrawl](https://www.firecrawl.dev/blog/claude-code-skill) [Best Open-Source Web Crawlers in 2026](https://www.firecrawl.dev/blog/best-open-source-web-crawler) [Scraper vs Crawler: When to Use Each (With Examples)](https://www.firecrawl.dev/blog/scraper-vs-crawler) [15 Best Open-Source RAG Frameworks in 2026](https://www.firecrawl.dev/blog/best-open-source-rag-frameworks)

FOOTER

The easiest way to extract

data from the web

Backed by

Y Combinator

[Linkedin](https://www.linkedin.com/company/firecrawl) [Github](https://github.com/firecrawl/firecrawl) [YouTube](https://www.youtube.com/@Firecrawl_dev)

SOC II ¬∑ Type 2

AICPA

SOC 2

[X (Twitter)](https://x.com/firecrawl) [Discord](https://discord.gg/gSmWdAkdwd)

Products

[Playground](https://www.firecrawl.dev/playground) [Agent](https://www.firecrawl.dev/agent) [Pricing](https://www.firecrawl.dev/pricing) [Templates](https://www.firecrawl.dev/templates) [Changelog](https://www.firecrawl.dev/changelog)

Use Cases

[AI Platforms](https://www.firecrawl.dev/use-cases/ai-platforms) [Lead Enrichment](https://www.firecrawl.dev/use-cases/lead-enrichment) [SEO Teams](https://www.firecrawl.dev/use-cases/seo-teams) [Deep Research](https://www.firecrawl.dev/use-cases/deep-research) [Competitive Intelligence](https://www.firecrawl.dev/use-cases/competitive-intelligence)

Documentation

[Getting started](https://docs.firecrawl.dev/introduction) [API Reference](https://docs.firecrawl.dev/api-reference/introduction) [Integrations](https://www.firecrawl.dev/app) [Examples](https://docs.firecrawl.dev/use-cases/overview) [SDKs](https://docs.firecrawl.dev/sdks/overview)

Company

[Blog](https://www.firecrawl.dev/blog) [Careers](https://www.firecrawl.dev/careers) [Creator & OSS program](https://www.firecrawl.dev/creator-oss-program) [Student program](https://www.firecrawl.dev/student-program)

¬© 2025 Firecrawl

[Terms of Service](https://www.firecrawl.dev/terms-of-service) [Privacy Policy](https://www.firecrawl.dev/privacy-policy) [Report Abuse](mailto:help@firecrawl.com?subject=Issue:)

[All systems normal](https://status.firecrawl.dev/)

## Batch Web Scraping
Introducing Spark 1 Pro and Spark 1 Mini models in /agent. [Try it now ‚Üí](https://www.firecrawl.dev/agent)

//

Get started

//

### Ready to build?

Start getting Web Data for free and scale seamlessly as your project expands. No credit card needed.

[Start for free](https://www.firecrawl.dev/signin) [See our plans](https://www.firecrawl.dev/pricing)

#### All Questions

[Glossary](https://www.firecrawl.dev/glossary)/ [Web Scraping APIs](https://www.firecrawl.dev/glossary/web-scraping-apis)/Questions

[What is automatic CAPTCHA solving in web scraping?](https://www.firecrawl.dev/glossary/web-scraping-apis/what-is-automatic-captcha-solving-web-scraping)

[What is browser fingerprinting evasion in web scraping?](https://www.firecrawl.dev/glossary/web-scraping-apis/what-is-browser-fingerprinting-evasion-web-scraping)

# What is batch web scraping?

## TL;DR

Batch scraping submits multiple URLs in one request. The service handles parallel processing and returns consolidated results.

## What is batch web scraping?

Instead of making individual API calls per URL, you submit a list. The service processes them in parallel, manages rate limiting, and returns unified results.

| Factor | Sequential | Batch |
| --- | --- | --- |
| API calls | One per URL | One total |
| Speed | Sum of all scrapes | Parallel |
| Error handling | Per-request | Unified |

## Common use cases

- E-commerce catalog scraping
- Competitive price monitoring
- Content aggregation from multiple sources

[Firecrawl's batch endpoint](https://docs.firecrawl.dev/features/batch-scrape) processes URL arrays in parallel with per-URL status tracking.

## Key Takeaways

Batch scraping handles multiple URLs in one request, enabling faster, simpler large-scale extraction.

Last updated: Jan 26, 2026

\[ CTA \]

\[ CRAWL \]

\[ SCRAPE \]

\[ CTA \]

//

Get started

//

Ready to build?

Start getting Web Data for free and scale seamlessly as your project expands. No credit card needed.

[Start for free](https://www.firecrawl.dev/signin) [See our plans](https://www.firecrawl.dev/pricing)

FOOTER

The easiest way to extract

data from the web

Backed by

Y Combinator

[Linkedin](https://www.linkedin.com/company/firecrawl) [Github](https://github.com/firecrawl/firecrawl) [YouTube](https://www.youtube.com/@Firecrawl_dev)

SOC II ¬∑ Type 2

AICPA

SOC 2

[X (Twitter)](https://x.com/firecrawl) [Discord](https://discord.gg/gSmWdAkdwd)

Products

[Playground](https://www.firecrawl.dev/playground) [Agent](https://www.firecrawl.dev/agent) [Pricing](https://www.firecrawl.dev/pricing) [Templates](https://www.firecrawl.dev/templates) [Changelog](https://www.firecrawl.dev/changelog)

Use Cases

[AI Platforms](https://www.firecrawl.dev/use-cases/ai-platforms) [Lead Enrichment](https://www.firecrawl.dev/use-cases/lead-enrichment) [SEO Teams](https://www.firecrawl.dev/use-cases/seo-teams) [Deep Research](https://www.firecrawl.dev/use-cases/deep-research) [Competitive Intelligence](https://www.firecrawl.dev/use-cases/competitive-intelligence)

Documentation

[Getting started](https://docs.firecrawl.dev/introduction) [API Reference](https://docs.firecrawl.dev/api-reference/introduction) [Integrations](https://www.firecrawl.dev/app) [Examples](https://docs.firecrawl.dev/use-cases/overview) [SDKs](https://docs.firecrawl.dev/sdks/overview)

Company

[Blog](https://www.firecrawl.dev/blog) [Careers](https://www.firecrawl.dev/careers) [Creator & OSS program](https://www.firecrawl.dev/creator-oss-program) [Student program](https://www.firecrawl.dev/student-program)

¬© 2025 Firecrawl

[Terms of Service](https://www.firecrawl.dev/terms-of-service) [Privacy Policy](https://www.firecrawl.dev/privacy-policy) [Report Abuse](mailto:help@firecrawl.com?subject=Issue:)

[All systems normal](https://status.firecrawl.dev/)

## Map Endpoint Introduction
Introducing Spark 1 Pro and Spark 1 Mini models in /agent. [Try it now ‚Üí](https://www.firecrawl.dev/agent)

//

Get started

//

### Ready to build?

Start getting Web Data for free and scale seamlessly as your project expands. No credit card needed.

[Start for free](https://www.firecrawl.dev/signin) [See our plans](https://www.firecrawl.dev/pricing)

[Blog](https://www.firecrawl.dev/blog)

Launch Week I / Day 3: Introducing the Map Endpoint

![placeholder](https://www.firecrawl.dev/_next/image?url=%2Fblog%2Fauthors%2Feric-img.jpeg&w=48&q=75&dpl=dpl_2hQ8hmy6vNQsu8DPuBRaRM6deLpr)Eric Ciarla

Aug 28, 2024

![Launch Week I / Day 3: Introducing the Map Endpoint image](https://www.firecrawl.dev/_next/image?url=%2Fimages%2Fblog%2Ffirecrawl-map-endpoint.png&w=3840&q=75&dpl=dpl_2hQ8hmy6vNQsu8DPuBRaRM6deLpr)

Welcome to Day 3 of Firecrawl's first-ever Launch Week! We're thrilled to unveil the Map Endpoint.

**Introducing the Map Endpoint (Alpha)**

This powerful new endpoint allows you to transform a single URL into a comprehensive map of an entire website in record time. It's the fastest and easiest way to gather all the URLs on a website, opening up new possibilities for your web scraping projects.

The Map endpoint is extremely useful when you need to quickly know the links on a website or when you need to scrape pages of a website that are related to a specific topic (using the `search` parameter).

**Getting Started with the Map Endpoint**

Using the new Map endpoint is straightforward. Here's a quick example using our Python SDK:

```
from firecrawl.firecrawl import FirecrawlApp

app = FirecrawlApp(api_key="fc-YOUR_API_KEY")

# Map a website:
map_result = app.map_url('https://firecrawl.dev')
print(map_result)
```

The response will include a list of URLs found on the website:

```
{
  "status": "success",
  "links": [\
    "https://firecrawl.dev",\
    "https://www.firecrawl.dev/pricing",\
    "https://www.firecrawl.dev/blog",\
    "https://www.firecrawl.dev/playground",\
    "https://www.firecrawl.dev/smart-crawl",\
    ...\
  ]
}
```

**What's Next?**

We're just getting started! The Map endpoint opens up exciting possibilities for future features and integrations. Stay tuned for the remaining two days of Launch Week, where we'll be unveiling even more tools to supercharge your web scraping projects.

We can't wait to see how you'll use the Map endpoint in your projects. As always, we welcome your feedback and suggestions to help us improve and refine this new feature.

Happy mapping, and see you tomorrow for Day 4 of Launch Week!

\[ CTA \]

\[ CRAWL \]

\[ SCRAPE \]

\[ CTA \]

//

Get started

//

Ready to build?

Start getting Web Data for free and scale seamlessly as your project expands. No credit card needed.

[Start for free](https://www.firecrawl.dev/signin) [See our plans](https://www.firecrawl.dev/pricing)

![placeholder](https://www.firecrawl.dev/_next/image?url=%2Fblog%2Fauthors%2Feric-img.jpeg&w=128&q=75&dpl=dpl_2hQ8hmy6vNQsu8DPuBRaRM6deLpr)

Eric Ciarla [@ericciarla](https://x.com/ericciarla)

CMO of Firecrawl

About the Author

Eric Ciarla is the cofounder and Chief Marketing Officer (CMO) of Firecrawl. He also worked on Mendable.ai and sold it to companies like Snapchat, Coinbase, and MongoDB. Previously worked at Ford and Fracta as a Data Scientist. Eric also co-founded SideGuide, a tool for learning code within VS Code with 50,000 users.

More articles by Eric Ciarla

[Extract Web Data at Scale With Parallel Agents](https://www.firecrawl.dev/blog/introducing-parallel-agents) [Introducing the Firecrawl Skill and CLI - Give Agents Real-Time Web Data](https://www.firecrawl.dev/blog/introducing-firecrawl-skill-and-cli) [How Credal Extracts 6M+ URLs Monthly to Power Production AI Agents](https://www.firecrawl.dev/blog/credal-firecrawl-ai-agents) [How to Create an llms.txt File for Any Website](https://www.firecrawl.dev/blog/How-to-Create-an-llms-txt-File-for-Any-Website) [Introducing Spark 1 Pro and Spark 1 Mini](https://www.firecrawl.dev/blog/introducing-spark-1) [Introducing /agent: Gather Data Wherever It Lives on the Web](https://www.firecrawl.dev/blog/introducing-agent) [Retell‚Äôs AI phone agents get LLM-ready content from Firecrawl](https://www.firecrawl.dev/blog/retell-firecrawl-ai-phone-agents) [Introducing Firecrawl v2.5 - The World's Best Web Data API](https://www.firecrawl.dev/blog/the-worlds-best-web-data-api-v25) [Why Firecrawl Beats Octoparse for AI Web Scraping](https://www.firecrawl.dev/blog/firecrawl-vs-octoparse-data-extraction) [Introducing Firecrawl Observer, Our Open-Source Website Monitoring Tool](https://www.firecrawl.dev/blog/introducing-firecrawl-observer)

FOOTER

The easiest way to extract

data from the web

Backed by

Y Combinator

[Linkedin](https://www.linkedin.com/company/firecrawl) [Github](https://github.com/firecrawl/firecrawl) [YouTube](https://www.youtube.com/@Firecrawl_dev)

SOC II ¬∑ Type 2

AICPA

SOC 2

[X (Twitter)](https://x.com/firecrawl) [Discord](https://discord.gg/gSmWdAkdwd)

Products

[Playground](https://www.firecrawl.dev/playground) [Agent](https://www.firecrawl.dev/agent) [Pricing](https://www.firecrawl.dev/pricing) [Templates](https://www.firecrawl.dev/templates) [Changelog](https://www.firecrawl.dev/changelog)

Use Cases

[AI Platforms](https://www.firecrawl.dev/use-cases/ai-platforms) [Lead Enrichment](https://www.firecrawl.dev/use-cases/lead-enrichment) [SEO Teams](https://www.firecrawl.dev/use-cases/seo-teams) [Deep Research](https://www.firecrawl.dev/use-cases/deep-research) [Competitive Intelligence](https://www.firecrawl.dev/use-cases/competitive-intelligence)

Documentation

[Getting started](https://docs.firecrawl.dev/introduction) [API Reference](https://docs.firecrawl.dev/api-reference/introduction) [Integrations](https://www.firecrawl.dev/app) [Examples](https://docs.firecrawl.dev/use-cases/overview) [SDKs](https://docs.firecrawl.dev/sdks/overview)

Company

[Blog](https://www.firecrawl.dev/blog) [Careers](https://www.firecrawl.dev/careers) [Creator & OSS program](https://www.firecrawl.dev/creator-oss-program) [Student program](https://www.firecrawl.dev/student-program)

¬© 2025 Firecrawl

[Terms of Service](https://www.firecrawl.dev/terms-of-service) [Privacy Policy](https://www.firecrawl.dev/privacy-policy) [Report Abuse](mailto:help@firecrawl.com?subject=Issue:)

[All systems normal](https://status.firecrawl.dev/)

## July 2024 Updates
Introducing Spark 1 Pro and Spark 1 Mini models in /agent. [Try it now ‚Üí](https://www.firecrawl.dev/agent)

//

Get started

//

### Ready to build?

Start getting Web Data for free and scale seamlessly as your project expands. No credit card needed.

[Start for free](https://www.firecrawl.dev/signin) [See our plans](https://www.firecrawl.dev/pricing)

[Blog](https://www.firecrawl.dev/blog)

Firecrawl July 2024 Updates

![placeholder](https://www.firecrawl.dev/_next/image?url=%2Fblog%2Fauthors%2Feric-img.jpeg&w=48&q=75&dpl=dpl_2hQ8hmy6vNQsu8DPuBRaRM6deLpr)Eric Ciarla

Jul 31, 2024

![Firecrawl July 2024 Updates image](https://www.firecrawl.dev/_next/image?url=%2Fimages%2Fblog%2Flaunch-yc-firecrawl.png&w=3840&q=75&dpl=dpl_2hQ8hmy6vNQsu8DPuBRaRM6deLpr)

We are excited to share our latest updates from July!

**TLDR:**

- We launched [Firecrawl on Launch YC](https://www.ycombinator.com/launches/LTf-firecrawl-open-source-crawling-and-scraping-for-ai-ready-web-data) üî•
- Improvements to Endpoints + Dashboard
- New Templates & Community Creations
- We are hiring a [Developer Relations Specialist](https://www.ycombinator.com/companies/firecrawl/jobs/bbUHmrJ-devrel-and-growth-specialist-at-firecrawl) & [Web Automation Engineer](https://www.ycombinator.com/companies/firecrawl/jobs/hZHD0j6-founding-web-automation-engineer)

### Officially launched on YC üß°

After three months and more than 8K stars, we have officially decided to launch Firecrawl on YC. It has been an incredible journey, and we are excited to continue building the best way to power AI with web data. [Check out our launch (and leave an upvote üôÇ)!](https://www.ycombinator.com/launches/LTf-firecrawl-open-source-crawling-and-scraping-for-ai-ready-web-data)

![Firecrawl Launch YC](https://www.firecrawl.dev/images/blog/launchyc.jpeg)

### Improvements to Endpoints + Dashboard

This month, we made improving our core product a priority. This meant focusing time on speed, reliability, and our dashboard as well.

Specifically in these categories, we:

- Shaved off around 1 second for every scrape and crawl request
- Expanded scrape reliability for a bunch of new types of sites
- Added enhanced dashboard monitoring which allows you to see processes, timing, failures and more. Check it out on your Activity Logs page on the dashboard!

Look for even more speed and reliability improvements coming soon!

![New enhanced dashboard monitoring](https://www.firecrawl.dev/images/blog/newactivitylogs.jpeg)

### New Templates & Community Creations

Not only did we release some examples and templates this month, but we also witnessed incredible creations from our community. If you're working on an interesting Firecrawl project, we'd love to hear about it! Give us a shout at [@firecrawl](https://x.com/firecrawl). Here are a few highlights:

- Firecrawl Web Data Ingestion UI Template [(Link to repo)](https://github.com/firecrawl/firecrawl/tree/main/apps/ui/ingestion-ui)
- Generative UI with demo Firecrawl x Langchain by Brace Sproul from Langchain [(Link to repo)](https://github.com/bracesproul/gen-ui)
- Scraping Real Estate Data from Zillow by Sourav Maji [(Link to post)](https://x.com/SouravMaji221/status/1818133241460556178)
- Website Contraction Analysis with Google Gemini [(Link to post)](https://x.com/ericciarla/status/1808614350967525873)

![Web Data Ingestion UI Template](https://www.firecrawl.dev/images/blog/ingestiontemplate.jpeg)

### We are hiring!

If you want to help build the best way to power AI with web data, we want to hear from you. Specifically, we are hiring for these roles:

- DevRel and Growth Specialist at Firecrawl [(Link to post)](https://www.ycombinator.com/companies/firecrawl/jobs/bbUHmrJ-devrel-and-growth-specialist-at-firecrawl)
- Founding Web Automation Engineer [(Link to job post)](https://www.ycombinator.com/companies/firecrawl/jobs/hZHD0j6-founding-web-automation-engineer)

That's all for this update! Stay tuned for the next one üöÄ

\[ CTA \]

\[ CRAWL \]

\[ SCRAPE \]

\[ CTA \]

//

Get started

//

Ready to build?

Start getting Web Data for free and scale seamlessly as your project expands. No credit card needed.

[Start for free](https://www.firecrawl.dev/signin) [See our plans](https://www.firecrawl.dev/pricing)

![placeholder](https://www.firecrawl.dev/_next/image?url=%2Fblog%2Fauthors%2Feric-img.jpeg&w=128&q=75&dpl=dpl_2hQ8hmy6vNQsu8DPuBRaRM6deLpr)

Eric Ciarla [@ericciarla](https://x.com/ericciarla)

CMO of Firecrawl

About the Author

Eric Ciarla is the cofounder and Chief Marketing Officer (CMO) of Firecrawl. He also worked on Mendable.ai and sold it to companies like Snapchat, Coinbase, and MongoDB. Previously worked at Ford and Fracta as a Data Scientist. Eric also co-founded SideGuide, a tool for learning code within VS Code with 50,000 users.

More articles by Eric Ciarla

[Extract Web Data at Scale With Parallel Agents](https://www.firecrawl.dev/blog/introducing-parallel-agents) [Introducing the Firecrawl Skill and CLI - Give Agents Real-Time Web Data](https://www.firecrawl.dev/blog/introducing-firecrawl-skill-and-cli) [How Credal Extracts 6M+ URLs Monthly to Power Production AI Agents](https://www.firecrawl.dev/blog/credal-firecrawl-ai-agents) [How to Create an llms.txt File for Any Website](https://www.firecrawl.dev/blog/How-to-Create-an-llms-txt-File-for-Any-Website) [Introducing Spark 1 Pro and Spark 1 Mini](https://www.firecrawl.dev/blog/introducing-spark-1) [Introducing /agent: Gather Data Wherever It Lives on the Web](https://www.firecrawl.dev/blog/introducing-agent) [Retell‚Äôs AI phone agents get LLM-ready content from Firecrawl](https://www.firecrawl.dev/blog/retell-firecrawl-ai-phone-agents) [Introducing Firecrawl v2.5 - The World's Best Web Data API](https://www.firecrawl.dev/blog/the-worlds-best-web-data-api-v25) [Why Firecrawl Beats Octoparse for AI Web Scraping](https://www.firecrawl.dev/blog/firecrawl-vs-octoparse-data-extraction) [Introducing Firecrawl Observer, Our Open-Source Website Monitoring Tool](https://www.firecrawl.dev/blog/introducing-firecrawl-observer)

FOOTER

The easiest way to extract

data from the web

Backed by

Y Combinator

[Linkedin](https://www.linkedin.com/company/firecrawl) [Github](https://github.com/firecrawl/firecrawl) [YouTube](https://www.youtube.com/@Firecrawl_dev)

SOC II ¬∑ Type 2

AICPA

SOC 2

[X (Twitter)](https://x.com/firecrawl) [Discord](https://discord.gg/gSmWdAkdwd)

Products

[Playground](https://www.firecrawl.dev/playground) [Agent](https://www.firecrawl.dev/agent) [Pricing](https://www.firecrawl.dev/pricing) [Templates](https://www.firecrawl.dev/templates) [Changelog](https://www.firecrawl.dev/changelog)

Use Cases

[AI Platforms](https://www.firecrawl.dev/use-cases/ai-platforms) [Lead Enrichment](https://www.firecrawl.dev/use-cases/lead-enrichment) [SEO Teams](https://www.firecrawl.dev/use-cases/seo-teams) [Deep Research](https://www.firecrawl.dev/use-cases/deep-research) [Competitive Intelligence](https://www.firecrawl.dev/use-cases/competitive-intelligence)

Documentation

[Getting started](https://docs.firecrawl.dev/introduction) [API Reference](https://docs.firecrawl.dev/api-reference/introduction) [Integrations](https://www.firecrawl.dev/app) [Examples](https://docs.firecrawl.dev/use-cases/overview) [SDKs](https://docs.firecrawl.dev/sdks/overview)

Company

[Blog](https://www.firecrawl.dev/blog) [Careers](https://www.firecrawl.dev/careers) [Creator & OSS program](https://www.firecrawl.dev/creator-oss-program) [Student program](https://www.firecrawl.dev/student-program)

¬© 2025 Firecrawl

[Terms of Service](https://www.firecrawl.dev/terms-of-service) [Privacy Policy](https://www.firecrawl.dev/privacy-policy) [Report Abuse](mailto:help@firecrawl.com?subject=Issue:)

[All systems normal](https://status.firecrawl.dev/)

## Website Summarization Tool
Introducing Parallel Agents - Run multiple /agent queries simultaneously. [Read more ‚Üí](https://www.firecrawl.dev/blog/introducing-parallel-agents)

//

Get started

//

### Ready to build?

Start getting Web Data for free and scale seamlessly as your project expands.No credit card needed.

[Start for free](https://www.firecrawl.dev/signin) [See our plans](https://www.firecrawl.dev/pricing)

#### All Questions

[Glossary](https://www.firecrawl.dev/glossary)/ [Web Extraction APIs](https://www.firecrawl.dev/glossary/web-extraction-apis)/Questions

[How do web extraction APIs handle structured output formats (JSON, CSV, XML)?](https://www.firecrawl.dev/glossary/web-extraction-apis/how-web-extraction-apis-handle-structured-output-formats)

[What are CSS selectors and XPath in web extraction?](https://www.firecrawl.dev/glossary/web-extraction-apis/what-are-css-selectors-xpath-web-extraction)

# How to build an agent that summarizes a website quickly?

## TL;DR

Firecrawl offers two approaches: use the [agent endpoint](https://docs.firecrawl.dev/agents/firecrawl-agent) for fully autonomous summarization, or combine map + crawl for more control. The agent handles everything‚Äîdiscovering pages, extracting content, and generating structured summaries.

## Autonomous summarization

Let Firecrawl's agent explore and summarize:

```
result = app.agent({
    "prompt": "Summarize what this company does, their main products, and key differentiators",
    "urls": ["https://example.com"],
})
```

The agent navigates the site, reads relevant pages, and returns a structured summary.

## Controlled approach with map + crawl

For precise control over which pages to include:

```
# 1. Discover URLs
site_map = app.map("https://example.com")

# 2. Filter to key pages
key_pages = [url for url in site_map["links"]\
             if "/about" in url or "/products" in url]

# 3. Scrape with summaries
content = app.batch_scrape(key_pages[:10], {
    "formats": ["markdown", "summary"]
})
```

## Using the summary format

Firecrawl generates page summaries directly:

```
result = app.scrape_url("https://example.com", {
    "formats": ["summary"]
})
```

## Key Takeaways

Firecrawl's agent endpoint provides one-call website summarization‚Äîjust describe what you want to know. For more control, combine map (discover URLs), selective scraping, and the summary format. Both approaches deliver fast website overviews without custom crawling infrastructure.

Last updated: Jan 26, 2026

\[ CTA \]

\[ CRAWL \]

\[ SCRAPE \]

\[ CTA \]

//

Get started

//

Ready to build?

Start getting Web Data for free and scale seamlessly as your project expands. No credit card needed.

[Start for free](https://www.firecrawl.dev/signin) [See our plans](https://www.firecrawl.dev/pricing)

FOOTER

The easiest way to extract

data from the web

Backed by

Y Combinator

[Linkedin](https://www.linkedin.com/company/firecrawl) [Github](https://github.com/firecrawl/firecrawl) [YouTube](https://www.youtube.com/@Firecrawl_dev)

SOC II ¬∑ Type 2

AICPA

SOC 2

[X (Twitter)](https://x.com/firecrawl) [Discord](https://discord.gg/gSmWdAkdwd)

Products

[Playground](https://www.firecrawl.dev/playground) [Agent](https://www.firecrawl.dev/agent) [Pricing](https://www.firecrawl.dev/pricing) [Templates](https://www.firecrawl.dev/templates) [Changelog](https://www.firecrawl.dev/changelog)

Use Cases

[AI Platforms](https://www.firecrawl.dev/use-cases/ai-platforms) [Lead Enrichment](https://www.firecrawl.dev/use-cases/lead-enrichment) [SEO Teams](https://www.firecrawl.dev/use-cases/seo-teams) [Deep Research](https://www.firecrawl.dev/use-cases/deep-research) [Competitive Intelligence](https://www.firecrawl.dev/use-cases/competitive-intelligence)

Documentation

[Getting started](https://docs.firecrawl.dev/introduction) [API Reference](https://docs.firecrawl.dev/api-reference/introduction) [Integrations](https://www.firecrawl.dev/app) [Examples](https://docs.firecrawl.dev/use-cases/overview) [SDKs](https://docs.firecrawl.dev/sdks/overview)

Company

[Blog](https://www.firecrawl.dev/blog) [Careers](https://www.firecrawl.dev/careers) [Creator & OSS program](https://www.firecrawl.dev/creator-oss-program) [Student program](https://www.firecrawl.dev/student-program)

¬© 2025 Firecrawl

[Terms of Service](https://www.firecrawl.dev/terms-of-service) [Privacy Policy](https://www.firecrawl.dev/privacy-policy) [Report Abuse](mailto:help@firecrawl.com?subject=Issue:)

[All systems normal](https://status.firecrawl.dev/)

## Monthly Portfolios Overview
### Response

DownloadCopy

View

JSONCSV

{

"items":

‚ñº\[19 items\
\
{\
\
"item\_title": "Monthly-Portfolio-Shriram-Mutual-Fund-July-2025",\
\
"item\_url": "https://cdn.shriramamc.in/uploads/Statutory-disclosure/Monthly-Fortnightly-Portfolio-of-Scheme(s)/Monthly-Portfolio-for-the-Financial-Year/2025-2026/Monthly-Portfolio-Shriram-Mutual-Fund-July-2025.xls",\
\
"date\_raw": "July 2025",\
\
"date\_context": "Monthly Portfolio > 2025-2026",\
\
"source\_location": "filename"\
\
}\
\
,\
\
{\
\
"item\_title": "Monthly-Portfolio-Shriram-Mutual-Fund-Oct-2025",\
\
"item\_url": "https://cdn.shriramamc.in/uploads/Statutory-disclosure/Monthly-Fortnightly-Portfolio-of-Scheme(s)/Monthly-Portfolio-for-the-Financial-Year/2025-2026/Monthly-Portfolio-Shriram-Mutual-Fund-Oct-2025.xls",\
\
"date\_raw": "Oct 2025",\
\
"date\_context": "Monthly Portfolio > 2025-2026",\
\
"source\_location": "filename"\
\
}\
\
,\
\
{\
\
"item\_title": "Monthly-Portfolio-Shriram-Mutual-Fund-April-2025",\
\
"item\_url": "https://cdn.shriramamc.in/uploads/Statutory-disclosure/Monthly-Fortnightly-Portfolio-of-Scheme(s)/Monthly-Portfolio-for-the-Financial-Year/2025-2026/Monthly-Portfolio-Shriram-Mutual-Fund-April-2025.xls",\
\
"date\_raw": "April 2025",\
\
"date\_context": "Monthly Portfolio > 2025-2026",\
\
"source\_location": "filename"\
\
}\
\
,\
\
{\
\
"item\_title": "Monthly-Portfolio-Shriram-Mutual-Fund-February-2025",\
\
"item\_url": "https://cdn.shriramamc.in/uploads/Statutory-disclosure/Monthly-Fortnightly-Portfolio-of-Scheme(s)/Monthly-Portfolio-for-the-Financial-Year/2024-2025/Monthly-Portfolio-Shriram-Mutual-Fund-February-2025.xls",\
\
"date\_raw": "February 2025",\
\
"date\_context": "Monthly Portfolio > 2024-2025",\
\
"source\_location": "filename"\
\
}\
\
,\
\
{\
\
"item\_title": "Monthly-Portfolio-Shriram-Mutual-Fund-July-2024",\
\
"item\_url": "https://cdn.shriramamc.in/uploads/Statutory-disclosure/Monthly-Fortnightly-Portfolio-of-Scheme(s)/Monthly-Portfolio-for-the-Financial-Year/2024-2025/Monthly-Portfolio-Shriram-Mutual-Fund-July-2024.xls",\
\
"date\_raw": "July 2024",\
\
"date\_context": "Monthly Portfolio > 2024-2025",\
\
"source\_location": "filename"\
\
}\
\
,\
\
{\
\
"item\_title": "Monthly-Portfolio-Shriram-Mutual-Fund-November-2024",\
\
"item\_url": "https://cdn.shriramamc.in/uploads/Statutory-disclosure/Monthly-Fortnightly-Portfolio-of-Scheme(s)/Monthly-Portfolio-for-the-Financial-Year/2024-2025/Monthly-Portfolio-Shriram-Mutual-Fund-November-2024.xls",\
\
"date\_raw": "November 2024",\
\
"date\_context": "Monthly Portfolio > 2024-2025",\
\
"source\_location": "filename"\
\
}\
\
,\
\
{\
\
"item\_title": "Monthly-Portfolio-Shriram-Mutual-Fund-December-2024",\
\
"item\_url": "https://cdn.shriramamc.in/uploads/Statutory-disclosure/Monthly-Fortnightly-Portfolio-of-Scheme(s)/Monthly-Portfolio-for-the-Financial-Year/2024-2025/Monthly-Portfolio-Shriram-Mutual-Fund-December-2024.xls",\
\
"date\_raw": "December 2024",\
\
"date\_context": "Monthly Portfolio > 2024-2025",\
\
"source\_location": "filename"\
\
}\
\
,\
\
{\
\
"item\_title": "Monthly-Portfolio-Shriram-Mutual-Fund-September-2024",\
\
"item\_url": "https://cdn.shriramamc.in/uploads/Statutory-disclosure/Monthly-Fortnightly-Portfolio-of-Scheme(s)/Monthly-Portfolio-for-the-Financial-Year/2024-2025/Monthly-Portfolio-Shriram-Mutual-Fund-September-2024.xls",\
\
"date\_raw": "September 2024",\
\
"date\_context": "Monthly Portfolio > 2024-2025",\
\
"source\_location": "filename"\
\
}\
\
,\
\
{\
\
"item\_title": "Monthly-Portfolios-SHRIRAM-MUTUAL-FUND-October-2023",\
\
"item\_url": "https://cdn.shriramamc.in/uploads/Statutory-disclosure/Monthly-Fortnightly-Portfolio-of-Scheme(s)/Monthly-Portfolio-for-the-Financial-Year/2023-2024/Monthly-Portfolios-SHRIRAM-MUTUAL-FUND-October-2023.xls",\
\
"date\_raw": "October 2023",\
\
"date\_context": "Monthly Portfolio > 2023-2024",\
\
"source\_location": "filename"\
\
}\
\
,\
\
{\
\
"item\_title": "Monthly-Portfolio-Shriram-Mutual-Fund-February-2024",\
\
"item\_url": "https://cdn.shriramamc.in/uploads/Statutory-disclosure/Monthly-Fortnightly-Portfolio-of-Scheme(s)/Monthly-Portfolio-for-the-Financial-Year/2023-2024/Monthly-Portfolio-Shriram-Mutual-Fund-February-2024.xls",\
\
"date\_raw": "February 2024",\
\
"date\_context": "Monthly Portfolio > 2023-2024",\
\
"source\_location": "filename"\
\
}\
\
,\
\
{\
\
"item\_title": "Monthly-Portfolio-Shriram-Mutual-Fund-January-2024",\
\
"item\_url": "https://cdn.shriramamc.in/uploads/Statutory-disclosure/Monthly-Fortnightly-Portfolio-of-Scheme(s)/Monthly-Portfolio-for-the-Financial-Year/2023-2024/Monthly-Portfolio-Shriram-Mutual-Fund-January-2024.xls",\
\
"date\_raw": "January 2024",\
\
"date\_context": "Monthly Portfolio > 2023-2024",\
\
"source\_location": "filename"\
\
}\
\
,\
\
{\
\
"item\_title": "Monthly-Portfolios-SHRIRAM-MUTUAL-FUND-December-2022",\
\
"item\_url": "https://cdn.shriramamc.in/uploads/Statutory-disclosure/Monthly-Fortnightly-Portfolio-of-Scheme(s)/Monthly-Portfolio-for-the-Financial-Year/2022-2023/Monthly-Portfolios-SHRIRAM-MUTUAL-FUND-December-2022.xls",\
\
"date\_raw": "December 2022",\
\
"date\_context": "Monthly Portfolio > 2022-2023",\
\
"source\_location": "filename"\
\
}\
\
,\
\
{\
\
"item\_title": "Monthly-Portfolios-SHRIRAM-MUTUAL-FUND-May-2022",\
\
"item\_url": "https://cdn.shriramamc.in/uploads/Statutory-disclosure/Monthly-Fortnightly-Portfolio-of-Scheme(s)/Monthly-Portfolio-for-the-Financial-Year/2022-2023/Monthly-Portfolios-SHRIRAM-MUTUAL-FUND-May-2022.xls",\
\
"date\_raw": "May 2022",\
\
"date\_context": "Monthly Portfolio > 2022-2023",\
\
"source\_location": "filename"\
\
}\
\
,\
\
{\
\
"item\_title": "Monthly-Portfolios-SHRIRAM-MUTUAL-FUND-December-2021",\
\
"item\_url": "https://cdn.shriramamc.in/uploads/Statutory-disclosure/Monthly-Fortnightly-Portfolio-of-Scheme(s)/Monthly-Portfolio-for-the-Financial-Year/2021-2022/Monthly-Portfolios-SHRIRAM-MUTUAL-FUND-December-2021.xls",\
\
"date\_raw": "December 2021",\
\
"date\_context": "Monthly Portfolio > 2021-2022",\
\
"source\_location": "filename"\
\
}\
\
,\
\
{\
\
"item\_title": "Monthly-Portfolios-SHRIRAM-MUTUAL-FUND-November-2021",\
\
"item\_url": "https://cdn.shriramamc.in/uploads/Statutory-disclosure/Monthly-Fortnightly-Portfolio-of-Scheme(s)/Monthly-Portfolio-for-the-Financial-Year/2021-2022/Monthly-Portfolios-SHRIRAM-MUTUAL-FUND-November-2021.xls",\
\
"date\_raw": "November 2021",\
\
"date\_context": "Monthly Portfolio > 2021-2022",\
\
"source\_location": "filename"\
\
}\
\
,\
\
{\
\
"item\_title": "Monthly-Portfolios-SHRIRAM-MUTUAL-FUND-January-2022",\
\
"item\_url": "https://cdn.shriramamc.in/uploads/Statutory-disclosure/Monthly-Fortnightly-Portfolio-of-Scheme(s)/Monthly-Portfolio-for-the-Financial-Year/2021-2022/Monthly-Portfolios-SHRIRAM-MUTUAL-FUND-January-2022.xls",\
\
"date\_raw": "January 2022",\
\
"date\_context": "Monthly Portfolio > 2021-2022",\
\
"source\_location": "filename"\
\
}\
\
,\
\
{\
\
"item\_title": "Monthly-Portfolios-SHRIRAM-MUTUAL-FUND-January-2021",\
\
"item\_url": "https://cdn.shriramamc.in/uploads/Statutory-disclosure/Monthly-Fortnightly-Portfolio-of-Scheme(s)/Monthly-Portfolio-for-the-Financial-Year/2020-2021/Monthly-Portfolios-SHRIRAM-MUTUAL-FUND-January-2021.xls",\
\
"date\_raw": "January 2021",\
\
"date\_context": "Monthly Portfolio > 2020-2021",\
\
"source\_location": "filename"\
\
}\
\
,\
\
{\
\
"item\_title": "Monthly-Portfolios-SHRIRAM-MUTUAL-FUND-February-2021",\
\
"item\_url": "https://cdn.shriramamc.in/uploads/Statutory-disclosure/Monthly-Fortnightly-Portfolio-of-Scheme(s)/Monthly-Portfolio-for-the-Financial-Year/2020-2021/Monthly-Portfolios-SHRIRAM-MUTUAL-FUND-February-2021.xls",\
\
"date\_raw": "February 2021",\
\
"date\_context": "Monthly Portfolio > 2020-2021",\
\
"source\_location": "filename"\
\
}\
\
,\
\
{\
\
"item\_title": "Monthly-Portfolios-SHRIRAM-MUTUAL-FUND-March-2021",\
\
"item\_url": "https://cdn.shriramamc.in/uploads/Statutory-disclosure/Monthly-Fortnightly-Portfolio-of-Scheme(s)/Monthly-Portfolio-for-the-Financial-Year/2020-2021/Monthly-Portfolios-SHRIRAM-MUTUAL-FUND-March-2021.xls",\
\
"date\_raw": "March 2021",\
\
"date\_context": "Monthly Portfolio > 2020-2021",\
\
"source\_location": "filename"\
\
}\
\
\]

}

Activity

## Activity

Starting extract for query: "‚ö†Ô∏è STRICT REQUIREMENT - ANALYST-VERIFIED PATTERNS:
The following patterns are derived from ACTUAL FILES that analysts have already collected and verified.
You MUST priorit......

[www.shriramamc.in](https://www.shriramamc.in/investor-statutory-disclosures)

Running code...

Running code...

Running code...

Running code...

Running code...

![](https://www.google.com/s2/favicons?domain=www.shriramamc.in&sz=32)![](https://www.google.com/s2/favicons?domain=www.shriramamc.in&sz=32)

Read 2 pages

Running code...

Running code...

Using subagents\_\_create

site:shriramamc.in "Monthly-Portfolio" xlsx

Using initialize\_browser

Running code...

Attempting to navigate again

Running code...

Using initialize\_browser

Running code...

Running code...

Running code...

[www.shriramamc.in](https://www.shriramamc.in/investor-statutory-disclosures)

Running code...

Running code...

Running code...

[www.shriramamc.in](https://www.shriramamc.in/investor-statutory-disclosures)

Running code...

Running code...

Using initialize\_browser

Running code...

[www.shriramamc.in](https://www.shriramamc.in/investor-statutory-disclosures)

Running code...

Running code...

Running code...

Running code...

Running code...

Running code...

Running code...

Re-initialize if needed

Running code...

Running code...

Using initialize\_browser

Set a common user agent

Running code...

Running code...

[www.shriramamc.in](https://www.shriramamc.in/investor-statutory-disclosures)

Running code...

Search for the Monthly Portfolio section in the markdown

Running code...

List of months and years to check

Running code...

Running code...

Running code...

Running code...

Running code...

Running code...

Using initialize\_browser

Block images and css to speed up and reduce load

Running code...

[web.archive.org](https://web.archive.org/web/20250125/https://www.shriramamc.in/investor-statutory-disclosures)

Running code...

Running code...

Let's print some of those 1393 links to see their structure

Running code...

Running code...

Running code...

Using initialize\_browser

Running code...

Running code...

Running code...

I'll try to use the browser to query the Wayback Machine CDX API
But I can't use requests. I'll use the browser.

Running code...

[web.archive.org](https://web.archive.org/cdx/search/cdx?url=cdn.shriramamc.in/uploads/Statutory-disclosure/Monthly-Fortnightly-Portfolio-of-Scheme&matchType=prefix&output=json)

Running code...

Running code...

[web.archive.org](https://web.archive.org/web/cdx/search/cdx?url=cdn.shriramamc.in/uploads/Statutory-disclosure/&matchType=prefix&output=json)

Running code...

[www.shriramamc.in](https://www.shriramamc.in/investor-statutory-disclosures)

Running code...

Running code...

Running code...

Running code...

Running code...

Running code...

Running code...

[www.shriramamc.in](https://www.shriramamc.in/investor-statutory-disclosures)

Running code...

Running code...

Try to do everything in one go without any unnecessary calls

Running code...

Running code...

Running code...

[www.shriramamc.in](https://www.shriramamc.in/statutory-disclosures)

Running code...

Search for any link containing "Monthly" and ".xls" in the broad CDX
(I'll try a different way to get the CDX)

Running code...

[www.shriramamc.in](https://www.shriramamc.in/investor-statutory-disclosures)

Running code...

Using initialize\_browser

Running code...

Running code...

Running code...

Running code...

[web.archive.org](https://web.archive.org/cdx/search/cdx?url=cdn.shriramamc.in/uploads/Statutory-disclosure/&matchType=prefix&output=json&limit=100000)

Running code...

Running code...

Running code...

Running code...

Running code...

Running code...

Running code...

Using initialize\_browser

Running code...

Search the broad CDX for anything containing 'Monthly' and 'Portfolio'

Running code...

[www.shriramamc.in](https://www.shriramamc.in/investor-statutory-disclosures)

Running code...

Try one more regex for Monthly Portfolio specifically

Running code...

[www.shriramamc.in](https://www.shriramamc.in/investor-statutory-disclosures)

Final results (empty or partial)

Running code...

Running code...

Using done

Using subagents\_\_wait

Running code...

[www.shriramamc.in](https://www.shriramamc.in/investor-statutory-disclosures)

Using subagents\_\_create

Using subagents\_\_wait

Running code...

Running code...

Running code...

Using subagents\_\_create

Using subagents\_\_wait

Running code...

Running code...

Running code...

[www.shriramamc.in](https://www.shriramamc.in/investor-statutory-disclosures)

Running code...

Running code...

Running code...

Using subagents\_\_create

Using subagents\_\_wait

Running code...

site:cdn.shriramamc.in "Monthly-Portfolio" xlsx

![](https://www.google.com/s2/favicons?domain=www.shriramamc.in&sz=32)![](https://www.google.com/s2/favicons?domain=www.shriramamc.in&sz=32)

Read 2 pages

"Monthly-Portfolio-Shriram Mutual Fund" xlsx

site:cdn.shriramamc.in "Monthly-Portfolio"

[www.shriramamc.in](https://www.shriramamc.in/StatDis-MonthlyPart.aspx)

Using subagents\_\_create

Using subagents\_\_wait

Running code...

Running code...

![](https://www.google.com/s2/favicons?domain=www.shriramamc.in&sz=32)![](https://www.google.com/s2/favicons?domain=www.shriramamc.in&sz=32)

Read 2 pages

Using subagents\_\_create

Using subagents\_\_wait

Using subagents\_\_list

"https://cdn.shriramamc.in/uploads/Statutory-disclosure/Monthly-Fortnightly-Portfolio-of-Scheme(s)/" Monthly-Portfolio

site:cdn.shriramamc.in "Monthly-Portfolio-Shriram-Mutual-Fund" 2021 2022 2023 2024 2025

Using subagents\_\_create

site:cdn.shriramamc.in "Monthly-Portfolio-Shriram-Mutual-Fund" September October November December 2024 2025

site:cdn.shriramamc.in "Monthly-Portfolio-Shriram-Mutual-Fund" May June August September 2024 2025

site:cdn.shriramamc.in "Monthly-Portfolio-for-the-Financial-Year/2021-2022"

site:cdn.shriramamc.in "Monthly-Portfolio-for-the-Financial-Year/2020-2021"

site:cdn.shriramamc.in "Monthly-Portfolio-for-the-Financial-Year/2022-2023"

Running code...

site:cdn.shriramamc.in "Monthly-Portfolio-Shriram-Mutual-Fund" March April May June August 2024 2023

Using subagents\_\_create

Using subagents\_\_wait

Using subagents\_\_list

Using subagents\_\_list

Running code...

site:cdn.shriramamc.in "Monthly-Portfolio" 2020 2021

site:cdn.shriramamc.in "Monthly-Portfolio" 2021 2022 "Financial-Year"

site:cdn.shriramamc.in "Monthly-Portfolio-for-the-Financial-Year/2022-2023" Monthly-Portfolios September October November December 2022 2023

Running code...

Research completed.

Query completed

Describe what data you want to extract and /agent handles the rest. [Try it now ‚Üí](https://www.firecrawl.dev/agent)

## Firecrawl Changelog
Introducing the Firecrawl Skill + CLI for Agents. [Learn more ‚Üí](https://docs.firecrawl.dev/sdks/cli)

Changelog

Feb 3, 2026

## v2.8.0 is live

![v2.8.0 Launch](https://www.firecrawl.dev/images/v28.webp)

Firecrawl v2.8.0 brings major improvements to agent workflows, developer tooling, and self-hosted deployments across the API and SDKs.

### Highlights

- **Parallel Agents** \- Execute thousands of `/agent` queries simultaneously with automatic failure handling and intelligent waterfall execution. Powered by Spark 1 Fast for instant retrieval, automatically upgrading to Spark 1 Mini for complex queries requiring deeper research.
- **Firecrawl Skill** \- Enables agents to use Firecrawl for web scraping and data extraction, install via `npx skills add firecrawl/cli`.
- **Firecrawl CLI** \- Command-line interface with full scrape, search, crawl & map support, install via `npm install -g firecrawl-cli`.
- **Spark Model Family** \- Three new models powering /agent: Spark 1 Fast for instant retrieval (currently only available in Playground), Spark 1 Mini for complex research queries, and Spark 1 Pro for advanced extraction tasks.
- **Agent Enhancements** \- Webhook support, model selection, and new MCP Server tools for autonomous web data gathering.

Read the full changelog [here](https://github.com/firecrawl/firecrawl/releases/tag/v2.8.0).

Jan 30, 2026

## Parallel Agents: Extract Web Data at Scale

We're bringing **parallel processing** to [/agent](https://www.firecrawl.dev/agent), letting you batch hundreds or even thousands of queries simultaneously. What took hours of sequential agent queries now completes in minutes with automatic failure handling and parallel execution.

Try it in the [Agent Playground](https://www.firecrawl.dev/app/agent) \- the playground automatically determines when your use case is a good fit for Parallel Agents.

![Parallel Agents](https://www.firecrawl.dev/images/blog/parallel-agents/parallel-agents.webp)

### Highlights

- **Parallel Batch Processing**: Run thousands of /agent queries simultaneously to enrich companies, research competitors, or build product datasets at scale.
- **Intelligent Waterfall**: Tries instant retrieval first, then automatically upgrades specific cells to full agent research (Spark One Mini) only when needed.
- **Real-Time Spreadsheet Interface**: Work in familiar CSV format with instant visual feedback as cells populate in real-time.
- **Zero Configuration**: Input your data schema, write one prompt, hit run. No workflow building required.
- **Predictable Pricing**: 10 credits per cell with Spark-1 Fast.

Read the full blog [here](https://www.firecrawl.dev/blog/introducing-parallel-agents).

Jan 27, 2026

## Introducing the Firecrawl Skill & CLI

![Firecrawl Skill + CLI](https://www.firecrawl.dev/images/blog/firecrawl-cli-skills-launch/firecrawlskillscli.webp)
We're introducing the **Firecrawl Skill and CLI**, a new way for AI agents to reliably access real-time web data on their own. With a single install, agents like Claude Code, Antigravity, and OpenCode can access all of your favorite Firecrawl endpoints - including scrape, search, crawl, and map for any use case you need.

Install the skill with `$ npx skills add firecrawl/cli` and learn more in our [docs](https://docs.firecrawl.dev/sdks/cli).

### Highlights

- **One-Command Install**: Install the skill with a single command and teach agents how to install, authenticate, and use all of Firecrawl's powerful end-to-end.
- **Real-Time Web Data at Runtime**: Agents can pull fresh, full-page content from docs, product pages, pricing, and articles exactly when they need it.
- **Context-Efficient for Agents**: Uses a file-based approach for context management and bash methods for efficient search and retrieval.
- **Works Across Complex & Dynamic Sites**: Powered by Firecrawl's custom browser stack to reliably extract complete data from large, JavaScript-heavy sites.
- **Proven, Best-in-Class Coverage**: Backed by benchmark results showing >80% coverage across real-world evaluations.

Read the full blog [here](http://firecrawl.dev/blog/introducing-firecrawl-skill-and-cli).

Dec 5, 2025

## v2.7.0 is here!

![v2.7.0 Launch](https://www.firecrawl.dev/images/v27.png)

### Highlights

- **ZDR Search Support** \- Enterprise customers can now search with Zero Data Retention enabled end to end. If you're interested, contact [alex@firecrawl.dev](mailto:alex@firecrawl.dev) to enable for your team.
- **Partner Integrations API** \- Available in closed beta for native integrations. Get in touch with us at [eric@firecrawl.dev](mailto:eric@firecrawl.dev) if you are intested in offering Firecrawl as a native integration in your product.
- **Improved Branding Format** \- Better detection and support across all platforms.
- **Faster Screenshots** \- Enhanced viewport and full page screenshots with improved speed and accuracy.
- **Self-hosted Improvements** \- Significant enhancements for deployments and infrastructure.
- **Performance Enhancements** \- Platform-wide improvements for better user experience.

Read the full changelog [here](https://github.com/firecrawl/firecrawl/releases/tag/v2.7.0)

Nov 14, 2025

## v2.6.0 available now

![v2.6.0 Launch](https://www.firecrawl.dev/images/v26.png)

### Highlights

- **Unified Billing Model** \- Credits and tokens merged into single system. Extract now uses credits (15 tokens = 1 credit), existing tokens work everywhere.
- **Enhanced Branding Format** \- Full support across Playground, MCP, JS and Python SDKs.
- **Reliability and Speed Improvements** \- All endpoints significantly faster with improved reliability.
- **Instant Credit Purchases** \- Buy credit packs directly from dashboard without waiting for auto-recharge.
- **Improved Markdown Parsing** \- Enhanced markdown conversion and main content extraction accuracy.
- **Change Tracking** \- Faster and more reliable detection of web page content updates.
- **Core Stability Fixes** \- Fixed tons of core stability issues, PDF timeouts, and improved error handling.

Read the full changelog [here](https://github.com/firecrawl/firecrawl/releases/tag/v2.6.0)

Oct 25, 2025

## v2.5.0 - The World's Best Web Data API

![v2.5.0 Launch](https://www.firecrawl.dev/images/v25.png)

Today, we're excited to announce Firecrawl v2.5, which delivers the **highest quality** and **most comprehensive** web data API available. This release represents a significant leap forward in web data extraction, powered by two major infrastructure improvements: our new Semantic Index and a completely custom browser stack.

See the benchmarks below:

![Benchmarks](https://www.firecrawl.dev/images/benchmark.png)

We've open-sourced these benchmarks! Check out [scrape-evals](https://www.firecrawl.dev/blog/introducing-scrape-evals), our reproducible framework for testing web scraping engines on 1,000 real URLs.

### Highlights

- **Open-Source Scrape-Evals Benchmark**

We've released [scrape-evals](https://www.firecrawl.dev/blog/introducing-scrape-evals), an open-source benchmark testing 13 web scraping engines on 1,000 real URLs for coverage and quality.

- **Full-Page, High-Quality Extraction**

Improved browser stack ensures complete and consistent data from any type of website.

- **Semantic Index for Faster Results**

Retrieve either fresh data or a previously indexed snapshot with faster speeds and increased coverage.

- **5x Cheaper Search & New Credit Packs**

Search is now 5x cheaper and now every plan has an auto-recharge credit pack sized to match your scale.

- **Smarter Concurrency & Crawl Architecture**

New crawling system improves throughput, reliability, and queue fairness across large workloads.

- **Excel (.xlsx) Scraping Support**

Extract clean data directly from spreadsheets or csv files.


### Get Started with Firecrawl v2.5

Firecrawl v2.5 is available now for all users - no code changes required. You can start experiencing the improved quality and coverage today:

- Experiment in our interactive [playground](https://www.firecrawl.dev/playground)
- Review the complete [documentation](https://docs.firecrawl.dev/)
- [Sign up](https://www.firecrawl.dev/) to integrate Firecrawl into your applications

We're excited to see what you build with the world's most reliable web data API.

Read more about it in our blog post [here](https://www.firecrawl.dev/blog/the-worlds-best-web-data-api-v25) and view the full changelog [here](https://github.com/firecrawl/firecrawl/releases/tag/v2.5.0)

Oct 13, 2025

## v2.4.0 is live now

![v2.4.0 Launch](https://www.firecrawl.dev/images/v24.png)

### What's New

- **New PDF Search Category** \- Search specifically for PDF documents using our v2/search endpoint with the new 'pdf' category filter
- **10x Better Semantic Crawling** \- Improved accuracy and relevance when crawling with a prompt
- **New x402 Search Endpoint** \- Our search API available via Coinbase x402 integration
- **Fire-enrich v2 Example** \- AI-powered data enrichment tool that transforms emails into rich datasets. See [repo](https://github.com/firecrawl/fire-enrich)
- **Enhanced Crawl Status & Warnings** \- Real-time status updates with clear feedback for robots.txt limitations and low-result scenarios
- **20+ Self-Host Improvements** \- Major stability and functionality upgrades for self-hosted deployments

Read the full changelog [here](https://github.com/firecrawl/firecrawl/releases/tag/v2.4.0)

Sep 19, 2025

## Firecrawl v2.3.0 is here

![v2.3.0 Launch](https://www.firecrawl.dev/images/v23.png)

### What's New

- YouTube transcript support
- Added odt & rtf parsing support
- Docx parsing is ~50x faster
- Enterprise Auto-Recharge
- Playground UX improvements
- Self hosting improvements

Read the full changelog [here](https://github.com/firecrawl/firecrawl/releases/tag/v2.3.0)

Sep 12, 2025

## Firecrawl v2.2.0 is here

![v2.2.0 Launch](https://www.firecrawl.dev/images/v22.png)

### New Features

- MCP version 3 is live. Stable support for cloud mcp with HTTP Transport and SSE modes. Compatible with v2 and v1 from.
- Webhooks: Now we support signatures + extract support + event failures
- Map is now 15x faster + supports more urls
- Search reliability improvements
- Usage is now tracked by API Key
- Support for additional locations (CA, CZ, IL, IN, IT, PL, and PT)
- Queue status endpoint
- Added `maxPages` parameter to v2 scrape API for pdf parsing

Read the full changelog [here](https://github.com/firecrawl/firecrawl/releases/tag/v2.2.0)

Aug 29, 2025

## Firecrawl v2.1.0 is here

![v2.1.0 Launch](https://www.firecrawl.dev/images/v21.png)

### New Features

- **Search Categories**: Filter search results by specific categories using the `categories` parameter:
  - `github`: Search within GitHub repositories, code, issues, and documentation
  - `research`: Search academic and research websites (arXiv, Nature, IEEE, PubMed, etc.)
  - More coming soon
- **Image Extraction:** Added image extraction support to the v2 scrape endpoint.
- **Data Attribute Scraping:** Now supports extraction of `data-*` attributes.
- **Hash-Based Routing:** Crawl endpoints now handle hash-based routes.
- **Improved Google Drive Scraping:** Added ability to scrape TXT, PDF, and Sheets from Google Drive.
- **PDF Enhancements:** Extracts PDF titles and shows them in metadata.
- Map endpoint supports up to **100k results**.

Read the full changelog [here](https://github.com/firecrawl/firecrawl/releases/tag/v2.1.0)

Aug 19, 2025

## Introducing Firecrawl v2

![Firecrawl v2](https://www.firecrawl.dev/images/v2-changelog.png)

### Key Improvements

- Faster by default: Requests are cached with maxAge defaulting to 2 days, and sensible defaults like blockAds, skipTlsVerification, and removeBase64Images are enabled.

- New summary format: You can now specify "summary" as a format to directly receive a concise summary of the page content.

- Updated JSON extraction: JSON extraction and change tracking now use an object format. The old "extract" format has been renamed to "json".

- Enhanced screenshot options: Use the object form.

- New search sources: Search across "news" and "images" in addition to web results by setting the sources parameter.

- Smart crawling with prompts: Pass a natural-language prompt to crawl and the system derives paths/limits automatically. Use the new crawl-params-preview endpoint to inspect the derived options before starting a job.


Read the full changelog [here](https://github.com/firecrawl/firecrawl/releases/tag/v2.0.0)

Jul 18, 2025

## Firecrawl v1.15.0 is here

## v1.15.0 Release

We're excited to announce the release of Firecrawl v1.15.0, packed with tons of improvements, bug fixes and enterprise features.

![v1.15.0 Launch](https://www.firecrawl.dev/images/v115.jpg)

- SSO for enterprise
- Improved scraping reliability
- Search params added to activity logs
- FireGEO example (Open Source FireGEO). See [repo](https://github.com/firecrawl/firegeo)
- And over 50 PRs merged for bug & improvements üî•

Read the full changelog [here](https://github.com/firecrawl/firecrawl/releases/tag/v1.15.0)

Jul 4, 2025

## Firecrawl v1.14.0 is here

## v1.14.0 Release

We're excited to announce the release of Firecrawl v1.14.0, packed with cool updates.

![v1.14.0 Launch](https://www.firecrawl.dev/images/v114.jpg)

- Authenticated scraping (Join the waitlist [here](https://firecrawl.dev/authenticated-scraping))
- Zero data retention for enterprise (Email us at [help@firecrawl.com](mailto:help@firecrawl.com) to enable it)
- Improved p75 speeds
- New MCP version w/ maxAge + better tool calling
- Open Researcher Example (Open Source Researcher). See [repo](https://github.com/firecrawl/open-researcher)
- And so much more. Check out [here](https://github.com/firecrawl/firecrawl/releases/tag/v1.14.0) for all the details üî•

Jun 27, 2025

## Firecrawl v1.13.0 is here

## v1.13.0 Release

We're excited to announce the release of Firecrawl v1.13.0, packed with awesome features.

![v1.13.0 Launch](https://www.firecrawl.dev/images/v113.jpg)

- Added AU, FR, DE to [Enhanced Mode](https://docs.firecrawl.dev/features/proxies#location-based-proxy-selection)
- Crawl subdomains with [allowSubdomains](https://docs.firecrawl.dev/api-reference/endpoint/crawl-post#body-allow-subdomains)
- Google slides scraping
- Generate a PDF of the current page. See [docs](https://docs.firecrawl.dev/api-reference/endpoint/scrape#generate-pdf)
- Higher res screenshots with [quality param](https://docs.firecrawl.dev/api-reference/endpoint/scrape#screenshot)
- Weekly view for usage on the dashboard
- Fireplexity Example (Open Source Perplexity). See [repo](https://github.com/firecrawl/fireplexity)
- And more!

Jun 20, 2025

## Firecrawl v1.12.0 is here

## v1.12.0 Release

We're excited to announce the release of Firecrawl v1.12.0, packed with new features.

![v1.12.0 Launch](https://www.firecrawl.dev/images/v112.jpg)

- New Concurrency System - Specify max concurrency by request in crawl and batch scrape for better control. [See docs](https://docs.firecrawl.dev/api-reference/endpoint/crawl-post#body-max-concurrency).
- Crawl Entire Domain Param - Follow internal links to sibling or parent URLs, not just child paths (prev. allowBackwardLinks). [See docs](https://docs.firecrawl.dev/api-reference/endpoint/crawl-post#body-crawl-entire-domain).
- Google Docs Scraping - We now officially support scraping Google Docs files
- Improved Activity Logs - Better support for FIRE-1 requests. [See your logs here.](https://www.firecrawl.dev/app/logs)
- /search Playground Enhanced - Location Params added. [Check out the playground.](https://www.firecrawl.dev/playground?mode=search)
- Firestarter Example - Open Source Chatbot building platform. [Repo here.](https://github.com/firecrawl/firestarter)
- Plus tons of performance improvements and bug fixes.

Jun 13, 2025

## Firecrawl v1.11.0 is here

## v1.11.0 Release

We're excited to announce the release of Firecrawl v1.11.0, packed with major performance improvements and new features.

![Index Launch](https://www.firecrawl.dev/images/index-launch.jpg)

**Major Updates:**

- **Firecrawl Index**: 500% faster scraping speeds when opted in. See [docs](https://docs.firecrawl.dev/features/fast-scraping) for more details.
- **Enhanced Activity Logs**:
  - View webhook events
  - See and manage active crawls
- **Fire Enrich Example**: New open-source Clay integration. Open Source repository [here](https://github.com/firecrawl/fire-enrich).
- **Community Java SDK**: Expanding our SDK support. View [repository](https://github.com/firecrawl/firecrawl-java-sdk).
- And many more improvements!

Jun 3, 2025

## Introducing Search

## Introducing Search

We're excited to announce the launch of our new Search API endpoint that combines web search with Firecrawl's powerful scraping capabilities.

![Search API](https://www.firecrawl.dev/images/llm_ready_search_for_devs_and_agents.webp)

**Key Features:**

- Search the web and get full content from results in one API call
- Choose specific output formats (markdown, HTML, links, screenshots)
- Customize search parameters (language, country, time range, number of results)
- Full SDK support for Python and Node.js

May 16, 2025

## Firecrawl v1.9.0 Release

## Firecrawl v1.9.0 Release

### **What's New:**

**Self-Host Improvements**

- Supabase client error fixes
- Fixed support for LLM Providers
- Crawl is much faster now
- Global adoption of cacheable lookup system
- Easier setup for self-host

**MCP Improvements (v1.11.0)**

- Tons of improvements to it (prompts, examples, and how to use params properly)

**SDK & API Enhancements**

- Added change tracking to SDK 2.0
- Crawl delay support with per-crawl concurrency limiting
- New Qwen3 crawler example via OpenRouter
- Cancel batch scrape endpoint

**Performance & Limits**

- Global adoption of cacheable lookup system
- Increased map endpoint limit from 5,000 to 30,000 links
- Search schema limit increased from 50 to 100

**Fixes & Stability**

- Better error handling for SSL failures
- Optional chaining bug fixes
- WaitAction field validation in firecrawl-py
- Concurrency queue reworked to prioritize by time, not priority

**Dashboard (Cloud version)**

- New activity logs

**GitHub Changelog**: [https://github.com/firecrawl/firecrawl/compare/v1.8.0...v1.9.0](https://github.com/firecrawl/firecrawl/compare/v1.8.0...v1.9.0)

May 5, 2025

## Enhanced Mode Updates

- **What is Enhanced Mode**: Enhanced Mode is a specialized proxy feature for scraping websites with advanced anti-bot protection, providing better success rates when extracting data from challenging sites.

- **Pricing Change**: Starting May 8th, 2025, Enhanced Mode proxy requests will cost 5 credits per request (previously included in standard credit pricing).

- **Quality Improvements**: The price adjustment reflects significant quality improvements to Enhanced Mode, ensuring higher success rates and more reliable data extraction from sites with sophisticated anti-scraping measures.

- **Usage Optimization**: For optimal credit usage, consider using Enhanced Mode as a retry mechanism only when encountering specific error status codes (401, 403, or 500).


Apr 28, 2025

## Firecrawl Launch Week III ‚Äì Summary

## Firecrawl Launch Week III ‚Äì Summary

**Day 7 ‚Äì Integration Day**

- 20+ new/updated integrations: Discord Bot, Make, n8n, Langflow, LlamaIndex, Dify, and more.

**Day 6 ‚Äì Firecrawl MCP**

- MCP now supports FIRE-1 agent for interaction-aware scraping.
- Added SSE streaming for real-time data.

**Day 5 ‚Äì Developer Day**

- **Python SDK v2.0**: async, named params, typed responses.
- **Rust SDK**: batch scraping, cancel jobs, `llms.txt`, smarter search.
- Up to 20 seats on every plan.
- New Firecrawl Dark Theme for VS Code & compatible editors.

**Day 4 ‚Äì LLMstxt.new**

- Prefix any URL with `llmstxt.new/` ‚Üí clean `.txt` output.
- Two outputs: `llms.txt` (summary) & `llms-full.txt` (full content).
- API-ready for LLM training/inference.

**Day 3 ‚Äì /extract v2**

- FIRE-1 powered extraction with pagination & dynamic flows.
- Extract without a URL via built-in search.
- Faster, more accurate models.

**Day 2 ‚Äì FIRE-1 Agent**

- AI agent for smart navigation and interaction.
- Handles pagination, buttons, and JS-rendered elements.

**Day 1 ‚Äì Change Tracking**

- Detect & diff webpage changes via SDK.
- Structured `changeTracking` format with timestamps.

**Day 0 ‚Äì Firecrawl Editor Theme**

- Official theme for VS Code, Cursor, Windsurf, etc.

Apr 4, 2025

## v1.7.0 Release Notes

### New Features

- **Deep Research Open Alpha**: Structured outputs + customizability.
- **Concurrent Browsers**: Improved rate limits for all users.
- **Compare Beta**: Figure what has changed in the website directly in /scrape and /crawl endpoints. Currently in closed beta.
- **/extract**: URLs are now optional.
- **/scrape**: Warns if concurrency-limited.
- **New Firecrawl Examples**: Featuring models like Claude 3.7, Gemini 2.5, Deepseek V3, Mistral 3.1, and more.
- **Crawl**: `maxDiscoveryDepth` option added.

### Fixes & Improvements

- Fixed **circular JSON error** in search.
- Reworked new **tally** system.
- Fixed sitemaps poisoning crawler with unrelated links.
- Crawler status retries added on failure (up to 3 times).
- Credit check now snaps to remaining credits if exceeded.
- Fixed path filtering bug in Map.
- Removed unsupported schema in `llmExtract`.

Mar 12, 2025

## Concurrent Browsers

We're excited to introduce **concurrent browsers** in our pricing!

We also 5x'd the rate limits, now displayed as concurrent browsers. This change provides more visibility and allows users to upgrade for faster speeds. Enjoy the awesome increase in rate limits across all plans!

See the new rate limits [here](https://docs.firecrawl.dev/rate-limits).

Mar 7, 2025

## v1.6.0

### Introducing LLMs.txt API

The /llmstxt endpoint allows you to transform any website into clean, [LLM-ready text files](https://www.firecrawl.dev/blog/How-to-Create-an-llms-txt-File-for-Any-Website). Simply provide a URL, and Firecrawl will crawl the site and generate both llms.txt and llms-full.txt files that can be used for training or analysis with any LLM.

Docs here: [https://docs.firecrawl.dev/features/alpha/llmstxt](https://docs.firecrawl.dev/features/alpha/llmstxt)

### Introducing Deep Research API (Alpha)

The /deep-research endpoint enables AI-powered deep research and analysis on any topic. Simply provide a research query, and Firecrawl will autonomously explore the web, gather relevant information, and synthesize findings into comprehensive insights.

Join the waitlist here: [https://www.firecrawl.dev/deep-research](https://www.firecrawl.dev/deep-research)

### Official Firecrawl MCP Server

Introducing the Firecrawl MCP Server. Give Cursor, Windsurf, Claude enhanced web extraction capabilities. Big thanks to [@vrknetha](https://github.com/vrknetha), [@cawstudios](https://caw.tech/) for the initial implementation!

See here: [https://github.com/firecrawl/firecrawl-mcp-server](https://github.com/firecrawl/firecrawl-mcp-server)

### Fixes & Enhancements

- Improved charset detection and re-decoding.
- Fixed extract token limit issues.
- Addressed issues with includes/excludes handling.
- Fixed AI SDK handling of JSON responses.

### New Features & Improvements

- AI-SDK Migration ‚Äì transitioned to AI-SDK.
- Auto-Recharge Emails ‚Äì notify users about upgrades.
- Fire-Index Added ‚Äì introduced a new indexing system.
- Self-Hosting Enhancements ‚Äì OpenAI-compatible API & Ollama env support.
- Batch Billing ‚Äì streamlined billing processes.
- Supabase Read Replica Routing ‚Äì improved database performance.

### Crawler & AI Improvements

- Implemented Claude 3.7 and GPT-4.5 web crawlers.
- Added Groq Web Crawler example.
- Updated crawl-status behavior for better error handling.
- Improved cross-origin redirect handling.

### Documentation & Maintenance

- Updated Dockerfile.
- Fixed missing "required" field in docs.

Feb 20, 2025

## Self Host Overhaul - v1.5.0

### Self-Host Fixes

- **Reworked Guide:** The `SELF_HOST.md` and `docker-compose.yaml` have been updated for clarity and compatibility
- **Kubernetes Imporvements:** Updated self-hosted Kubernetes deployment examples for compatibility and consistency (#1177)
- **Self-Host Fixes:** Numerous fixes aimed at improving self-host performance and stability (#1207)
- **Proxy Support:** Added proxy support tailored for self-hosted environments (#1212)
- **Playwright Integration:** Added fixes and continuous integration for the Playwright microservice (#1210)
- **Search Endpoint Upgrade:** Added SearXNG support for the `/search` endpoint (#1193)

### Core Fixes & Enhancements

- **Crawl Status Fixes:** Fixed various race conditions in the crawl status endpoint (#1184)
- **Timeout Enforcement:** Added timeout for scrapeURL engines to prevent hanging requests (#1183)
- **Query Parameter Retention:** Map function now preserves query parameters in results (#1191)
- **Screenshot Action Order:** Ensured screenshots execute after specified actions (#1192)
- **PDF Scraping:** Improved handling for PDFs on complex websites (#1198)
- **Map/scrapeURL Abort Control:** Integrated AbortController to stop scraping when the request times out (#1205)
- **SDK Timeout Enforcement:** Enforced request timeouts in the SDK (#1204)

### New Features & Additions

- **Proxy Options:** Introduced proxy configuration options for infrastructure management (#1196)
- **Deep Research (Alpha):** Launched an alpha implementation of deep research (#1202)
- **LLM Text Generator:** Added a new endpoint for llms.txt generation (#1201)

### Docker & Containerization

- **Production Ready Docker Image:** A streamlined, production ready Docker image is now available to simplify self-hosted deployments.

Feb 14, 2025

## v1.4.4

### Features & Enhancements

- Scrape API: Added action & wait time validation ( [#1146](https://github.com/firecrawl/firecrawl/pull/1146))
- Extraction Improvements:
  - Added detection of PDF/image sub-links & extracted text via Gemini ( [#1173](https://github.com/firecrawl/firecrawl/pull/1173))
  - Multi-entity prompt enhancements for extraction ( [#1181](https://github.com/firecrawl/firecrawl/pull/1181))
  - Show sources out of \_\_experimental in extraction ( [#1180](https://github.com/firecrawl/firecrawl/pull/1180))
- Environment Setup: Added Serper & Search API env vars to docker-compose ( [#1147](https://github.com/firecrawl/firecrawl/pull/1147))
- Credit System Update: Now displays "tokens" instead of "credits" when out of tokens ( [#1178](https://github.com/firecrawl/firecrawl/pull/1178))

### Examples

- Gemini 2.0 Crawler: Implemented new crawling example ( [#1161](https://github.com/firecrawl/firecrawl/pull/1161))
- Gemini TrendFinder: [https://github.com/firecrawl/gemini-trendfinder](https://github.com/firecrawl/gemini-trendfinder)
- Normal Search to Open Deep Research: [https://github.com/nickscamara/open-deep-research](https://github.com/nickscamara/open-deep-research)

### Fixes

- HTML Transformer: Updated free\_string function parameter type ( [#1163](https://github.com/firecrawl/firecrawl/pull/1163))
- Gemini Crawler: Updated library & improved PDF link extraction ( [#1175](https://github.com/firecrawl/firecrawl/pull/1175))
- Crawl Queue Worker: Only reports successful page count in num\_docs ( [#1179](https://github.com/firecrawl/firecrawl/pull/1179))
- Scraping & URLs:
  - Fixed relative URL conversion ( [#584](https://github.com/firecrawl/firecrawl/pull/584))
  - Enforced scrape rate limit in batch scraping ( [#1182](https://github.com/firecrawl/firecrawl/pull/1182))

Feb 7, 2025

## Examples Week - v1.4.3

### Summary of changes

- Open Deep Research: An open source version of OpenAI Deep Research. See here: [https://github.com/nickscamara/open-deep-research](https://github.com/nickscamara/open-deep-research)
- R1 Web Extractor Feature: New extraction capability added.
- O3-Mini Web Crawler: Introduces a lightweight crawler for specific use cases.
- Updated Model Parameters: Enhancements to o3-mini\_company\_researcher.
- URL Deduplication: Fixes handling of URLs ending with /, index.html, index.php, etc.
- Improved URL Blocking: Uses tldts parsing for better blocklist management.
- Valid JSON via rawHtml in Scrape: Ensures valid JSON extraction.
- Product Reviews Summarizer: Implements summarization using o3-mini.
- Scrape Options for Extract: Adds more configuration options for extracting data.
- O3-Mini Job Resource Extractor: Extracts job-related resources using o3-mini.
- Cached Scrapes for Extract evals: Improves performance by using cached data for extractions evals.

Jan 31, 2025

## Extract & API Improvements - v1.4.2

We're excited to announce several new features and improvements:

### New Features

- Added web search capabilities to the extract endpoint via the `enableWebSearch` parameter
- Introduced source tracking with `__experimental_showSources` parameter
- Added configurable webhook events for crawl and batch operations
- New `timeout` parameter for map endpoint
- Optional ad blocking with `blockAds` parameter (enabled by default)

### Infrastructure & UI

- Enhanced proxy selection and infrastructure reliability
- Added domain checker tool to cloud platform
- Redesigned LLMs.txt generator interface for better usability

Jan 24, 2025

## Extract Improvements - v1.4.1

We've significantly enhanced our data extraction capabilities with several key updates:

- Extract now returns a lot more data
- Improved infrastructure reliability
- Migrated from Cheerio to a high-performance Rust-based parser for faster and more memory-efficient parsing
- Enhanced crawl cancellation functionality for better control over running jobs

Jan 7, 2025

## /extract changes

We have updated the `/extract` endpoint to now be asynchronous. When you make a request to `/extract`, it will return an ID that you can use to check the status of your extract job. If you are using our SDKs, there are no changes required to your code, but please make sure to update the SDKs to the latest versions as soon as possible.

For those using the API directly, we have made it backwards compatible. However, you have 10 days to update your implementation to the new asynchronous model.

For more details about the parameters, refer to the docs sent to you.

Jan 3, 2025

## v1.2.0

### Introducing /v1/search

The search endpoint combines web search with Firecrawl‚Äôs scraping capabilities to return full page content for any query.

Include `scrapeOptions` with `formats: ["markdown"]` to get complete markdown content for each search result otherwise it defaults to getting SERP results (url, title, description).

More info here: [v1/search docs](https://docs.firecrawl.dev/api-reference/endpoint/search)

### Fixes and improvements

- Fixed LLM not following the schema in the python SDK for `/extract`
- Fixed schema json not being able to be sent to the `/extract` endpoint through the Node SDK
- Prompt is now optional for the `/extract` endpoint
- Our fork of [MinerU](https://github.com/firecrawl/mineru-api) is now default for PDF Parsing

Dec 27, 2024

## v1.1.0

### Changelog Highlights

#### Feature Enhancements

- **New Features**:
  - Geolocation, mobile scraping, 4x faster parsing, better webhooks,
  - Credit packs, auto-recharges and batch scraping support.
  - Iframe support and query parameter differentiation for URLs.
  - Similar URL deduplication.
  - Enhanced map ranking and sitemap fetching.

#### Performance Improvements

- Faster crawl status filtering and improved map ranking algorithm.
- Optimized Kubernetes setup and simplified build processes.
- Sitemap discoverability and performance improved

#### Bug Fixes

- Resolved issues:
  - Badly formatted JSON, scrolling actions, and encoding errors.
  - Crawl limits, relative URLs, and missing error handlers.
- Fixed self-hosted crawling inconsistencies and schema errors.

#### SDK Updates

- Added dynamic WebSocket imports with fallback support.
- Optional API keys for self-hosted instances.
- Improved error handling across SDKs.

#### Documentation Updates

- Improved API docs and examples.
- Updated self-hosting URLs and added Kubernetes optimizations.
- Added articles: mastering `/scrape` and `/crawl`.

#### Miscellaneous

- Added new Firecrawl examples
- Enhanced metadata handling for webhooks and improved sitemap fetching.
- Updated blocklist and streamlined error messages.

Oct 28, 2024

![Batch Scrape](https://www.firecrawl.dev/images/blog/firecrawl-batch-scrape.jpg)

## Introducing Batch Scrape

You can now scrape multiple URLs simultaneously with our new Batch Scrape endpoint.

- Read more about the Batch Scrape endpoint [here](https://www.firecrawl.dev/blog/launch-week-ii-day-1-introducing-batch-scrape-endpoint).
- Python SDK (1.4.x) and Node SDK (1.7.x) updated with batch scrape support.

Oct 10, 2024

## Cancel Crawl in the SDKs, More Examples, Improved Speed

- Added crawl cancellation support for the Python SDK (1.3.x) and Node SDK (1.6.x)
- OpenAI Voice + Firecrawl example added to the repo
- CRM lead enrichment example added to the repo
- Improved our Docker images
- Limit and timeout fixes for the self hosted playwright scraper
- Improved speed of all scrapes

Sep 27, 2024

## Fixes + Improvements (no version bump)

- Fixed 500 errors that would happen often in some crawled websites and when servers were at capacity
- Fixed an issue where v1 crawl status wouldn't properly return pages over 10mb
- Fixed an issue where `screenshot` would return undefined
- Push improvements that reduce speed times when a scraper fails

Sep 24, 2024

![Actions](https://www.firecrawl.dev/images/actions.png)

## Introducing Actions

Interact with pages before extracting data, unlocking more data from every site!

Firecrawl now allows you to perform various actions on a web page before scraping its content. This is particularly useful for interacting with dynamic content, navigating through pages, or accessing content that requires user interaction.

- Version 1.5.x of the Node SDK now supports type-safe Actions.
- Actions are now available in the REST API and Python SDK (no version bumps required!).

Here is a python example of how to use actions to navigate to google.com, search for Firecrawl, click on the first result, and take a screenshot.

```
from firecrawl import Firecrawl

app = Firecrawl(api_key="fc-YOUR_API_KEY")

# Scrape a website:
scrape_result = app.scrape_url('firecrawl.dev',
    params={
        'formats': ['markdown', 'html'],
        'actions': [\
            {"type": "wait", "milliseconds": 2000},\
            {"type": "click", "selector": "textarea[title=\"Search\"]"},\
            {"type": "wait", "milliseconds": 2000},\
            {"type": "write", "text": "firecrawl"},\
            {"type": "wait", "milliseconds": 2000},\
            {"type": "press", "key": "ENTER"},\
            {"type": "wait", "milliseconds": 3000},\
            {"type": "click", "selector": "h3"},\
            {"type": "wait", "milliseconds": 3000},\
            {"type": "screenshot"}\
        ]
    }
)
print(scrape_result)
```

For more examples, check out our [API Reference](https://docs.firecrawl.dev/api-reference/endpoint/scrape).

Sep 23, 2024

![Firecrawl E2E Type Safe LLM Extract](https://www.firecrawl.dev/images/newllmextract.jpeg)

## Mid-September Updates

### Typesafe LLM Extract

- E2E Type Safety for LLM Extract in Node SDK version 1.5.x.
- 10x cheaper in the cloud version. From 50 to 5 credits per extract.
- Improved speed and reliability.

### Rust SDK v1.0.0

- Rust SDK v1 is finally here! Check it out [here](https://crates.io/crates/firecrawl/1.0.0).

### Map Improved Limits

- Map smart results limits increased from 100 to 1000.

### Faster scrape

- Scrape speed improved by 200ms-600ms depending on the website.

### Launching changelog

- For now on, for every new release, we will be creating a changelog entry here.

### Improvements

- Lots of improvements pushed to the infra and API. For all Mid-September changes, refer to the commits [here](https://github.com/firecrawl/firecrawl/commits/main/).

Sep 8, 2024

## September 8, 2024

### Patch Notes (No version bump)

- Fixed an issue where some of the custom header params were not properly being set in v1 API. You can now pass headers to your requests just fine.

Aug 29, 2024

![Firecrawl V1](https://www.firecrawl.dev/images/blog/f-v1-changelog.png)

## Firecrawl V1 is here! With that we introduce a more reliable and developer friendly API.

### Here is what's new:

- Output Formats for /scrape: Choose what formats you want your output in.
- New /map endpoint: Get most of the URLs of a webpage.
- Developer friendly API for /crawl/id status.
- 2x Rate Limits for all plans.
- Go SDK and Rust SDK.
- Teams support.
- API Key Management in the dashboard.
- onlyMainContent is now default to true.
- /crawl webhooks and websocket support.

Learn more about it [here](https://docs.firecrawl.dev/v1).

Start using v1 right away at [https://firecrawl.dev](https://firecrawl.dev/)

\[ CTA \]

\[ CRAWL \]

\[ SCRAPE \]

\[ CTA \]

//

Get started

//

Ready to build?

Start getting Web Data for free and scale seamlessly as your project expands. No credit card needed.

[Start for free](https://www.firecrawl.dev/signin) [See our plans](https://www.firecrawl.dev/pricing)

FOOTER

The easiest way to extract

data from the web

Backed by

Y Combinator

[Linkedin](https://www.linkedin.com/company/firecrawl) [Github](https://github.com/firecrawl/firecrawl) [YouTube](https://www.youtube.com/@Firecrawl_dev)

SOC II ¬∑ Type 2

AICPA

SOC 2

[X (Twitter)](https://x.com/firecrawl) [Discord](https://discord.gg/gSmWdAkdwd)

Products

[Playground](https://www.firecrawl.dev/playground) [Agent](https://www.firecrawl.dev/agent) [Pricing](https://www.firecrawl.dev/pricing) [Templates](https://www.firecrawl.dev/templates) [Changelog](https://www.firecrawl.dev/changelog)

Use Cases

[AI Platforms](https://www.firecrawl.dev/use-cases/ai-platforms) [Lead Enrichment](https://www.firecrawl.dev/use-cases/lead-enrichment) [SEO Teams](https://www.firecrawl.dev/use-cases/seo-teams) [Deep Research](https://www.firecrawl.dev/use-cases/deep-research) [Competitive Intelligence](https://www.firecrawl.dev/use-cases/competitive-intelligence)

Documentation

[Getting started](https://docs.firecrawl.dev/introduction) [API Reference](https://docs.firecrawl.dev/api-reference/introduction) [Integrations](https://www.firecrawl.dev/app) [Examples](https://docs.firecrawl.dev/use-cases/overview) [SDKs](https://docs.firecrawl.dev/sdks/overview)

Company

[Blog](https://www.firecrawl.dev/blog) [Careers](https://www.firecrawl.dev/careers) [Creator & OSS program](https://www.firecrawl.dev/creator-oss-program) [Student program](https://www.firecrawl.dev/student-program)

¬© 2025 Firecrawl

[Terms of Service](https://www.firecrawl.dev/terms-of-service) [Privacy Policy](https://www.firecrawl.dev/privacy-policy) [Report Abuse](mailto:help@firecrawl.com?subject=Issue:)

[All systems normal](https://status.firecrawl.dev/)

## MCP vs A2A Protocols
Introducing Spark 1 Pro and Spark 1 Mini models in /agent. [Try it now ‚Üí](https://www.firecrawl.dev/agent)

//

Get started

//

### Ready to build?

Start getting Web Data for free and scale seamlessly as your project expands. No credit card needed.

[Start for free](https://www.firecrawl.dev/signin) [See our plans](https://www.firecrawl.dev/pricing)

#### Table of Contents

[Blog](https://www.firecrawl.dev/blog)

MCP vs. A2A Protocols: What Developers Need to Know About AI's New Plumbing

![placeholder](https://www.firecrawl.dev/_next/image?url=%2Fblog%2Fauthors%2Fcaleb.jpg&w=48&q=75&dpl=dpl_2hQ8hmy6vNQsu8DPuBRaRM6deLpr)Caleb Peffer

Apr 25, 2025

![MCP vs. A2A Protocols: What Developers Need to Know About AI's New Plumbing image](https://www.firecrawl.dev/_next/image?url=%2Fimages%2Fblog%2Fmcp-vs-a2a%2Fmcp-vs-a2a.png&w=3840&q=75&dpl=dpl_2hQ8hmy6vNQsu8DPuBRaRM6deLpr)

## MCP vs. A2A Protocols: What Developers Need to Know About AI's New Plumbing

We're seeing AI models do remarkable things. They can write code, analyze data, and even hold surprisingly coherent conversations. But like a brilliant brain locked in a dark room, they're often cut off from the real-time data, specialized tools, and importantly, _each other_. That's starting to change.

Two new protocols are emerging as the potential standards for connecting AI to the outside world and enabling different AI systems to collaborate: the **Model Context Protocol (MCP)** and the **Agent2Agent Protocol (A2A)**. They sound similar, and they share some technical roots, but they solve fundamentally different problems. Understanding the distinction is key for anyone building or using sophisticated AI applications.

So, what are they, and why should you care?

### MCP: Giving AI Applications Access to the World

Imagine you're using an AI-powered code editor. You want it to understand your _entire_ codebase, not just the file you have open. Or maybe you want your chat assistant to pull live data from a specific database or trigger an external API. This is where MCP comes in.

Spearheaded initially by Anthropic, the **Model Context Protocol (MCP)** aims to be a standard way for **LLM applications (like IDEs, chat interfaces ‚Äì the 'hosts') to connect securely to external data sources and tools (the 'servers')**.

- **Think of it like:** The Language Server Protocol (LSP) standardized how code editors talk to language analysis tools (like linters or autocompleters). MCP aims to do the same for AI, standardizing how applications get context or access tools.
- **How it works:** It uses familiar JSON-RPC messages for communication between the host application and the MCP server.
- **What it enables:**
  - Servers can provide `Resources` (files, database snippets, contextual information). **For instance, an MCP server could use a service like Firecrawl to provide resources such as the real-time content of a specific webpage (even Firecrawl's own homepage!) or structured data extracted from it.**
  - Servers can offer `Prompts` (pre-defined workflows or templates).
  - Servers can expose `Tools` (specific functions the AI can be instructed to execute).
- **Key Idea:** MCP is about enriching a _single_ AI application by giving it controlled access to external capabilities and data, with a strong emphasis on user consent for security.

### A2A: Enabling AI Agents to Collaborate

Now, consider a more complex task: planning a multi-city business trip. This might involve searching for flights, finding hotels that meet certain criteria, checking calendar availability, and booking everything. You could imagine different specialized AI agents handling each part: a flight-search agent, a hotel-booking agent, a calendar agent. How do they work together? That's the problem **Agent2Agent (A2A)** tackles.

Driven by Google and a consortium of partners, A2A focuses on **enabling different AI agents, potentially built by different vendors using different frameworks, to communicate, coordinate, and collaborate on tasks**.

- **Think of it like:** A universal translator and rulebook for meetings between different AI agents.
- **How it works:** It also builds on standards like HTTP, SSE, and JSON-RPC. It defines interactions between a 'client' agent initiating a task and a 'remote' agent acting upon it.
- **What it enables:**
  - `Capability Discovery`: Agents can advertise what they can do via an "Agent Card".
  - `Task Management`: A standardized "task" object allows agents to track the status of collaborative work, even for long-running processes.
  - `Collaboration`: Agents can exchange messages containing context, instructions, results (`Artifacts`), etc.
  - `User Experience Negotiation`: Agents can figure out the best way to display information (text, forms, even video).
  - `Modality Agnostic`: Designed to handle more than just text (audio, video).
- **Key Idea:** A2A is about creating a multi-agent ecosystem where specialized agents can work together to achieve complex goals.

### The Crucial Difference: App-to-Tool vs. Agent-to-Agent

The core distinction is simple:

- **MCP:** Connects **one application** to **external resources/tools**. (App ‚Üí Tool Server)
- **A2A:** Connects **multiple agents** to **each other** for collaboration. (Agent ‚Üî Agent)

They aren't rivals; they are designed to be **complementary**. An agent involved in an A2A collaboration might very well _use_ an MCP connection to fetch data or execute a specific tool needed for its part of the task. MCP provides the _resource_, A2A provides the _framework for collaboration_ using potentially many such resources.

### Why This Matters

For developers and businesses, these protocols represent the essential plumbing for the next wave of AI.

- **MCP** lowers the barrier to creating AI applications that are deeply integrated with real-world data and specific functionalities, moving beyond generic knowledge.
- **A2A** paves the way for automating complex, multi-step processes by allowing specialized AI agents to work in concert, creating workflows that are more powerful than any single agent could manage alone.

Instead of countless bespoke integrations, MCP and A2A offer the promise of standardized connections. They move us from isolated AI brains to interconnected systems, capable of more complex and useful work. Watching how these protocols evolve and gain adoption will be crucial for understanding the future of practical AI implementation.

* * *

**Learn More:**

- **MCP Specification:** [https://modelcontextprotocol.io/specification/2025-03-26](https://modelcontextprotocol.io/specification/2025-03-26)
- **A2A Specification & Blog:** [https://github.com/google/A2A](https://github.com/google/A2A), [https://developers.googleblog.com/en/a2a-a-new-era-of-agent-interoperability/](https://developers.googleblog.com/en/a2a-a-new-era-of-agent-interoperability/)

**P.S.** Need to power your AI applications with reliable, up-to-date web data or build integrations like the ones described? Check out [Firecrawl](https://firecrawl.dev/) for powerful scraping, crawling, and data extraction APIs.

\[ CTA \]

\[ CRAWL \]

\[ SCRAPE \]

\[ CTA \]

//

Get started

//

Ready to build?

Start getting Web Data for free and scale seamlessly as your project expands. No credit card needed.

[Start for free](https://www.firecrawl.dev/signin) [See our plans](https://www.firecrawl.dev/pricing)

![placeholder](https://www.firecrawl.dev/_next/image?url=%2Fblog%2Fauthors%2Fcaleb.jpg&w=128&q=75&dpl=dpl_2hQ8hmy6vNQsu8DPuBRaRM6deLpr)

Caleb Peffer [@CalebPeffer](https://x.com/CalebPeffer)

CEO of Firecrawl

About the Author

Caleb Peffer is the Chief Executive Officer (CEO) of Firecrawl. Previously, built and scaled Mendable, an innovative "chat with your documents" application, and sold it to major customers like Snapchat, Coinbase, and MongoDB. Also co-founded SideGuide, a tool for learning code within VS Code with 50,000 users. Caleb has a passion for building products that help people do their best work. Caleb studied Computer Science and has over 10 years of experience in software engineering.

More articles by Caleb Peffer

[We just raised our Series A and shipped /v2](https://www.firecrawl.dev/blog/firecrawl-v2-series-a-announcement) [MCP vs. A2A Protocols: What Developers Need to Know About AI's New Plumbing](https://www.firecrawl.dev/blog/mcp-vs-a2a-protocols) [Using LLM Extraction for Customer Insights](https://www.firecrawl.dev/blog/lead-gen-business-insights-make-firecrawl)

FOOTER

The easiest way to extract

data from the web

Backed by

Y Combinator

[Linkedin](https://www.linkedin.com/company/firecrawl) [Github](https://github.com/firecrawl/firecrawl) [YouTube](https://www.youtube.com/@Firecrawl_dev)

SOC II ¬∑ Type 2

AICPA

SOC 2

[X (Twitter)](https://x.com/firecrawl) [Discord](https://discord.gg/gSmWdAkdwd)

Products

[Playground](https://www.firecrawl.dev/playground) [Agent](https://www.firecrawl.dev/agent) [Pricing](https://www.firecrawl.dev/pricing) [Templates](https://www.firecrawl.dev/templates) [Changelog](https://www.firecrawl.dev/changelog)

Use Cases

[AI Platforms](https://www.firecrawl.dev/use-cases/ai-platforms) [Lead Enrichment](https://www.firecrawl.dev/use-cases/lead-enrichment) [SEO Teams](https://www.firecrawl.dev/use-cases/seo-teams) [Deep Research](https://www.firecrawl.dev/use-cases/deep-research) [Competitive Intelligence](https://www.firecrawl.dev/use-cases/competitive-intelligence)

Documentation

[Getting started](https://docs.firecrawl.dev/introduction) [API Reference](https://docs.firecrawl.dev/api-reference/introduction) [Integrations](https://www.firecrawl.dev/app) [Examples](https://docs.firecrawl.dev/use-cases/overview) [SDKs](https://docs.firecrawl.dev/sdks/overview)

Company

[Blog](https://www.firecrawl.dev/blog) [Careers](https://www.firecrawl.dev/careers) [Creator & OSS program](https://www.firecrawl.dev/creator-oss-program) [Student program](https://www.firecrawl.dev/student-program)

¬© 2025 Firecrawl

[Terms of Service](https://www.firecrawl.dev/terms-of-service) [Privacy Policy](https://www.firecrawl.dev/privacy-policy) [Report Abuse](mailto:help@firecrawl.com?subject=Issue:)

[All systems normal](https://status.firecrawl.dev/)

## Enterprise Web Scraping
Introducing the Firecrawl Skill + CLI for Agents. [Learn more ‚Üí](https://docs.firecrawl.dev/sdks/cli)

//

Get started

//

### Ready to build?

Start getting Web Data for free and scale seamlessly as your project expands. No credit card needed.

[Start for free](https://www.firecrawl.dev/signin) [See our plans](https://www.firecrawl.dev/pricing)

#### All Questions

[Glossary](https://www.firecrawl.dev/glossary)/ [Web Scraping APIs](https://www.firecrawl.dev/glossary/web-scraping-apis)/Questions

[What is browser fingerprinting evasion in web scraping?](https://www.firecrawl.dev/glossary/web-scraping-apis/what-is-browser-fingerprinting-evasion-web-scraping)

[What is JavaScript rendering in web scraping?](https://www.firecrawl.dev/glossary/web-scraping-apis/what-is-javascript-rendering-web-scraping)

# What is enterprise web scraping?

## TL;DR

Enterprise scraping adds SLAs, compliance, dedicated support, and deployment options to core scraping functionality.

## Enterprise requirements

| Requirement | What it means |
| --- | --- |
| SLAs | Guaranteed uptime |
| Compliance | SOC 2, GDPR, HIPAA |
| Deployment | Cloud or self-hosted |
| Support | Dedicated contacts |
| Audit logging | Usage tracking |

## Self-hosted parity

True enterprise solutions offer identical functionality in their cloud or yours‚Äîno feature gaps.

[Firecrawl's enterprise offering](https://www.firecrawl.dev/enterprise) includes self-hosted deployment with full feature parity and dedicated support, including:

- Custom concurrent browsers
- Priority support SLA
- Zero-data retention
- Whitelisted IP addresses
- Up to 3x monthly rollover cap

## Key Takeaways

Enterprise scraping wraps core functionality with reliability, compliance, and support for large organizations.

Last updated: Jan 26, 2026

\[ CTA \]

\[ CRAWL \]

\[ SCRAPE \]

\[ CTA \]

//

Get started

//

Ready to build?

Start getting Web Data for free and scale seamlessly as your project expands. No credit card needed.

[Start for free](https://www.firecrawl.dev/signin) [See our plans](https://www.firecrawl.dev/pricing)

FOOTER

The easiest way to extract

data from the web

Backed by

Y Combinator

[Linkedin](https://www.linkedin.com/company/firecrawl) [Github](https://github.com/firecrawl/firecrawl) [YouTube](https://www.youtube.com/@Firecrawl_dev)

SOC II ¬∑ Type 2

AICPA

SOC 2

[X (Twitter)](https://x.com/firecrawl) [Discord](https://discord.gg/gSmWdAkdwd)

Products

[Playground](https://www.firecrawl.dev/playground) [Agent](https://www.firecrawl.dev/agent) [Pricing](https://www.firecrawl.dev/pricing) [Templates](https://www.firecrawl.dev/templates) [Changelog](https://www.firecrawl.dev/changelog)

Use Cases

[AI Platforms](https://www.firecrawl.dev/use-cases/ai-platforms) [Lead Enrichment](https://www.firecrawl.dev/use-cases/lead-enrichment) [SEO Teams](https://www.firecrawl.dev/use-cases/seo-teams) [Deep Research](https://www.firecrawl.dev/use-cases/deep-research) [Competitive Intelligence](https://www.firecrawl.dev/use-cases/competitive-intelligence)

Documentation

[Getting started](https://docs.firecrawl.dev/introduction) [API Reference](https://docs.firecrawl.dev/api-reference/introduction) [Integrations](https://www.firecrawl.dev/app) [Examples](https://docs.firecrawl.dev/use-cases/overview) [SDKs](https://docs.firecrawl.dev/sdks/overview)

Company

[Blog](https://www.firecrawl.dev/blog) [Careers](https://www.firecrawl.dev/careers) [Creator & OSS program](https://www.firecrawl.dev/creator-oss-program) [Student program](https://www.firecrawl.dev/student-program)

¬© 2025 Firecrawl

[Terms of Service](https://www.firecrawl.dev/terms-of-service) [Privacy Policy](https://www.firecrawl.dev/privacy-policy) [Report Abuse](mailto:help@firecrawl.com?subject=Issue:)

[All systems normal](https://status.firecrawl.dev/)

## Competitive Intelligence
Introducing Spark 1 Pro and Spark 1 Mini models in /agent. [Try it now ‚Üí](https://www.firecrawl.dev/agent)

[2 Months Free ‚Äî Annually](https://www.firecrawl.dev/pricing)

# Competitive Intelligence   & Market Monitoring

Turn competitor site data into structured competitive signals

for pricing, packaging, and product strategy with Firecrawl.

[Start for free](https://www.firecrawl.dev/app/playground) [View Docs](https://docs.firecrawl.dev/introduction)

//

Used by over 500,000 developers

//

Trusted by 80,000+

companies of all sizes

![Logo 17](https://www.firecrawl.dev/assets-original/logocloud/17.png)

![Logo 18](https://www.firecrawl.dev/assets-original/logocloud/18.png)

![Logo 1](https://www.firecrawl.dev/assets-original/logocloud/1.png)

![Logo 2](https://www.firecrawl.dev/assets-original/logocloud/2.png)

![Logo 3](https://www.firecrawl.dev/assets-original/logocloud/3.png)

![Logo 5](https://www.firecrawl.dev/assets-original/logocloud/5.png)

![Logo 6](https://www.firecrawl.dev/assets-original/logocloud/6.png)

![Logo 7](https://www.firecrawl.dev/assets-original/logocloud/7.png)

![Logo 8](https://www.firecrawl.dev/assets-original/logocloud/8.png)

![Logo 9](https://www.firecrawl.dev/assets-original/logocloud/9.png)

![Logo 10](https://www.firecrawl.dev/assets-original/logocloud/10.png)

![Logo 11](https://www.firecrawl.dev/assets-original/logocloud/11.png)

![Logo 12](https://www.firecrawl.dev/assets-original/logocloud/12.png)

![Logo 13](https://www.firecrawl.dev/assets-original/logocloud/13.png)

![Logo 14](https://www.firecrawl.dev/assets-original/logocloud/14.png)

![Logo 15](https://www.firecrawl.dev/assets-original/logocloud/15.png)

![Logo 16](https://www.firecrawl.dev/assets-original/logocloud/16.png)

![Logo 17](https://www.firecrawl.dev/assets-original/logocloud/17.png)

![Logo 18](https://www.firecrawl.dev/assets-original/logocloud/18.png)

![Logo 19](https://www.firecrawl.dev/assets-original/logocloud/19.png)

![Logo 20](https://www.firecrawl.dev/assets-original/logocloud/20.png)

![Logo 21](https://www.firecrawl.dev/assets-original/logocloud/21.png)

![Logo 17](https://www.firecrawl.dev/assets-original/logocloud/17.png)

![Logo 18](https://www.firecrawl.dev/assets-original/logocloud/18.png)

![Logo 1](https://www.firecrawl.dev/assets-original/logocloud/1.png)

![Logo 2](https://www.firecrawl.dev/assets-original/logocloud/2.png)

![Logo 3](https://www.firecrawl.dev/assets-original/logocloud/3.png)

![Logo 5](https://www.firecrawl.dev/assets-original/logocloud/5.png)

![Logo 6](https://www.firecrawl.dev/assets-original/logocloud/6.png)

![Logo 7](https://www.firecrawl.dev/assets-original/logocloud/7.png)

![Logo 8](https://www.firecrawl.dev/assets-original/logocloud/8.png)

![Logo 9](https://www.firecrawl.dev/assets-original/logocloud/9.png)

![Logo 10](https://www.firecrawl.dev/assets-original/logocloud/10.png)

![Logo 11](https://www.firecrawl.dev/assets-original/logocloud/11.png)

![Logo 12](https://www.firecrawl.dev/assets-original/logocloud/12.png)

![Logo 13](https://www.firecrawl.dev/assets-original/logocloud/13.png)

![Logo 14](https://www.firecrawl.dev/assets-original/logocloud/14.png)

![Logo 15](https://www.firecrawl.dev/assets-original/logocloud/15.png)

![Logo 16](https://www.firecrawl.dev/assets-original/logocloud/16.png)

![Logo 17](https://www.firecrawl.dev/assets-original/logocloud/17.png)

![Logo 18](https://www.firecrawl.dev/assets-original/logocloud/18.png)

![Logo 19](https://www.firecrawl.dev/assets-original/logocloud/19.png)

![Logo 20](https://www.firecrawl.dev/assets-original/logocloud/20.png)

![Logo 21](https://www.firecrawl.dev/assets-original/logocloud/21.png)

24/7

automated monitoring

10x

faster competitive tracking

1 API

search + crawl + extract

### Perfect for

#### Product and pricing teams

Track packaging, pricing pages, and product updates without manual checks or screenshots.

#### Competitive intelligence programs

Convert website changes into structured signals for dashboards, alerts, and briefings.

#### Sales enablement

Keep battlecards and talking points current with citations back to competitor pages.

#### Market monitoring

Follow launches, messaging shifts, and hiring signals across competitors and segments.

\[ 01 / 03 \]

¬∑

Use Cases

Competitor Monitor

Competitor A

competitor-a.com

3 changes

New pricing page

/pricing

2h ago

Feature update

/features

5h ago

Blog post

/blog/update

1d ago

Competitor B

competitor-b.com

1 change

Product launch

/products/new

3h ago

### How it works

#### Discover the pages that matter

Use Search to find competitor pricing, product, docs, and jobs pages‚Äîthen scope what you monitor to just those URLs and paths.

[Search endpoint](https://docs.firecrawl.dev/features/search)

#### Crawl competitor sections

Crawl only the sections you care about (pricing, product, docs, release notes) so you capture changes without over-crawling entire sites.

[Crawl endpoint](https://docs.firecrawl.dev/features/crawl)

#### Extract structured competitive signals

Extract plan rows, feature lists, positioning statements, and job listings into clean markdown or JSON you can query and compare over time.

[Extract endpoint](https://docs.firecrawl.dev/features/extract)

#### Schedule always-on monitoring

Run scheduled crawls so you get daily/weekly diffs and alerts without manual checks or screenshot chasing.

[Batch scrape & scheduling](https://docs.firecrawl.dev/features/batch-scrape)

#### Send to dashboards and briefings

Pipe Firecrawl output into your warehouse, BI tools, or CI dashboards so stakeholders get alerts, timelines, and weekly briefings with source URLs.

[Integrations](https://www.firecrawl.dev/integrations)

\[ 02 / 03 \]

¬∑

What Our Customers Say

//

Community

//

## People love    building with Firecrawl

Discover why developers choose Firecrawl every day.

[![Morgan Linton](https://www.firecrawl.dev/assets-original/testimonials/morgan-linton.png)Morgan Linton@morganlinton"If you're coding with AI, and haven't discovered @firecrawl yet, prepare to have your mind blown ü§Ø"](https://x.com/morganlinton/status/1839454165703204955) [![Chris DeWeese](https://www.firecrawl.dev/assets-original/testimonials/chris-deweese.png)Chris DeWeese@chrisdeweese\_"Started using @firecrawl for a project, I wish I used this sooner."](https://x.com/chrisdeweese_/status/1853587120406876601) [![Alex Reibman](https://www.firecrawl.dev/assets-original/testimonials/alex-reibman.png)Alex Reibman@AlexReibman"Moved our internal agent's web scraping tool from Apify to Firecrawl because it benchmarked 50x faster with AgentOps."](https://x.com/AlexReibman/status/1780299595484131836) [![Tom - Morpho](https://www.firecrawl.dev/assets-original/testimonials/tom-morpho.png)Tom - Morpho@TomReppelin"I found gold today. Thank you @firecrawl"](https://x.com/TomReppelin/status/1844382491014201613)

[![Morgan Linton](https://www.firecrawl.dev/assets-original/testimonials/morgan-linton.png)Morgan Linton@morganlinton"If you're coding with AI, and haven't discovered @firecrawl yet, prepare to have your mind blown ü§Ø"](https://x.com/morganlinton/status/1839454165703204955) [![Chris DeWeese](https://www.firecrawl.dev/assets-original/testimonials/chris-deweese.png)Chris DeWeese@chrisdeweese\_"Started using @firecrawl for a project, I wish I used this sooner."](https://x.com/chrisdeweese_/status/1853587120406876601) [![Alex Reibman](https://www.firecrawl.dev/assets-original/testimonials/alex-reibman.png)Alex Reibman@AlexReibman"Moved our internal agent's web scraping tool from Apify to Firecrawl because it benchmarked 50x faster with AgentOps."](https://x.com/AlexReibman/status/1780299595484131836) [![Tom - Morpho](https://www.firecrawl.dev/assets-original/testimonials/tom-morpho.png)Tom - Morpho@TomReppelin"I found gold today. Thank you @firecrawl"](https://x.com/TomReppelin/status/1844382491014201613)

[![Bardia](https://www.firecrawl.dev/assets-original/testimonials/bardia.png)Bardia@thepericulum"The Firecrawl team ships. I wanted types for their node SDK, and less than an hour later, I got them."](https://x.com/thepericulum/status/1781397799487078874) [![Matt Busigin](https://www.firecrawl.dev/assets-original/testimonials/matt-busigin.png)Matt Busigin@mbusigin"Firecrawl is dope. Congrats guys üëè"](https://x.com/mbusigin/status/1836065372010656069) [![Sumanth](https://www.firecrawl.dev/assets-original/testimonials/sumanth.png)Sumanth@Sumanth\_077"Web scraping will never be the same!\\
\\
Firecrawl is an open-source framework that takes a URL, crawls it, and conver..."](https://x.com/Sumanth_077/status/1940049003074478511) [![Steven Tey](https://www.firecrawl.dev/assets-original/testimonials/steven-tey.png)Steven Tey@steventey"Open-source Clay alternative just dropped\\
\\
Upload a CSV of emails and..."](https://x.com/steventey/status/1932945651761098889)

[![Bardia](https://www.firecrawl.dev/assets-original/testimonials/bardia.png)Bardia@thepericulum"The Firecrawl team ships. I wanted types for their node SDK, and less than an hour later, I got them."](https://x.com/thepericulum/status/1781397799487078874) [![Matt Busigin](https://www.firecrawl.dev/assets-original/testimonials/matt-busigin.png)Matt Busigin@mbusigin"Firecrawl is dope. Congrats guys üëè"](https://x.com/mbusigin/status/1836065372010656069) [![Sumanth](https://www.firecrawl.dev/assets-original/testimonials/sumanth.png)Sumanth@Sumanth\_077"Web scraping will never be the same!\\
\\
Firecrawl is an open-source framework that takes a URL, crawls it, and conver..."](https://x.com/Sumanth_077/status/1940049003074478511) [![Steven Tey](https://www.firecrawl.dev/assets-original/testimonials/steven-tey.png)Steven Tey@steventey"Open-source Clay alternative just dropped\\
\\
Upload a CSV of emails and..."](https://x.com/steventey/status/1932945651761098889)

### How Firecrawl compares to alternatives

| Feature | Firecrawl | Manual CSV uploads | Browser extensions | Generic scrapers |
| --- | --- | --- | --- | --- |
| Structured markdown output |  |  |  |  |
| Automatic scheduling & refresh |  |  |  |  |
| JavaScript rendering |  |  |  |  |
| URL metadata preserved |  |  |  |  |
| Multi-tenant scoping |  |  |  |  |
| API-first integration |  |  |  |  |
| Built-in rate limiting & retries |  |  |  |  |
| No manual intervention required |  |  |  |  |

### Tutorials & Guides

[![Web Scraping Change Detection with Firecrawl](https://www.firecrawl.dev/_next/image?url=%2Fimages%2Fblog%2Fchange-detection%2Fchange-detection.jpg&w=3840&q=75&dpl=dpl_2hQ8hmy6vNQsu8DPuBRaRM6deLpr)\\
\\
**Web Scraping Change Detection with Firecrawl** \\
\\
Learn how to build a monitoring system that tracks changes on web pages and intelligently identifies which content has been updated.\\
\\
Read tutorial ‚Üí](https://www.firecrawl.dev/blog/web-scraping-change-detection-with-firecrawl) [![How to Build an Automated Competitor Price Monitoring System with Python](https://www.firecrawl.dev/_next/image?url=%2Fimages%2Fblog%2Fcompetitor_price_scraping%2Fcompetitor-price-scraping.jpg&w=3840&q=75&dpl=dpl_2hQ8hmy6vNQsu8DPuBRaRM6deLpr)\\
\\
**How to Build an Automated Competitor Price Monitoring System with Python** \\
\\
Learn how to build an automated price monitoring system in Python to track and compare competitor prices across e-commerce sites.\\
\\
Read tutorial ‚Üí](https://www.firecrawl.dev/blog/automated-competitor-price-scraping)

//

FAQ

//

## Frequently    asked questions

Everything you need to know about this use case.

General

What types of competitive signals can Firecrawl capture?

Firecrawl can turn pricing tables, product and plan pages, docs updates, release notes, blog posts, case studies, landing pages, and job listings into structured records your competitive intelligence (CI) stack can query.

How do I avoid over-crawling or hitting sensitive areas?

You can scope Firecrawl jobs to specific domains and paths and set crawl frequency per competitor. Many teams focus on pricing, product, docs, and blog paths rather than entire sites.

Technical

How do teams actually consume this data?

Most teams send Firecrawl output into a warehouse, BI layer, or CI dashboard so analysts can build alerts, timeline views, and briefings without owning scraping infrastructure themselves.

Why Firecrawl?

What is Firecrawl's scrape quality and coverage like?

The world's most comprehensive web data API. Our custom browser stack and semantic index deliver superior data quality across any website, handling more content types and edge cases than any competitor.

How does Firecrawl handle complex websites?

JavaScript rendering, dynamic content, and robust request handling built-in.

Can Firecrawl scrape at enterprise scale?

Process millions of pages with automatic rate limiting, caching, and distributed infrastructure.

How fast is Firecrawl scraping?

Optimized scraping engine with parallel processing and smart caching for instant results.

Is Firecrawl built for developers?

Comprehensive docs, SDKs for all major languages, and dedicated support to help you succeed.

\[ 03 / 03 \]

¬∑

Pricing

//

Transparent

//

## Flexible pricing

Explore transparent pricing built for real-world scraping.  Start for free, then scale as you grow.

üá≥üá¥NOK

Free Plan

A lightweight way to try scraping.

No cost, no card, no hassle.

500 credits (one-time)

kr0123456789

one-time

Get started

Scrape 500 pages

2 concurrent requests

Low rate limits

Hobby

Great for side projects and small tools.

Fast, simple, no overkill.

3,000 credits / month

kr012345678901234567890123456789

/monthly

Billed yearly

2 months free

Subscribe

Scrape 3,000 pages

5 concurrent requests

Basic support

kr87 per extra 1k credits

Standard

Most popular

Perfect for scaling with less effort.

Simple, solid, dependable.

100,000 credits / month

kr012345678901234567890123456789

/monthly

Billed yearly

2 months free

Subscribe

Scrape 100,000 pages

50 concurrent requests

Standard support

kr454 per extra 35k credits

Growth

Built for high volume and speed.

Firecrawl at full force.

500,000 credits / month

kr012345678901234567890123456789.0123456789k

/monthly

Billed yearly

2 months free

Subscribe

Scrape 500,000 pages

100 concurrent requests

Priority support

kr1,712 per extra 175k credits

Extra credits are available via auto-recharge packs. [Enable](https://www.firecrawl.dev/signin?view=signup)

Actual price may vary based on the exchange rate in place between USD and NOK at the time of payment processing or invoicing. Prices exclude all taxes, levies and duties and are paid in USD.

## Scale Plans

High-volume plans for teams that need more power and dedicated support. Get access to higher rate limits, more concurrent browsers, and priority support.

[Need more? Contact us](https://fk4bvu0n5qp.typeform.com/to/Ej6oydlg)

Scale

For teams scaling their data pipelines

1,000,000 credits

kr5,792per month

Billed yearly

2 months free

Subscribe

Scrape 1,000,000 pages

150 concurrent requests

Priority support

Enterprise

Power at your pace with custom solutions

Custom credits

Custom

[Get Started](https://fk4bvu0n5qp.typeform.com/to/Ej6oydlg)

Scrape unlimited pages

Custom concurrent requests

Dedicated support & SLA

Bulk discounts

Zero-data retention

SSO & advanced security

\[ CTA \]

\[ CRAWL \]

\[ SCRAPE \]

\[ CTA \]

//

Get started

//

Ready to stay ahead of the competition?

Start monitoring competitors with automated intelligence gathering.

[Start for free](https://www.firecrawl.dev/app/playground)

FOOTER

The easiest way to extract

data from the web

Backed by

Y Combinator

[Linkedin](https://www.linkedin.com/company/firecrawl) [Github](https://github.com/firecrawl/firecrawl) [YouTube](https://www.youtube.com/@Firecrawl_dev)

SOC II ¬∑ Type 2

AICPA

SOC 2

[X (Twitter)](https://x.com/firecrawl) [Discord](https://discord.gg/gSmWdAkdwd)

Products

[Playground](https://www.firecrawl.dev/playground) [Agent](https://www.firecrawl.dev/agent) [Pricing](https://www.firecrawl.dev/pricing) [Templates](https://www.firecrawl.dev/templates) [Changelog](https://www.firecrawl.dev/changelog)

Use Cases

[AI Platforms](https://www.firecrawl.dev/use-cases/ai-platforms) [Lead Enrichment](https://www.firecrawl.dev/use-cases/lead-enrichment) [SEO Teams](https://www.firecrawl.dev/use-cases/seo-teams) [Deep Research](https://www.firecrawl.dev/use-cases/deep-research) [Competitive Intelligence](https://www.firecrawl.dev/use-cases/competitive-intelligence)

Documentation

[Getting started](https://docs.firecrawl.dev/introduction) [API Reference](https://docs.firecrawl.dev/api-reference/introduction) [Integrations](https://www.firecrawl.dev/app) [Examples](https://docs.firecrawl.dev/use-cases/overview) [SDKs](https://docs.firecrawl.dev/sdks/overview)

Company

[Blog](https://www.firecrawl.dev/blog) [Careers](https://www.firecrawl.dev/careers) [Creator & OSS program](https://www.firecrawl.dev/creator-oss-program) [Student program](https://www.firecrawl.dev/student-program)

¬© 2025 Firecrawl

[Terms of Service](https://www.firecrawl.dev/terms-of-service) [Privacy Policy](https://www.firecrawl.dev/privacy-policy) [Report Abuse](mailto:help@firecrawl.com?subject=Issue:)

[All systems normal](https://status.firecrawl.dev/)

StripeM-Inner

## Firecrawl v2.5 Overview
Introducing Parallel Agents - Run multiple /agent queries simultaneously. [Read more ‚Üí](https://www.firecrawl.dev/blog/introducing-parallel-agents)

//

Get started

//

### Ready to build?

Start getting Web Data for free and scale seamlessly as your project expands.No credit card needed.

[Start for free](https://www.firecrawl.dev/signin) [See our plans](https://www.firecrawl.dev/pricing)

#### Table of Contents

[Blog](https://www.firecrawl.dev/blog)

Introducing Firecrawl v2.5 - The World's Best Web Data API

![placeholder](https://www.firecrawl.dev/_next/image?url=%2Fblog%2Fauthors%2Feric-img.jpeg&w=48&q=75&dpl=dpl_2hQ8hmy6vNQsu8DPuBRaRM6deLpr)Eric Ciarla

Oct 30, 2025

![Introducing Firecrawl v2.5 - The World's Best Web Data API image](https://www.firecrawl.dev/_next/image?url=%2Fimages%2Fblog%2Fv25%2Ffirecrawl25combo.webp&w=3840&q=75&dpl=dpl_2hQ8hmy6vNQsu8DPuBRaRM6deLpr)

Today, we're excited to announce Firecrawl v2.5, which delivers the highest quality and most comprehensive web data API. This release represents a significant leap forward in web data extraction, powered by two major infrastructure improvements: our new Semantic Index and a completely custom browser stack.

## A Custom Browser Stack Built for Quality

To achieve maximum data quality, we built our own browser stack from the ground up. This wasn't a decision we made lightly, but the results speak for themselves.

Our custom browser stack automatically detects how each page is rendered, allowing us to extract data at high speeds while maintaining an exceptionally high quality bar. The browser fleet is designed to handle any content type (PDFs, paginated tables, dynamic JavaScript applications) and convert them into clean, agent-ready formats that work seamlessly with AI systems.

This architecture enables us to index complete pages rather than partial content, which is critical for maintaining data integrity. The impact on quality is substantial, as demonstrated in our benchmarks against leading competitors:

![Firecrawl v2.5 Quality Benchmarks](https://www.firecrawl.dev/images/blog/v25/firecrawl25benchmarksquality.webp)

## Introducing Our Semantic Index

Alongside our custom browser stack, we've built a semantic index that fundamentally improves both coverage and speed. This index already serves 40% of all API calls, enabling us to deliver top-tier data quickly across most websites.

The semantic index contains previously captured full page snapshots, embeddings, and structural metadata. This allows us to offer a unique capability: users can request data "as of now" or "as of last known good copy," effectively providing access to any previous or current state of the web at any moment. You can control this behavior using the `maxAge` parameter, which lets you specify how recent the data should be.

This dual-mode approach ensures both reliability and freshness, giving developers the flexibility to choose the right data retrieval strategy for their use case. Our coverage benchmarks demonstrate the effectiveness of this approach:

![Firecrawl v2.5 Coverage Benchmarks](https://www.firecrawl.dev/images/blog/v25/firecrawl25benchmarkscoverage.webp)

## Building the Future of Web Data

Firecrawl v2.5 represents another step toward our larger vision: building a new programmatic layer for the internet. We're creating a web data interface specifically designed for AI agents and modern applications, where accessing web content is as simple and reliable as calling any other API.

We're also committed to transparency and community contribution. In the coming weeks, we'll be open sourcing our web data retrieval benchmarks, allowing the broader developer community to validate and build upon our work.

If you're passionate about this mission and want to help shape the future of web data infrastructure, we're actively hiring. Visit our [careers page](https://www.firecrawl.dev/careers) to learn more about open positions.

## Get Started with Firecrawl v2.5

Firecrawl v2.5 is available now for all users - no code changes required. You can start experiencing the improved quality and coverage today:

- Experiment in our interactive [playground](https://www.firecrawl.dev/playground)
- Review the complete [documentation](https://docs.firecrawl.dev/)
- [Sign up](https://www.firecrawl.dev/) to integrate Firecrawl into your applications

We're excited to see what you build with the world's most reliable web data API.

\-\- Eric and the Firecrawl team

![placeholder](https://www.firecrawl.dev/_next/image?url=%2Fblog%2Fauthors%2Feric-img.jpeg&w=128&q=75&dpl=dpl_2hQ8hmy6vNQsu8DPuBRaRM6deLpr)

Eric Ciarla [@ericciarla](https://x.com/ericciarla)

CMO of Firecrawl

About the Author

Eric Ciarla is the cofounder and Chief Marketing Officer (CMO) of Firecrawl. He also worked on Mendable.ai and sold it to companies like Snapchat, Coinbase, and MongoDB. Previously worked at Ford and Fracta as a Data Scientist. Eric also co-founded SideGuide, a tool for learning code within VS Code with 50,000 users.

More articles by Eric Ciarla

[Extract Web Data at Scale With Parallel Agents](https://www.firecrawl.dev/blog/introducing-parallel-agents) [Introducing the Firecrawl Skill and CLI - Give Agents Real-Time Web Data](https://www.firecrawl.dev/blog/introducing-firecrawl-skill-and-cli) [How Credal Extracts 6M+ URLs Monthly to Power Production AI Agents](https://www.firecrawl.dev/blog/credal-firecrawl-ai-agents) [How to Create an llms.txt File for Any Website](https://www.firecrawl.dev/blog/How-to-Create-an-llms-txt-File-for-Any-Website) [Introducing Spark 1 Pro and Spark 1 Mini](https://www.firecrawl.dev/blog/introducing-spark-1) [Introducing /agent: Gather Data Wherever It Lives on the Web](https://www.firecrawl.dev/blog/introducing-agent) [Retell‚Äôs AI phone agents get LLM-ready content from Firecrawl](https://www.firecrawl.dev/blog/retell-firecrawl-ai-phone-agents) [Introducing Firecrawl v2.5 - The World's Best Web Data API](https://www.firecrawl.dev/blog/the-worlds-best-web-data-api-v25) [Why Firecrawl Beats Octoparse for AI Web Scraping](https://www.firecrawl.dev/blog/firecrawl-vs-octoparse-data-extraction) [Introducing Firecrawl Observer, Our Open-Source Website Monitoring Tool](https://www.firecrawl.dev/blog/introducing-firecrawl-observer)

FOOTER

The easiest way to extract

data from the web

Backed by

Y Combinator

[Linkedin](https://www.linkedin.com/company/firecrawl) [Github](https://github.com/firecrawl/firecrawl) [YouTube](https://www.youtube.com/@Firecrawl_dev)

SOC II ¬∑ Type 2

AICPA

SOC 2

[X (Twitter)](https://x.com/firecrawl) [Discord](https://discord.gg/gSmWdAkdwd)

Products

[Playground](https://www.firecrawl.dev/playground) [Agent](https://www.firecrawl.dev/agent) [Pricing](https://www.firecrawl.dev/pricing) [Templates](https://www.firecrawl.dev/templates) [Changelog](https://www.firecrawl.dev/changelog)

Use Cases

[AI Platforms](https://www.firecrawl.dev/use-cases/ai-platforms) [Lead Enrichment](https://www.firecrawl.dev/use-cases/lead-enrichment) [SEO Teams](https://www.firecrawl.dev/use-cases/seo-teams) [Deep Research](https://www.firecrawl.dev/use-cases/deep-research) [Competitive Intelligence](https://www.firecrawl.dev/use-cases/competitive-intelligence)

Documentation

[Getting started](https://docs.firecrawl.dev/introduction) [API Reference](https://docs.firecrawl.dev/api-reference/introduction) [Integrations](https://www.firecrawl.dev/app) [Examples](https://docs.firecrawl.dev/use-cases/overview) [SDKs](https://docs.firecrawl.dev/sdks/overview)

Company

[Blog](https://www.firecrawl.dev/blog) [Careers](https://www.firecrawl.dev/careers) [Creator & OSS program](https://www.firecrawl.dev/creator-oss-program) [Student program](https://www.firecrawl.dev/student-program)

¬© 2025 Firecrawl

[Terms of Service](https://www.firecrawl.dev/terms-of-service) [Privacy Policy](https://www.firecrawl.dev/privacy-policy) [Report Abuse](mailto:help@firecrawl.com?subject=Issue:)

[Loading status...](https://status.firecrawl.dev/)

## Web Crawling APIs Overview
Introducing Parallel Agents - Run multiple /agent queries simultaneously. [Read more ‚Üí](https://www.firecrawl.dev/blog/introducing-parallel-agents)

//

Get started

//

### Ready to build?

Start getting Web Data for free and scale seamlessly as your project expands.No credit card needed.

[Start for free](https://www.firecrawl.dev/signin) [See our plans](https://www.firecrawl.dev/pricing)

#### All Questions

[Glossary](https://www.firecrawl.dev/glossary)/ [Web Extraction APIs](https://www.firecrawl.dev/glossary/web-extraction-apis)/Questions

[How can I extract data from tables, lists, and nested HTML structures?](https://www.firecrawl.dev/glossary/web-extraction-apis/extract-data-tables-lists-nested-html-structures)

# What is a web crawling API?

## TL;DR

A web crawling API automates the process of systematically discovering and extracting content across websites. It handles the technical complexities like proxy rotation, JavaScript rendering, rate limiting, and anti-bot measures so developers can focus on using the data. Web crawling APIs power search engines, market research tools, competitive intelligence platforms, and AI training systems.

## What is a Web Crawling API?

A web crawling API is a programmatic interface that automates the discovery and extraction of web content at scale. The API starts from seed URLs and follows hyperlinks to systematically navigate through websites, downloading and indexing pages along the way. Web crawling APIs manage infrastructure challenges like rotating proxies, rendering dynamic content, and respecting robots.txt rules.

## The Core Challenge Web Crawling APIs Solve

Building web crawlers from scratch requires managing complex infrastructure. Developers face proxy failures, IP blocks, browser crashes, and JavaScript rendering issues. A web crawling API abstracts these technical hurdles behind a simple API call.

The API handles proxy rotation across thousands of IP addresses, manages [headless browsers](https://www.firecrawl.dev/glossary/web-extraction-apis/what-is-headless-browser) for dynamic content, automatically retries failed requests, and handles complex web infrastructure. This transforms what would be weeks of infrastructure work into a few lines of code.

## Key Capabilities

| Capability | Description |
| --- | --- |
| Auto-discovery | Follows hyperlinks to discover new pages across domains |
| JavaScript rendering | Executes client-side scripts to access dynamic content |
| Intelligent rate limiting | Adjusts request frequency to avoid overwhelming servers |
| Data formatting | Converts HTML to structured formats like JSON or markdown |

## Common Use Cases

**Search engine indexing** remains the dominant use case. Search engines deploy crawlers to continuously discover and index web pages, enabling fast retrieval when users search. Google's Googlebot and Bing's Bingbot crawl billions of pages to maintain fresh [search indexes](https://www.firecrawl.dev/glossary/web-search-apis/what-is-web-search-api).

**Market intelligence teams** use web crawling APIs to monitor competitor pricing, track product catalogs, and analyze market trends. The API automatically visits competitor websites, extracts pricing data, and alerts teams to changes. E-commerce companies rely on this for dynamic pricing strategies.

**AI model training** requires massive amounts of web content. AI crawlers systematically collect text, images, and structured data to train large language models. These crawlers prioritize fresh, authoritative content and handle the scale required for modern AI systems.

## Web Crawling vs. Web Scraping

Web crawling discovers and indexes pages broadly across websites by following links. Web scraping targets specific pages or data points for extraction. Crawlers map entire domains, while scrapers extract precise information.

A crawler might index every page on a news website. A scraper extracts article titles and publication dates from known URLs. Crawling finds what exists, scraping extracts what matters.

## Technical Considerations

**Robots.txt compliance** determines which pages crawlers can access. The [robots.txt file](https://www.firecrawl.dev/glossary/web-crawling-apis/what-is-robots-txt-protocol) specifies crawling rules, including which paths to exclude and crawl rate limits. Reputable crawling APIs respect these rules to maintain ethical data collection practices.

**Resource consumption** affects both the crawler and target websites. Aggressive crawling strains server bandwidth and can trigger rate limiting. Quality crawling APIs implement [polite crawling](https://www.firecrawl.dev/glossary/web-crawling-apis/what-is-polite-crawling) practices, spacing requests appropriately and identifying themselves with proper user agents.

## Key Takeaways

Web crawling APIs automate the complex process of discovering and extracting web content at scale. They handle infrastructure challenges like proxies, JavaScript rendering, and complex web infrastructure that would otherwise require significant engineering resources. The technology powers search engines, competitive intelligence, market research, and AI training systems. When evaluating crawling solutions, prioritize APIs that respect robots.txt files, implement intelligent rate limiting, and offer reliable data formatting options. Modern solutions like [Firecrawl's Crawl API](https://docs.firecrawl.dev/features/crawl) provide production-ready infrastructure that handles these complexities automatically.

Last updated: Jan 26, 2026

\[ CTA \]

\[ CRAWL \]

\[ SCRAPE \]

\[ CTA \]

//

Get started

//

Ready to build?

Start getting Web Data for free and scale seamlessly as your project expands. No credit card needed.

[Start for free](https://www.firecrawl.dev/signin) [See our plans](https://www.firecrawl.dev/pricing)

FOOTER

The easiest way to extract

data from the web

Backed by

Y Combinator

[Linkedin](https://www.linkedin.com/company/firecrawl) [Github](https://github.com/firecrawl/firecrawl) [YouTube](https://www.youtube.com/@Firecrawl_dev)

SOC II ¬∑ Type 2

AICPA

SOC 2

[X (Twitter)](https://x.com/firecrawl) [Discord](https://discord.gg/gSmWdAkdwd)

Products

[Playground](https://www.firecrawl.dev/playground) [Agent](https://www.firecrawl.dev/agent) [Pricing](https://www.firecrawl.dev/pricing) [Templates](https://www.firecrawl.dev/templates) [Changelog](https://www.firecrawl.dev/changelog)

Use Cases

[AI Platforms](https://www.firecrawl.dev/use-cases/ai-platforms) [Lead Enrichment](https://www.firecrawl.dev/use-cases/lead-enrichment) [SEO Teams](https://www.firecrawl.dev/use-cases/seo-teams) [Deep Research](https://www.firecrawl.dev/use-cases/deep-research) [Competitive Intelligence](https://www.firecrawl.dev/use-cases/competitive-intelligence)

Documentation

[Getting started](https://docs.firecrawl.dev/introduction) [API Reference](https://docs.firecrawl.dev/api-reference/introduction) [Integrations](https://www.firecrawl.dev/app) [Examples](https://docs.firecrawl.dev/use-cases/overview) [SDKs](https://docs.firecrawl.dev/sdks/overview)

Company

[Blog](https://www.firecrawl.dev/blog) [Careers](https://www.firecrawl.dev/careers) [Creator & OSS program](https://www.firecrawl.dev/creator-oss-program) [Student program](https://www.firecrawl.dev/student-program)

¬© 2025 Firecrawl

[Terms of Service](https://www.firecrawl.dev/terms-of-service) [Privacy Policy](https://www.firecrawl.dev/privacy-policy) [Report Abuse](mailto:help@firecrawl.com?subject=Issue:)

[All systems normal](https://status.firecrawl.dev/)

## Web Data Extraction
Introducing Spark 1 Pro and Spark 1 Mini models in /agent. [Try it now ‚Üí](https://www.firecrawl.dev/agent)

FOOTER

The easiest way to extract

data from the web

Backed by

Y Combinator

[Linkedin](https://www.linkedin.com/company/firecrawl) [Github](https://github.com/firecrawl/firecrawl) [YouTube](https://www.youtube.com/@Firecrawl_dev)

SOC II ¬∑ Type 2

AICPA

SOC 2

[X (Twitter)](https://x.com/firecrawl) [Discord](https://discord.gg/gSmWdAkdwd)

Products

[Playground](https://www.firecrawl.dev/playground) [Agent](https://www.firecrawl.dev/agent) [Pricing](https://www.firecrawl.dev/pricing) [Templates](https://www.firecrawl.dev/templates) [Changelog](https://www.firecrawl.dev/changelog)

Use Cases

[AI Platforms](https://www.firecrawl.dev/use-cases/ai-platforms) [Lead Enrichment](https://www.firecrawl.dev/use-cases/lead-enrichment) [SEO Teams](https://www.firecrawl.dev/use-cases/seo-teams) [Deep Research](https://www.firecrawl.dev/use-cases/deep-research) [Competitive Intelligence](https://www.firecrawl.dev/use-cases/competitive-intelligence)

Documentation

[Getting started](https://docs.firecrawl.dev/introduction) [API Reference](https://docs.firecrawl.dev/api-reference/introduction) [Integrations](https://www.firecrawl.dev/app) [Examples](https://docs.firecrawl.dev/use-cases/overview) [SDKs](https://docs.firecrawl.dev/sdks/overview)

Company

[Blog](https://www.firecrawl.dev/blog) [Careers](https://www.firecrawl.dev/careers) [Creator & OSS program](https://www.firecrawl.dev/creator-oss-program) [Student program](https://www.firecrawl.dev/student-program)

¬© 2025 Firecrawl

[Terms of Service](https://www.firecrawl.dev/terms-of-service) [Privacy Policy](https://www.firecrawl.dev/privacy-policy) [Report Abuse](mailto:help@firecrawl.com?subject=Issue:)

[All systems normal](https://status.firecrawl.dev/)

reCAPTCHA

Recaptcha requires verification.

[Privacy](https://www.google.com/intl/en/policies/privacy/) \- [Terms](https://www.google.com/intl/en/policies/terms/)

protected by **reCAPTCHA**

[Privacy](https://www.google.com/intl/en/policies/privacy/) \- [Terms](https://www.google.com/intl/en/policies/terms/)

## Using OpenAI Structured Outputs
Introducing Spark 1 Pro and Spark 1 Mini models in /agent. [Try it now ‚Üí](https://www.firecrawl.dev/agent)

//

Get started

//

### Ready to build?

Start getting Web Data for free and scale seamlessly as your project expands.No credit card needed.

[Start for free](https://www.firecrawl.dev/signin) [See our plans](https://www.firecrawl.dev/pricing)

[Blog](https://www.firecrawl.dev/blog)

How to Use OpenAI's Structured Outputs and JSON Strict Mode

![placeholder](https://www.firecrawl.dev/_next/image?url=%2Fblog%2Fauthors%2Feric-img.jpeg&w=48&q=75&dpl=dpl_2hQ8hmy6vNQsu8DPuBRaRM6deLpr)Eric Ciarla

Aug 07, 2024

![How to Use OpenAI's Structured Outputs and JSON Strict Mode image](https://www.firecrawl.dev/_next/image?url=%2Fimages%2Fblog%2Fopenai-structured-output.png&w=3840&q=75&dpl=dpl_2hQ8hmy6vNQsu8DPuBRaRM6deLpr)

Getting structured data from LLMs is super useful for developers integrating AI into their applications, enabling more reliable parsing and processing of model outputs.

OpenAI just released new versions of gpt-4o and gpt-4o-mini which include huge improvements for developers looking to get structured data from LLMs. With the introduction of Structured Outputs and JSON Strict Mode developers can now guarantee a JSON output 100% of the time when setting strict to true.

![Structured Outputs Evaluation Scores from OpenAI's latest models](https://www.firecrawl.dev/images/blog/structured-data-eval-chart.png)**Figure 1:** Structured Output Evaluation Scores from OpenAI's latest models

Without further ado, let's dig into how to use these latest models with and get reliable structured data from them.

### How to use Structured Outputs with JSON Strict Mode

To demonstrate the power of these models, we can use JSON Strict mode to extract structured data from a web page. [See the code on Github.](https://github.com/firecrawl/openai-structured-outputs-with-firecrawl)

#### Prerequisites

Install the required libraries:

```
!pip install firecrawl-py openai
```

#### Step 1: Initialize the FirecrawlApp and OpenAI Client

```
from firecrawl import FirecrawlApp
from openai import OpenAI

firecrawl_app = FirecrawlApp(api_key='FIRECRAWL_API_KEY')
client = OpenAI(api_key='OPENAI_API_KEY')
```

#### Step 2: Scrape Data from a Web Page

```
url = 'https://mendable.ai'
scraped_data = firecrawl_app.scrape_url(url)
```

#### Step 3: Define the OpenAI API Request

```
messages = [\
    {\
        "role": "system",\
        "content": "You are a helpful assistant that extracts structured data from web pages."\
    },\
    {\
        "role": "user",\
        "content": f"Extract the headline and description from the following HTML content: {scraped_data['content']}"\
    }\
]

response_format = {
    "type": "json_schema",
    "json_schema": {
        "name": "extracted_data",
        "strict": True,
        "schema": {
            "type": "object",
            "properties": {
                "headline": {
                    "type": "string"
                },
                "description": {
                    "type": "string"
                }
            },
            "required": ["headline", "description"],
            "additionalProperties": False
        }
    }
}
```

#### Step 4: Call the OpenAI API and Extract Structured Data

If you are wondering which models you can use with OpenAI's structued output and JSON Strict mode it is both gpt-4o-2024-08-06 and gpt-4o-mini-2024-07-18.

```
chat_completion = client.chat.completions.create(
    model="gpt-4o-2024-08-06",
    messages=messages,
    response_format=response_format
)

extracted_data = chat_completion.choices[0].message.content

print(extracted_data)
```

By following these steps, you can reliably extract structured data from web pages using OpenAI's latest models with JSON Strict Mode.

That's about it! In this article, we showed you how to use Structured Output with scraped web data, but the sky's the limit when it comes to what you can build with reliable structured output from LLMs!

### References

- [Introducing Structured Outputs in the API](https://openai.com/index/introducing-structured-outputs-in-the-api/)

![placeholder](https://www.firecrawl.dev/_next/image?url=%2Fblog%2Fauthors%2Feric-img.jpeg&w=128&q=75&dpl=dpl_2hQ8hmy6vNQsu8DPuBRaRM6deLpr)

Eric Ciarla [@ericciarla](https://x.com/ericciarla)

CMO of Firecrawl

About the Author

Eric Ciarla is the cofounder and Chief Marketing Officer (CMO) of Firecrawl. He also worked on Mendable.ai and sold it to companies like Snapchat, Coinbase, and MongoDB. Previously worked at Ford and Fracta as a Data Scientist. Eric also co-founded SideGuide, a tool for learning code within VS Code with 50,000 users.

More articles by Eric Ciarla

[Extract Web Data at Scale With Parallel Agents](https://www.firecrawl.dev/blog/introducing-parallel-agents) [Introducing the Firecrawl Skill and CLI - Give Agents Real-Time Web Data](https://www.firecrawl.dev/blog/introducing-firecrawl-skill-and-cli) [How Credal Extracts 6M+ URLs Monthly to Power Production AI Agents](https://www.firecrawl.dev/blog/credal-firecrawl-ai-agents) [How to Create an llms.txt File for Any Website](https://www.firecrawl.dev/blog/How-to-Create-an-llms-txt-File-for-Any-Website) [Introducing Spark 1 Pro and Spark 1 Mini](https://www.firecrawl.dev/blog/introducing-spark-1) [Introducing /agent: Gather Data Wherever It Lives on the Web](https://www.firecrawl.dev/blog/introducing-agent) [Retell‚Äôs AI phone agents get LLM-ready content from Firecrawl](https://www.firecrawl.dev/blog/retell-firecrawl-ai-phone-agents) [Introducing Firecrawl v2.5 - The World's Best Web Data API](https://www.firecrawl.dev/blog/the-worlds-best-web-data-api-v25) [Why Firecrawl Beats Octoparse for AI Web Scraping](https://www.firecrawl.dev/blog/firecrawl-vs-octoparse-data-extraction) [Introducing Firecrawl Observer, Our Open-Source Website Monitoring Tool](https://www.firecrawl.dev/blog/introducing-firecrawl-observer)

FOOTER

The easiest way to extract

data from the web

Backed by

Y Combinator

[Linkedin](https://www.linkedin.com/company/firecrawl) [Github](https://github.com/firecrawl/firecrawl) [YouTube](https://www.youtube.com/@Firecrawl_dev)

SOC II ¬∑ Type 2

AICPA

SOC 2

[X (Twitter)](https://x.com/firecrawl) [Discord](https://discord.gg/gSmWdAkdwd)

Products

[Playground](https://www.firecrawl.dev/playground) [Agent](https://www.firecrawl.dev/agent) [Pricing](https://www.firecrawl.dev/pricing) [Templates](https://www.firecrawl.dev/templates) [Changelog](https://www.firecrawl.dev/changelog)

Use Cases

[AI Platforms](https://www.firecrawl.dev/use-cases/ai-platforms) [Lead Enrichment](https://www.firecrawl.dev/use-cases/lead-enrichment) [SEO Teams](https://www.firecrawl.dev/use-cases/seo-teams) [Deep Research](https://www.firecrawl.dev/use-cases/deep-research) [Competitive Intelligence](https://www.firecrawl.dev/use-cases/competitive-intelligence)

Documentation

[Getting started](https://docs.firecrawl.dev/introduction) [API Reference](https://docs.firecrawl.dev/api-reference/introduction) [Integrations](https://www.firecrawl.dev/app) [Examples](https://docs.firecrawl.dev/use-cases/overview) [SDKs](https://docs.firecrawl.dev/sdks/overview)

Company

[Blog](https://www.firecrawl.dev/blog) [Careers](https://www.firecrawl.dev/careers) [Creator & OSS program](https://www.firecrawl.dev/creator-oss-program) [Student program](https://www.firecrawl.dev/student-program)

¬© 2025 Firecrawl

[Terms of Service](https://www.firecrawl.dev/terms-of-service) [Privacy Policy](https://www.firecrawl.dev/privacy-policy) [Report Abuse](mailto:help@firecrawl.com?subject=Issue:)

[Loading status...](https://status.firecrawl.dev/)

## News Article Extraction
Introducing Spark 1 Pro and Spark 1 Mini models in /agent. [Try it now ‚Üí](https://www.firecrawl.dev/agent)

//

Get started

//

### Ready to build?

Start getting Web Data for free and scale seamlessly as your project expands. No credit card needed.

[Start for free](https://www.firecrawl.dev/signin) [See our plans](https://www.firecrawl.dev/pricing)

#### All Questions

[Glossary](https://www.firecrawl.dev/glossary)/ [Web Extraction APIs](https://www.firecrawl.dev/glossary/web-extraction-apis)/Questions

[What is natural language data extraction?](https://www.firecrawl.dev/glossary/web-extraction-apis/what-is-natural-language-data-extraction)

[What is structured data vs unstructured data when extracting web data?](https://www.firecrawl.dev/glossary/web-extraction-apis/what-is-structured-vs-unstructured-data-web-extraction)

# What is news article extraction?

## TL;DR

News extraction pulls just the story‚Äîheadline, byline, date, body text‚Äîfiltering out ads, related links, and navigation.

## What gets extracted

| Field | Description |
| --- | --- |
| Title | Article headline |
| Author | Byline |
| Date | Publication date |
| Body | Main article text |
| Images | Photos with captions |

## Why specialized extraction

Generic scraping returns entire pages. News extraction uses models trained on article structures to identify content boundaries and ignore sidebars.

## Use cases

- Media monitoring across publications
- Sentiment analysis on news coverage
- Content aggregation from multiple sources

[Firecrawl's `onlyMainContent`](https://docs.firecrawl.dev/features/scrape) extracts article text cleanly. You can also pull structured fields like author and date.

## Key Takeaways

News extraction isolates story content from page clutter for monitoring, analysis, and aggregation workflows.

Last updated: Jan 26, 2026

\[ CTA \]

\[ CRAWL \]

\[ SCRAPE \]

\[ CTA \]

//

Get started

//

Ready to build?

Start getting Web Data for free and scale seamlessly as your project expands. No credit card needed.

[Start for free](https://www.firecrawl.dev/signin) [See our plans](https://www.firecrawl.dev/pricing)

FOOTER

The easiest way to extract

data from the web

Backed by

Y Combinator

[Linkedin](https://www.linkedin.com/company/firecrawl) [Github](https://github.com/firecrawl/firecrawl) [YouTube](https://www.youtube.com/@Firecrawl_dev)

SOC II ¬∑ Type 2

AICPA

SOC 2

[X (Twitter)](https://x.com/firecrawl) [Discord](https://discord.gg/gSmWdAkdwd)

Products

[Playground](https://www.firecrawl.dev/playground) [Agent](https://www.firecrawl.dev/agent) [Pricing](https://www.firecrawl.dev/pricing) [Templates](https://www.firecrawl.dev/templates) [Changelog](https://www.firecrawl.dev/changelog)

Use Cases

[AI Platforms](https://www.firecrawl.dev/use-cases/ai-platforms) [Lead Enrichment](https://www.firecrawl.dev/use-cases/lead-enrichment) [SEO Teams](https://www.firecrawl.dev/use-cases/seo-teams) [Deep Research](https://www.firecrawl.dev/use-cases/deep-research) [Competitive Intelligence](https://www.firecrawl.dev/use-cases/competitive-intelligence)

Documentation

[Getting started](https://docs.firecrawl.dev/introduction) [API Reference](https://docs.firecrawl.dev/api-reference/introduction) [Integrations](https://www.firecrawl.dev/app) [Examples](https://docs.firecrawl.dev/use-cases/overview) [SDKs](https://docs.firecrawl.dev/sdks/overview)

Company

[Blog](https://www.firecrawl.dev/blog) [Careers](https://www.firecrawl.dev/careers) [Creator & OSS program](https://www.firecrawl.dev/creator-oss-program) [Student program](https://www.firecrawl.dev/student-program)

¬© 2025 Firecrawl

[Terms of Service](https://www.firecrawl.dev/terms-of-service) [Privacy Policy](https://www.firecrawl.dev/privacy-policy) [Report Abuse](mailto:help@firecrawl.com?subject=Issue:)

[All systems normal](https://status.firecrawl.dev/)

## Firecrawl CLI and Skill
Introducing Spark 1 Pro and Spark 1 Mini models in /agent. [Try it now ‚Üí](https://www.firecrawl.dev/agent)

//

Get started

//

### Ready to build?

Start getting Web Data for free and scale seamlessly as your project expands. No credit card needed.

[Start for free](https://www.firecrawl.dev/signin) [See our plans](https://www.firecrawl.dev/pricing)

#### Table of Contents

[Blog](https://www.firecrawl.dev/blog)

Introducing the Firecrawl Skill and CLI - Give Agents Real-Time Web Data

![placeholder](https://www.firecrawl.dev/_next/image?url=%2Fblog%2Fauthors%2Feric-img.jpeg&w=48&q=75&dpl=dpl_2hQ8hmy6vNQsu8DPuBRaRM6deLpr)Eric Ciarla

Jan 27, 2026

![Introducing the Firecrawl Skill and CLI - Give Agents Real-Time Web Data image](https://www.firecrawl.dev/_next/image?url=%2Fimages%2Fblog%2Ffirecrawl-cli-skills-launch%2Ffirecrawlskillscli.webp&w=3840&q=75&dpl=dpl_2hQ8hmy6vNQsu8DPuBRaRM6deLpr)

Today, we're launching **Firecrawl CLI** and **Skill** to give your AI agents reliable access to real-time web data.

## TL;DR:

- **Firecrawl CLI** is a command-line tool for scraping, searching, crawling, and mapping the web with results written directly to the filesystem.
- **The Firecrawl Skill** teaches AI agents how to install and use the CLI on their own - no manual setup required.
- Together, they give agents clean, structured web data exactly when they need it.

Just run:

```
$ npx skills add firecrawl/cli
```

That's it. The Firecrawl Skill handles the rest.

## The Problem: Agents Need Better Web Data

Most agents rely on web fetch tools that break on JavaScript-heavy sites, miss key content, or return unusable HTML. When they do get data, they dump entire pages into context, wasting tokens and slowing down reasoning.

The Firecrawl CLI and Skill helps AI agents reliably access real-time web data on their own. With a single install, agents like Claude Code, Antigravity, and OpenCode can access all of your favorite Firecrawl endpoints - including scrape, search, crawl, and map for any use case you need.

## Meet Firecrawl CLI

[Firecrawl CLI](https://docs.firecrawl.dev/sdks/cli) is a command-line tool designed for agents and developers who need **reliable web data.**

### Core Commands

- **scrape** \- Pull clean markdown from any page, even JavaScript-heavy sites
- **crawl** \- Follow links recursively and gather content from an entire site
- **map** \- Discover all URLs on a domain for comprehensive coverage
- **search** \- Search the web and scrape the results in one step

### Context-Efficient Data for Agents

Firecrawl CLI uses a file-based approach for context management and bash methods for efficient search and retrieval.

### Industry-Leading Reliability

[Firecrawl delivers >80% coverage on benchmark evaluations](https://www.firecrawl.dev/blog/the-worlds-best-web-data-api-v25) \- outperforming every other provider tested. It handles JavaScript rendering, dynamic content, authentication flows, and complex page structures that break other scrapers.

_(Methodology: Checked 1,000 URLs for content recall and whether various tools in the market retrieved at least 10% of the expected content gap, using the [Firecrawl scrape-content-dataset-v1 dataset](https://huggingface.co/datasets/firecrawl/scrape-content-dataset-v1).)_

**Example usage:**

```
# Scrape a page to markdown
$ firecrawl scrape https://example.com/pricing --format markdown -o pricing.md

# Crawl an entire website, wait for completion, and output results
$ firecrawl crawl https://example.com --wait --progress -o example-crawl.json

# Map an entire domain
$ firecrawl map https://example.com -o sitemap.json

# Search and scrape top results
$ firecrawl search "AI agent benchmarks 2026" --scrape --limit 5 -o results/
```

All results are written to the filesystem, so agents can search, analyze, or process data locally.

## Firecrawl Skill: Teach Agents to Use the CLI

The Firecrawl Skill is a skill package that teaches AI agents how to install, authenticate, and use Firecrawl CLI - end to end.

Skills are declarative packages that agents can install via the `npx skills` protocol. Once installed, agents know how to use the tool without manual integration.

### What the Skill Teaches

1. How to install Firecrawl CLI
2. How to authenticate with an API key
3. When and how to use scrape, map, and search commands
4. How to structure output for efficient filesystem usage

### Coding Agent Harness Compatibility

The Firecrawl Skill works with any agent that supports the Skills protocol:

- **Claude Code** ‚Äî Agentic coding in your terminal
- **OpenAI Codex** ‚Äî Build with GPT-4 in the CLI
- **Gemini CLI** ‚Äî Google's agent interface
- **OpenCode** ‚Äî Open-source agent harness
- And more

One skill, every major coding agent harness.

### Why Skills Matter

You don't configure endpoints, handle auth, or write tool definitions. The Skill does it. Add Firecrawl once, and your agent knows how to use it forever.

As the Skill evolves, your agent learns new capabilities automatically. No code changes. No redeployment. It just works.

## Firecrawl CLI + Skill: Agents Empowered with Live Web Data

When you combine Firecrawl CLI with our skill, your agent can reliably access web data on its own.

### How It Works

1. You run `$ npx skills add firecrawl/cli`
2. The skill teaches your agent about Firecrawl CLI capabilities
3. When your agent needs web data, it installs and uses the CLI automatically
4. Results are written to the filesystem, not dumped into context
5. Your agent searches, analyzes, or processes the data locally

Here's a quick look at common use cases where agents with Firecrawl shine:

| Use case | Value |
| --- | --- |
| **Competitor product research** | Track pricing, feature pages, and changes across competitor sites - so you get fresh data on specs, updates, and positioning without manual checking |
| **Documentation and help centers** | Pull full docs and help centers for the latest information, giving agents current API references and guides instead of stale training data |
| **Site change monitoring** | Detect updates across large sites, from pricing shifts to new content, and map entire domains to track changes over time automatically |
| **Deep research with sources** | Collect structured sources with URLs and timestamps to ground answers in verifiable data with proper attribution |

## Get Started

Install the Firecrawl Skill:

```
$ npx skills add firecrawl/cli
```

Or use the CLI directly:

```
$ npm install -g firecrawl-cli
$ firecrawl auth --api-key fc-YOUR_KEY
$ firecrawl scrape https://example.com
```

[Check out our docs for more info.](https://docs.firecrawl.dev/sdks/cli)

Give your agent the best web data available. No context bloat. Just reliable, real-time information when it needs it.

* * *

**Resources:**

- **GitHub**: [github.com/firecrawl/cli](https://github.com/firecrawl/cli)
- **Documentation**: [docs.firecrawl.dev/cli](https://docs.firecrawl.dev/cli)
- **Get an API key**: [firecrawl.dev](https://firecrawl.dev/)

\[ CTA \]

\[ CRAWL \]

\[ SCRAPE \]

\[ CTA \]

//

Get started

//

Ready to build?

Start getting Web Data for free and scale seamlessly as your project expands. No credit card needed.

[Start for free](https://www.firecrawl.dev/signin) [See our plans](https://www.firecrawl.dev/pricing)

![placeholder](https://www.firecrawl.dev/_next/image?url=%2Fblog%2Fauthors%2Feric-img.jpeg&w=128&q=75&dpl=dpl_2hQ8hmy6vNQsu8DPuBRaRM6deLpr)

Eric Ciarla [@ericciarla](https://x.com/ericciarla)

CMO of Firecrawl

About the Author

Eric Ciarla is the cofounder and Chief Marketing Officer (CMO) of Firecrawl. He also worked on Mendable.ai and sold it to companies like Snapchat, Coinbase, and MongoDB. Previously worked at Ford and Fracta as a Data Scientist. Eric also co-founded SideGuide, a tool for learning code within VS Code with 50,000 users.

More articles by Eric Ciarla

[Extract Web Data at Scale With Parallel Agents](https://www.firecrawl.dev/blog/introducing-parallel-agents) [Introducing the Firecrawl Skill and CLI - Give Agents Real-Time Web Data](https://www.firecrawl.dev/blog/introducing-firecrawl-skill-and-cli) [How Credal Extracts 6M+ URLs Monthly to Power Production AI Agents](https://www.firecrawl.dev/blog/credal-firecrawl-ai-agents) [How to Create an llms.txt File for Any Website](https://www.firecrawl.dev/blog/How-to-Create-an-llms-txt-File-for-Any-Website) [Introducing Spark 1 Pro and Spark 1 Mini](https://www.firecrawl.dev/blog/introducing-spark-1) [Introducing /agent: Gather Data Wherever It Lives on the Web](https://www.firecrawl.dev/blog/introducing-agent) [Retell‚Äôs AI phone agents get LLM-ready content from Firecrawl](https://www.firecrawl.dev/blog/retell-firecrawl-ai-phone-agents) [Introducing Firecrawl v2.5 - The World's Best Web Data API](https://www.firecrawl.dev/blog/the-worlds-best-web-data-api-v25) [Why Firecrawl Beats Octoparse for AI Web Scraping](https://www.firecrawl.dev/blog/firecrawl-vs-octoparse-data-extraction) [Introducing Firecrawl Observer, Our Open-Source Website Monitoring Tool](https://www.firecrawl.dev/blog/introducing-firecrawl-observer)

FOOTER

The easiest way to extract

data from the web

Backed by

Y Combinator

[Linkedin](https://www.linkedin.com/company/firecrawl) [Github](https://github.com/firecrawl/firecrawl) [YouTube](https://www.youtube.com/@Firecrawl_dev)

SOC II ¬∑ Type 2

AICPA

SOC 2

[X (Twitter)](https://x.com/firecrawl) [Discord](https://discord.gg/gSmWdAkdwd)

Products

[Playground](https://www.firecrawl.dev/playground) [Agent](https://www.firecrawl.dev/agent) [Pricing](https://www.firecrawl.dev/pricing) [Templates](https://www.firecrawl.dev/templates) [Changelog](https://www.firecrawl.dev/changelog)

Use Cases

[AI Platforms](https://www.firecrawl.dev/use-cases/ai-platforms) [Lead Enrichment](https://www.firecrawl.dev/use-cases/lead-enrichment) [SEO Teams](https://www.firecrawl.dev/use-cases/seo-teams) [Deep Research](https://www.firecrawl.dev/use-cases/deep-research) [Competitive Intelligence](https://www.firecrawl.dev/use-cases/competitive-intelligence)

Documentation

[Getting started](https://docs.firecrawl.dev/introduction) [API Reference](https://docs.firecrawl.dev/api-reference/introduction) [Integrations](https://www.firecrawl.dev/app) [Examples](https://docs.firecrawl.dev/use-cases/overview) [SDKs](https://docs.firecrawl.dev/sdks/overview)

Company

[Blog](https://www.firecrawl.dev/blog) [Careers](https://www.firecrawl.dev/careers) [Creator & OSS program](https://www.firecrawl.dev/creator-oss-program) [Student program](https://www.firecrawl.dev/student-program)

¬© 2025 Firecrawl

[Terms of Service](https://www.firecrawl.dev/terms-of-service) [Privacy Policy](https://www.firecrawl.dev/privacy-policy) [Report Abuse](mailto:help@firecrawl.com?subject=Issue:)

[All systems normal](https://status.firecrawl.dev/)

## Subscription Activation
Introducing Parallel Agents - Run multiple /agent queries simultaneously. [Read more ‚Üí](https://www.firecrawl.dev/blog/introducing-parallel-agents)

# Purchase Successful!

Welcome to the Firecrawl family!

Your subscription is now active.

Access your new credits

Enjoy faster scraping speeds

Integrate with your favorite tools

Go to Dashboard

Redirecting in 10 seconds...

FOOTER

The easiest way to extract

data from the web

Backed by

Y Combinator

[Linkedin](https://www.linkedin.com/company/firecrawl) [Github](https://github.com/firecrawl/firecrawl) [YouTube](https://www.youtube.com/@Firecrawl_dev)

SOC II ¬∑ Type 2

AICPA

SOC 2

[X (Twitter)](https://x.com/firecrawl) [Discord](https://discord.gg/gSmWdAkdwd)

Products

[Playground](https://www.firecrawl.dev/playground) [Agent](https://www.firecrawl.dev/agent) [Pricing](https://www.firecrawl.dev/pricing) [Templates](https://www.firecrawl.dev/templates) [Changelog](https://www.firecrawl.dev/changelog)

Use Cases

[AI Platforms](https://www.firecrawl.dev/use-cases/ai-platforms) [Lead Enrichment](https://www.firecrawl.dev/use-cases/lead-enrichment) [SEO Teams](https://www.firecrawl.dev/use-cases/seo-teams) [Deep Research](https://www.firecrawl.dev/use-cases/deep-research) [Competitive Intelligence](https://www.firecrawl.dev/use-cases/competitive-intelligence)

Documentation

[Getting started](https://docs.firecrawl.dev/introduction) [API Reference](https://docs.firecrawl.dev/api-reference/introduction) [Integrations](https://www.firecrawl.dev/app) [Examples](https://docs.firecrawl.dev/use-cases/overview) [SDKs](https://docs.firecrawl.dev/sdks/overview)

Company

[Blog](https://www.firecrawl.dev/blog) [Careers](https://www.firecrawl.dev/careers) [Creator & OSS program](https://www.firecrawl.dev/creator-oss-program) [Student program](https://www.firecrawl.dev/student-program)

¬© 2025 Firecrawl

[Terms of Service](https://www.firecrawl.dev/terms-of-service) [Privacy Policy](https://www.firecrawl.dev/privacy-policy) [Report Abuse](mailto:help@firecrawl.com?subject=Issue:)

[All systems normal](https://status.firecrawl.dev/)

## Location and Language Settings
Introducing Parallel Agents - Run multiple /agent queries simultaneously. [Read more ‚Üí](https://www.firecrawl.dev/blog/introducing-parallel-agents)

//

Get started

//

### Ready to build?

Start getting Web Data for free and scale seamlessly as your project expands.No credit card needed.

[Start for free](https://www.firecrawl.dev/signin) [See our plans](https://www.firecrawl.dev/pricing)

[Blog](https://www.firecrawl.dev/blog)

Launch Week II - Day 2: Introducing Location and Language Settings

![placeholder](https://www.firecrawl.dev/_next/image?url=%2Fblog%2Fauthors%2Feric-img.jpeg&w=48&q=75&dpl=dpl_2hQ8hmy6vNQsu8DPuBRaRM6deLpr)Eric Ciarla

Oct 29, 2024

![Launch Week II - Day 2: Introducing Location and Language Settings image](https://www.firecrawl.dev/_next/image?url=%2Fimages%2Fblog%2Ffirecrawl-location-language.jpg&w=3840&q=75&dpl=dpl_2hQ8hmy6vNQsu8DPuBRaRM6deLpr)

Welcome to Day 2 of Firecrawl's second Launch Week! Today, we're thrilled to introduce our latest feature: **Location and Language Settings**.

**Discover Location and Language Settings**

With this new feature, you can now specify a country and preferred languages to receive content that's tailored to your target location and linguistic preferences. This means more relevant and localized data for your web scraping projects.

**How It Works**

When you set the location parameters, Firecrawl utilizes an appropriate proxy (if available) and emulates the corresponding language and timezone settings. By default, the country is set to `'US'` if not specified.

**Getting Started with Location and Language Settings**

To leverage these new settings, include the `location` object in your request body with the following properties:

- `country`: ISO 3166-1 alpha-2 country code (e.g., `'US'`, `'AU'`, `'DE'`, `'JP'`). Defaults to `'US'`.
- `languages`: An array of preferred languages and locales for the request in order of priority. Defaults to the language of the specified location.

**Example Usage**

Here's how you can get started using Python:

```
from firecrawl import FirecrawlApp

app = FirecrawlApp(api_key="fc-YOUR_API_KEY")

# Scrape a website with location and language settings
scrape_result = app.scrape_url('airbnb.com',
    params={
        'formats': ['markdown', 'html'],
        'location': {
            'country': 'BR',
            'languages': ['pt-BR']
        }
    }
)
print(scrape_result)
```

**Understanding the Response**

By specifying the location as Brazil (`'BR'`) and the preferred language as Brazilian Portuguese (`'pt-BR'`), you'll receive content as it appears to users in Brazil, in Portuguese.

**Why Use Location and Language Settings?**

- **Relevance**: Access content that's specific to a particular country or language.
- **Localization**: Scrape websites as they appear to users in different regions.
- **Customization**: Tailor your scraping to match your target audience or market.

**What‚Äôs Next?**

We're just getting warmed up with Launch Week II! The Location and Language Settings are just one of the exciting new features we're rolling out to enhance your web scraping capabilities.

We'd love to hear how you plan to use these new settings in your projects. Your feedback helps us continue to improve and tailor our services to better meet your needs.

Happy scraping, and stay tuned for Day 3 of [Launch Week II](https://www.firecrawl.dev/launch-week) tomorrow!

\[ CTA \]

\[ CRAWL \]

\[ SCRAPE \]

\[ CTA \]

//

Get started

//

Ready to build?

Start getting Web Data for free and scale seamlessly as your project expands. No credit card needed.

[Start for free](https://www.firecrawl.dev/signin) [See our plans](https://www.firecrawl.dev/pricing)

![placeholder](https://www.firecrawl.dev/_next/image?url=%2Fblog%2Fauthors%2Feric-img.jpeg&w=128&q=75&dpl=dpl_2hQ8hmy6vNQsu8DPuBRaRM6deLpr)

Eric Ciarla [@ericciarla](https://x.com/ericciarla)

CMO of Firecrawl

About the Author

Eric Ciarla is the cofounder and Chief Marketing Officer (CMO) of Firecrawl. He also worked on Mendable.ai and sold it to companies like Snapchat, Coinbase, and MongoDB. Previously worked at Ford and Fracta as a Data Scientist. Eric also co-founded SideGuide, a tool for learning code within VS Code with 50,000 users.

More articles by Eric Ciarla

[Extract Web Data at Scale With Parallel Agents](https://www.firecrawl.dev/blog/introducing-parallel-agents) [Introducing the Firecrawl Skill and CLI - Give Agents Real-Time Web Data](https://www.firecrawl.dev/blog/introducing-firecrawl-skill-and-cli) [How Credal Extracts 6M+ URLs Monthly to Power Production AI Agents](https://www.firecrawl.dev/blog/credal-firecrawl-ai-agents) [How to Create an llms.txt File for Any Website](https://www.firecrawl.dev/blog/How-to-Create-an-llms-txt-File-for-Any-Website) [Introducing Spark 1 Pro and Spark 1 Mini](https://www.firecrawl.dev/blog/introducing-spark-1) [Introducing /agent: Gather Data Wherever It Lives on the Web](https://www.firecrawl.dev/blog/introducing-agent) [Retell‚Äôs AI phone agents get LLM-ready content from Firecrawl](https://www.firecrawl.dev/blog/retell-firecrawl-ai-phone-agents) [Introducing Firecrawl v2.5 - The World's Best Web Data API](https://www.firecrawl.dev/blog/the-worlds-best-web-data-api-v25) [Why Firecrawl Beats Octoparse for AI Web Scraping](https://www.firecrawl.dev/blog/firecrawl-vs-octoparse-data-extraction) [Introducing Firecrawl Observer, Our Open-Source Website Monitoring Tool](https://www.firecrawl.dev/blog/introducing-firecrawl-observer)

FOOTER

The easiest way to extract

data from the web

Backed by

Y Combinator

[Linkedin](https://www.linkedin.com/company/firecrawl) [Github](https://github.com/firecrawl/firecrawl) [YouTube](https://www.youtube.com/@Firecrawl_dev)

SOC II ¬∑ Type 2

AICPA

SOC 2

[X (Twitter)](https://x.com/firecrawl) [Discord](https://discord.gg/gSmWdAkdwd)

Products

[Playground](https://www.firecrawl.dev/playground) [Agent](https://www.firecrawl.dev/agent) [Pricing](https://www.firecrawl.dev/pricing) [Templates](https://www.firecrawl.dev/templates) [Changelog](https://www.firecrawl.dev/changelog)

Use Cases

[AI Platforms](https://www.firecrawl.dev/use-cases/ai-platforms) [Lead Enrichment](https://www.firecrawl.dev/use-cases/lead-enrichment) [SEO Teams](https://www.firecrawl.dev/use-cases/seo-teams) [Deep Research](https://www.firecrawl.dev/use-cases/deep-research) [Competitive Intelligence](https://www.firecrawl.dev/use-cases/competitive-intelligence)

Documentation

[Getting started](https://docs.firecrawl.dev/introduction) [API Reference](https://docs.firecrawl.dev/api-reference/introduction) [Integrations](https://www.firecrawl.dev/app) [Examples](https://docs.firecrawl.dev/use-cases/overview) [SDKs](https://docs.firecrawl.dev/sdks/overview)

Company

[Blog](https://www.firecrawl.dev/blog) [Careers](https://www.firecrawl.dev/careers) [Creator & OSS program](https://www.firecrawl.dev/creator-oss-program) [Student program](https://www.firecrawl.dev/student-program)

¬© 2025 Firecrawl

[Terms of Service](https://www.firecrawl.dev/terms-of-service) [Privacy Policy](https://www.firecrawl.dev/privacy-policy) [Report Abuse](mailto:help@firecrawl.com?subject=Issue:)

[All systems normal](https://status.firecrawl.dev/)

## Firecrawl Brand Assets
Introducing Spark 1 Pro and Spark 1 Mini models in /agent. [Try it now ‚Üí](https://www.firecrawl.dev/agent)

## Firecrawl  Brand Assets

Welcome to the Firecrawl brand hub. Below you'll find everything you need to keep our brand consistent and recognizable across all platforms.

Download brand assets

Wordmark

Firecrawl‚Äôs wordmark is a customized logotype designed for legibility and impact. Use it as the primary logo in most situations. Avoid stretching, recoloring, or modifying the wordmark.

SVG

[PNG](https://www.firecrawl.dev/brand/firecrawl-light-wordmark.png)

SVG

[PNG](https://www.firecrawl.dev/brand/firecrawl-light-wordmark.png)

SVG

[PNG](https://www.firecrawl.dev/brand/firecrawl-wordmark.png)

Symbol

The flame symbol represents Firecrawl‚Äôs core mission: blazing-fast, stealthy, and persistent data crawling. It should be used when square or minimal versions of the logo are required.

SVG

[PNG](https://www.firecrawl.dev/brand/firecrawl-light-logo.png)

SVG

[PNG](https://www.firecrawl.dev/brand/firecrawl-light-logo.png)

SVG

[PNG](https://www.firecrawl.dev/brand/firecrawl-logo.png)

Icon

When representing Firecrawl, whether on social platforms, marketplaces, app launchers, or anywhere a compact brand mark is needed, this stylized flame icon should be used.

![Firecrawl app icon](https://www.firecrawl.dev/_next/image?url=%2Fassets-original%2Ffirecrawl-app.png&w=256&q=75&dpl=dpl_2hQ8hmy6vNQsu8DPuBRaRM6deLpr)

[Download as PNG](https://www.firecrawl.dev/brand/firecrawl-app-icon.webp)

Colors

Firecrawl‚Äôs color system is built for clarity and contrast. Heat is our signature, bold, energetic, and expressive.

Graphite and Paper provide a clean, neutral backdrop that lets the orange shine.

The palette works seamlessly across light and dark themes, ensuring accessibility and brand consistency.

Heat

#FA5D19

rgb(250, 93, 25)

hsl(19, 95%, 54%)

Copy

Graphite

#262626

rgb(38, 38, 38)

hsl(0, 0%, 15%)

Copy

Paper

#F9F9F9

rgb(249, 249, 249)

hsl(0, 0%, 98%)

Copy

FOOTER

The easiest way to extract

data from the web

Backed by

Y Combinator

[Linkedin](https://www.linkedin.com/company/firecrawl) [Github](https://github.com/firecrawl/firecrawl) [YouTube](https://www.youtube.com/@Firecrawl_dev)

SOC II ¬∑ Type 2

AICPA

SOC 2

[X (Twitter)](https://x.com/firecrawl) [Discord](https://discord.gg/gSmWdAkdwd)

Products

[Playground](https://www.firecrawl.dev/playground) [Agent](https://www.firecrawl.dev/agent) [Pricing](https://www.firecrawl.dev/pricing) [Templates](https://www.firecrawl.dev/templates) [Changelog](https://www.firecrawl.dev/changelog)

Use Cases

[AI Platforms](https://www.firecrawl.dev/use-cases/ai-platforms) [Lead Enrichment](https://www.firecrawl.dev/use-cases/lead-enrichment) [SEO Teams](https://www.firecrawl.dev/use-cases/seo-teams) [Deep Research](https://www.firecrawl.dev/use-cases/deep-research) [Competitive Intelligence](https://www.firecrawl.dev/use-cases/competitive-intelligence)

Documentation

[Getting started](https://docs.firecrawl.dev/introduction) [API Reference](https://docs.firecrawl.dev/api-reference/introduction) [Integrations](https://www.firecrawl.dev/app) [Examples](https://docs.firecrawl.dev/use-cases/overview) [SDKs](https://docs.firecrawl.dev/sdks/overview)

Company

[Blog](https://www.firecrawl.dev/blog) [Careers](https://www.firecrawl.dev/careers) [Creator & OSS program](https://www.firecrawl.dev/creator-oss-program) [Student program](https://www.firecrawl.dev/student-program)

¬© 2025 Firecrawl

[Terms of Service](https://www.firecrawl.dev/terms-of-service) [Privacy Policy](https://www.firecrawl.dev/privacy-policy) [Report Abuse](mailto:help@firecrawl.com?subject=Issue:)

[All systems normal](https://status.firecrawl.dev/)

## Speak with Any Website
Introducing Spark 1 Pro and Spark 1 Mini models in /agent. [Try it now ‚Üí](https://www.firecrawl.dev/agent)

//

Get started

//

### Ready to build?

Start getting Web Data for free and scale seamlessly as your project expands.No credit card needed.

[Start for free](https://www.firecrawl.dev/signin) [See our plans](https://www.firecrawl.dev/pricing)

[Blog](https://www.firecrawl.dev/blog)

Using OpenAI's Realtime API and Firecrawl to Talk with Any Website

![placeholder](https://www.firecrawl.dev/_next/image?url=%2Fblog%2Fauthors%2Fnick-img.jpeg&w=48&q=75&dpl=dpl_2hQ8hmy6vNQsu8DPuBRaRM6deLpr)Nicolas Camara

Oct 11, 2024

Using OpenAI's Realtime API and Firecrawl to Talk with Any Website üî• - YouTube

[Photo image of Firecrawl](https://www.youtube.com/channel/UCO60vEm-6WAAtGckVqCi6Vg?embeds_referring_euri=https%3A%2F%2Fwww.firecrawl.dev%2F)

Firecrawl

7.29K subscribers

[Using OpenAI's Realtime API and Firecrawl to Talk with Any Website üî•](https://www.youtube.com/watch?v=3aFH12yjjcA)

Firecrawl

Search

Info

Shopping

Tap to unmute

If playback doesn't begin shortly, try restarting your device.

You're signed out

Videos you watch may be added to the TV's watch history and influence TV recommendations. To avoid this, cancel and sign in to YouTube on your computer.

CancelConfirm

Share

Include playlist

An error occurred while retrieving sharing information. Please try again later.

Watch later

Share

Copy link

Watch on

0:00

/

‚Ä¢Live

‚Ä¢

Interacting with any website through a conversational agent in real time is now possible thanks to OpenAI's new Realtime API and Firecrawl. This powerful combination allows developers to build low-latency, multi-modal conversational experiences that can fetch and interact with live web content on the fly.

In this tutorial, we'll guide you through the process of integrating Firecrawl's scraping and mapping tools into the OpenAI Realtime API Console Demo. By the end, you'll have a real-time conversational agent capable of talking with any website.

### Prerequisites

Before you begin, make sure you have the following:

- **Node.js and npm** installed on your machine.
- An **OpenAI API key** with access to the Realtime API.
- A **Firecrawl API key**.
- Basic understanding of **React** and **TypeScript**.

### Step 1: Clone the OpenAI Realtime API Console Demo

First, clone the repository that contains the OpenAI Realtime API Console Demo integrated with Firecrawl.

```
git clone https://github.com/nickscamara/firecrawl-openai-realtime.git
cd firecrawl-openai-realtime
```

### Step 2: Install Dependencies

Install the required npm packages:

```
npm install
```

### Step 3: Set Up Environment Variables

Create a `.env` file in the root directory and add your OpenAI and Firecrawl API keys:

```
OPENAI_API_KEY=your-openai-api-key
FIRECRAWL_API_KEY=your-firecrawl-api-key
```

If you're running a local relay server, set the relay server URL:

```
REACT_APP_LOCAL_RELAY_SERVER_URL=http://localhost:8081
```

### Step 4: Integrate Firecrawl Tools into the Realtime API Console Demo

Open the `ConsolePage.tsx` file located at `src/pages/ConsolePage.tsx`.

#### Import Firecrawl

At the top of the file, import the Firecrawl SDK:

```
import FirecrawlApp from "@mendable/firecrawl-js";
```

#### Add the 'scrape\_data' Tool

Within the `useEffect` hook where tools are added to the client, add the `scrape_data` tool:

```
client.addTool(
  {
    name: "scrape_data",
    description: "Goes to or scrapes data from a given URL using Firecrawl.",
    parameters: {
      type: "object",
      properties: {
        url: {
          type: "string",
          description: "URL to scrape data from",
        },
      },
      required: ["url"],
    },
  },
  async ({ url }: { url: string }) => {
    const firecrawl = new FirecrawlApp({
      apiKey: process.env.FIRECRAWL_API_KEY || "",
    });
    const data = await firecrawl.scrapeUrl(url, {
      formats: ["markdown", "screenshot"],
    });
    if (!data.success) {
      return "Failed to scrape data from the given URL.";
    }
    setScreenshot(data.screenshot || "");
    return data.markdown;
  },
);
```

This tool allows the assistant to scrape data from any URL using Firecrawl.

#### Add the 'map\_website' Tool

Next, add the `map_website` tool to enable searching for pages with specific keywords on a website:

```
client.addTool(
  {
    name: "map_website",
    description: "Searches a website for pages containing specific keywords using Firecrawl.",
    parameters: {
      type: "object",
      properties: {
        url: {
          type: "string",
          description: "URL of the website to search",
        },
        search: {
          type: "string",
          description: "Keywords to search for (2-3 max)",
        },
      },
      required: ["url", "search"],
    },
  },
  async ({ url, search }: { url: string; search: string }) => {
    const firecrawl = new FirecrawlApp({
      apiKey: process.env.FIRECRAWL_API_KEY || "",
    });
    const mapData = await firecrawl.mapUrl(url, { search });
    if (!mapData.success || !mapData.links?.length) {
      return "No pages found with the specified keywords.";
    }
    const topLink = mapData.links[0];
    const scrapeData = await firecrawl.scrapeUrl(topLink, {
      formats: ["markdown", "screenshot"],
    });
    if (!scrapeData.success) {
      return "Failed to retrieve data from the found page.";
    }
    setScreenshot(scrapeData.screenshot || "");
    return scrapeData.markdown;
  },
);
```

This tool allows the assistant to search a website for specific content and retrieve it.

#### Manage Screenshot State

At the top of your `ConsolePage` component, add state management for the screenshot:

```
const [screenshot, setScreenshot] = useState<string>("");
```

#### Display the Screenshot in the UI

In the UI, display the screenshot by adding the following within the appropriate JSX:

```
{
  screenshot && <img src={screenshot} alt="Website Screenshot" />;
}
```

### Step 5: Run the Application

In a new terminal window, start the React application:

```
npm start
```

Open your browser and navigate to `http://localhost:3000` to interact with your real-time conversational agent.

### Testing the Agent

Now, you can test your agent by initiating a conversation. For example, ask:

**User**: "Can you get the latest blog post from [https://mendable.ai](https://mendable.ai/)?"

The assistant will use the `scrape_data` tool to fetch content from the specified URL and present it to you.

### Conclusion

By integrating Firecrawl's scraping and mapping tools into the OpenAI Realtime API Console Demo, you've created a powerful conversational agent capable of interacting with any website in real time. This setup opens up endless possibilities for building advanced AI applications that can access and process live web content on demand.

### References

- [OpenAI Realtime API Documentation](https://platform.openai.com/docs/guides/realtime)
- [Firecrawl Node SDK](https://docs.firecrawl.dev/sdks/node)
- [OpenAI Realtime API Console Demo with Firecrawl](https://github.com/nickscamara/firecrawl-openai-realtime)
- [Firecrawl Official Website](https://www.firecrawl.dev/)

\[ CTA \]

\[ CRAWL \]

\[ SCRAPE \]

\[ CTA \]

//

Get started

//

Ready to build?

Start getting Web Data for free and scale seamlessly as your project expands. No credit card needed.

[Start for free](https://www.firecrawl.dev/signin) [See our plans](https://www.firecrawl.dev/pricing)

![placeholder](https://www.firecrawl.dev/_next/image?url=%2Fblog%2Fauthors%2Fnick-img.jpeg&w=128&q=75&dpl=dpl_2hQ8hmy6vNQsu8DPuBRaRM6deLpr)

Nicolas Camara [@nickscamara\_](https://x.com/nickscamara_)

CTO of Firecrawl

About the Author

Nicolas Camara is the Chief Technology Officer (CTO) at Firecrawl. He previously built and scaled Mendable, one of the pioneering "chat with your documents" apps, which had major Fortune 500 customers like Snapchat, Coinbase, and MongoDB. Prior to that, Nicolas built SideGuide, the first code-learning tool inside VS Code, and grew a community of 50,000 users. Nicolas studied Computer Science and has over 10 years of experience in building software.

More articles by Nicolas Camara

[Using OpenAI's Realtime API and Firecrawl to Talk with Any Website](https://www.firecrawl.dev/blog/How-to-Talk-with-Any-Website-Using-OpenAIs-Realtime-API-and-Firecrawl) [Extract website data using LLMs](https://www.firecrawl.dev/blog/data-extraction-using-llms) [Announcing Deep Research API](https://www.firecrawl.dev/blog/deep-research-api) [Firecrawl + Lovable - Build Web Data Apps Without Writing Code](https://www.firecrawl.dev/blog/firecrawl-lovable-integration) [Getting Started with Grok-2: Setup and Web Crawler Example](https://www.firecrawl.dev/blog/grok-2-setup-and-web-crawler-example) [Launch Week I / Day 6: LLM Extract (v1)](https://www.firecrawl.dev/blog/launch-week-i-day-6-llm-extract) [Launch Week I / Day 7: Crawl Webhooks (v1)](https://www.firecrawl.dev/blog/launch-week-i-day-7-webhooks) [OpenAI Swarm Tutorial: Create Marketing Campaigns for Any Website](https://www.firecrawl.dev/blog/openai-swarm-agent-tutorial) [Build a 'Chat with website' using Groq Llama 3](https://www.firecrawl.dev/blog/chat-with-website) [Firecrawl June 2024 Updates](https://www.firecrawl.dev/blog/firecrawl-june-2024-updates)

FOOTER

The easiest way to extract

data from the web

Backed by

Y Combinator

[Linkedin](https://www.linkedin.com/company/firecrawl) [Github](https://github.com/firecrawl/firecrawl) [YouTube](https://www.youtube.com/@Firecrawl_dev)

SOC II ¬∑ Type 2

AICPA

SOC 2

[X (Twitter)](https://x.com/firecrawl) [Discord](https://discord.gg/gSmWdAkdwd)

Products

[Playground](https://www.firecrawl.dev/playground) [Agent](https://www.firecrawl.dev/agent) [Pricing](https://www.firecrawl.dev/pricing) [Templates](https://www.firecrawl.dev/templates) [Changelog](https://www.firecrawl.dev/changelog)

Use Cases

[AI Platforms](https://www.firecrawl.dev/use-cases/ai-platforms) [Lead Enrichment](https://www.firecrawl.dev/use-cases/lead-enrichment) [SEO Teams](https://www.firecrawl.dev/use-cases/seo-teams) [Deep Research](https://www.firecrawl.dev/use-cases/deep-research) [Competitive Intelligence](https://www.firecrawl.dev/use-cases/competitive-intelligence)

Documentation

[Getting started](https://docs.firecrawl.dev/introduction) [API Reference](https://docs.firecrawl.dev/api-reference/introduction) [Integrations](https://www.firecrawl.dev/app) [Examples](https://docs.firecrawl.dev/use-cases/overview) [SDKs](https://docs.firecrawl.dev/sdks/overview)

Company

[Blog](https://www.firecrawl.dev/blog) [Careers](https://www.firecrawl.dev/careers) [Creator & OSS program](https://www.firecrawl.dev/creator-oss-program) [Student program](https://www.firecrawl.dev/student-program)

¬© 2025 Firecrawl

[Terms of Service](https://www.firecrawl.dev/terms-of-service) [Privacy Policy](https://www.firecrawl.dev/privacy-policy) [Report Abuse](mailto:help@firecrawl.com?subject=Issue:)

[All systems normal](https://status.firecrawl.dev/)

## Firecrawl Data Extraction
Introducing the Firecrawl Skill + CLI for Agents. [Learn more ‚Üí](https://docs.firecrawl.dev/sdks/cli)

//

Get started

//

### Ready to build?

Start getting Web Data for free and scale seamlessly as your project expands.No credit card needed.

[Start for free](https://www.firecrawl.dev/signin) [See our plans](https://www.firecrawl.dev/pricing)

#### Table of Contents

[Blog](https://www.firecrawl.dev/blog)

Introducing /agent: Gather Data Wherever It Lives on the Web

![placeholder](https://www.firecrawl.dev/_next/image?url=%2Fblog%2Fauthors%2Feric-img.jpeg&w=48&q=75&dpl=dpl_2hQ8hmy6vNQsu8DPuBRaRM6deLpr)Eric Ciarla

Dec 18, 2025

![Introducing /agent: Gather Data Wherever It Lives on the Web image](https://www.firecrawl.dev/_next/image?url=%2Fimages%2Fblog%2Fagent-launch%2Fagent-launch.webp&w=3840&q=75&dpl=dpl_2hQ8hmy6vNQsu8DPuBRaRM6deLpr)

Firecrawl /agent searches, navigates, and gathers even the most complex websites, finding data in hard-to-reach places and discovering information anywhere on the internet.

**It accomplishes in a few minutes what would take a human many hours**. /agent finds and extracts your data, wherever it lives on the web.

## The problem: data lives in hard-to-reach places

Building lead lists? Contact information is buried across company sites, team pages, and press releases.

Researching pricing? Competitors hide their pricing behind multi-page flows, gated content, or dynamic tables.

Curating datasets? The data you need is scattered - research papers across publishers, company information across databases, product specs across e-commerce sites.

Traditional web scraping requires you to map every site structure, write custom code for each page type, and maintain brittle scripts when layouts change. It's slow, expensive, and breaks constantly.

You need a better way to gather data at scale.

## How /agent works

Describe what data you want to extract and /agent handles the rest.

```
from firecrawl import FirecrawlApp
from pydantic import BaseModel, Field
from typing import List, Optional

app = FirecrawlApp(api_key="fc-YOUR_API_KEY")

class Company(BaseModel):
    name: str = Field(description="Company name")
    contact_email: Optional[str] = Field(None, description="Contact email")
    employee_count: Optional[str] = Field(None, description="Number of employees")

class CompaniesSchema(BaseModel):
    companies: List[Company] = Field(description="List of companies")

result = app.agent(
    prompt="Find YC W24 dev tool companies and get their contact info and team size",
    schema=CompaniesSchema
)

print(result.data)
```

No URLs required. No site mapping. No custom scripts. Agent figures out how to navigate sites, click through pages, handle dynamic content, and extract exactly what you need.

Want to provide starting points? URLs are optional:

```
result = app.agent(
    urls=["https://stripe.com/pricing", "https://square.com/pricing"],
    prompt="Compare pricing tiers and features"
)
```

Agent searches the web, navigates complex sites, clicks through multi-page flows, handles pagination, and returns structured data. Whether you need one data point or thousands, it scales.

### Research preview: expect improvements

We're launching /agent in research preview. This means:

- Expect kinks and edge cases
- Performance will improve significantly over time
- We're actively gathering feedback and iterating

Think of this as the early version of something that will get much better. We're committed to making /agent **the best way to extract web data at scale**.

## What /agent can do

**Find information in hard-to-reach places**: Agent clicks through authentication flows, navigates nested menus, handles dropdowns, and explores multi-step processes to find your data.

**Discover information across the web**: Searches for companies, people, products, or research. Visits multiple sites, cross-references data, and structures everything into clean JSON.

**Scale from one to thousands**: Extract a single contact email or curate entire datasets of companies, research papers, or products. Agent adapts.

**Navigate like a human**: Clicks buttons, follows links, handles pagination, explores sub-pages. Interacts with sites the way a person would, but faster.

## Real-world use cases

**Lead generation and company research**

"Find all YC W24 dev tool companies, their founders, contact emails, and employee count"

Agent searches for YC W24 companies, filters for dev tools, visits each company site, finds founder and contact information, checks team pages for headcount. Returns structured data ready for your CRM.

**Competitive pricing intelligence**

"Compare pricing tiers and features across Stripe, Square, and PayPal"

Agent visits each pricing page, navigates through tier details, extracts features and costs, handles different page layouts. Returns unified pricing comparison.

**Product research and e-commerce**

"Get all running shoes from Nike.com under $150 with customer ratings"

Agent navigates Nike's catalog, filters by category and price, clicks into product pages, extracts specs and ratings, handles pagination across hundreds of products.

**Dataset curation**

"Find the top 50 AI research papers from 2024 with author names, institutions, and citation counts"

Agent searches academic databases, visits publisher sites, extracts paper metadata, cross-references citation counts, structures everything for analysis.

**Complex browser interactions**

"Extract pricing from SaaS sites that require clicking 'See Pricing' buttons"

Agent handles JavaScript-heavy sites, clicks through multi-step flows, waits for dynamic content to load, navigates modal windows and forms.

## The end of brittle scraping scripts

Traditional web scraping means:

- Mapping site structures manually
- Writing custom selectors for each page
- Maintaining brittle scripts when sites change
- Building separate workflows for each data source

Agent replaces all of that with a prompt. It figures out navigation, handles changes automatically, and works across any site without custom code.

What takes a human hours - finding data sources, clicking through pages, copying information, structuring it - Agent does in minutes.

## /agent vs /extract

The /agent endpoint is the next evolution of our /extract endpoint. It uses AI agents to intelligently gather and structure data from across the web. Unlike /extract, Agent requires only a prompt and URLs are optional, making it incredibly flexible for a wide variety of use cases.

**What's different:**

| Feature | Agent | Extract |
| --- | --- | --- |
| URLs Required | Optional | Required |
| Web Search | Built-in | None |
| Navigation | Autonomous | Single page |
| Browser Actions | Full support | Limited |
| Scale | One to thousands | Single page |
| Status | Active development | Deprecated |

If you're using /extract, migration is straightforward - convert your extraction logic into a natural language prompt. Agent handles everything /extract did, plus autonomous discovery and navigation. A detailed migration guide will be available soon.

Try it, break it, let us know what doesn't work. Every edge case you find helps us improve.

## Available now

Agent is live across all our integrations:

- **API** ‚Äì Full control in your applications
- **SDKs** ‚Äì Python and Node with Pydantic/Zod schemas
- **Playground** ‚Äì [Try it immediately](https://www.firecrawl.dev/app/agent)

### Coming soon

- **MCP** ‚Äì Work with Claude, Gemini, OpenAI agents
- **n8n** ‚Äì Add Agent to workflow automations
- **Zapier** ‚Äì Integrate with thousands of apps

## Start building

1. Read the [/agent documentation](https://docs.firecrawl.dev/features/agent)
2. Experiment in the [Playground](https://www.firecrawl.dev/app/agent)
3. Share your projects on [Discord](https://discord.com/invite/gSmWdAkdwd)

Gather data wherever it lives on the web. Start building today.

\[ CTA \]

\[ CRAWL \]

\[ SCRAPE \]

\[ CTA \]

//

Get started

//

Ready to build?

Start getting Web Data for free and scale seamlessly as your project expands. No credit card needed.

[Start for free](https://www.firecrawl.dev/signin) [See our plans](https://www.firecrawl.dev/pricing)

![placeholder](https://www.firecrawl.dev/_next/image?url=%2Fblog%2Fauthors%2Feric-img.jpeg&w=128&q=75&dpl=dpl_2hQ8hmy6vNQsu8DPuBRaRM6deLpr)

Eric Ciarla [@ericciarla](https://x.com/ericciarla)

CMO of Firecrawl

About the Author

Eric Ciarla is the cofounder and Chief Marketing Officer (CMO) of Firecrawl. He also worked on Mendable.ai and sold it to companies like Snapchat, Coinbase, and MongoDB. Previously worked at Ford and Fracta as a Data Scientist. Eric also co-founded SideGuide, a tool for learning code within VS Code with 50,000 users.

More articles by Eric Ciarla

[Extract Web Data at Scale With Parallel Agents](https://www.firecrawl.dev/blog/introducing-parallel-agents) [Introducing the Firecrawl Skill and CLI - Give Agents Real-Time Web Data](https://www.firecrawl.dev/blog/introducing-firecrawl-skill-and-cli) [How Credal Extracts 6M+ URLs Monthly to Power Production AI Agents](https://www.firecrawl.dev/blog/credal-firecrawl-ai-agents) [How to Create an llms.txt File for Any Website](https://www.firecrawl.dev/blog/How-to-Create-an-llms-txt-File-for-Any-Website) [Introducing Spark 1 Pro and Spark 1 Mini](https://www.firecrawl.dev/blog/introducing-spark-1) [Introducing /agent: Gather Data Wherever It Lives on the Web](https://www.firecrawl.dev/blog/introducing-agent) [Retell‚Äôs AI phone agents get LLM-ready content from Firecrawl](https://www.firecrawl.dev/blog/retell-firecrawl-ai-phone-agents) [Introducing Firecrawl v2.5 - The World's Best Web Data API](https://www.firecrawl.dev/blog/the-worlds-best-web-data-api-v25) [Why Firecrawl Beats Octoparse for AI Web Scraping](https://www.firecrawl.dev/blog/firecrawl-vs-octoparse-data-extraction) [Introducing Firecrawl Observer, Our Open-Source Website Monitoring Tool](https://www.firecrawl.dev/blog/introducing-firecrawl-observer)

FOOTER

The easiest way to extract

data from the web

Backed by

Y Combinator

[Linkedin](https://www.linkedin.com/company/firecrawl) [Github](https://github.com/firecrawl/firecrawl) [YouTube](https://www.youtube.com/@Firecrawl_dev)

SOC II ¬∑ Type 2

AICPA

SOC 2

[X (Twitter)](https://x.com/firecrawl) [Discord](https://discord.gg/gSmWdAkdwd)

Products

[Playground](https://www.firecrawl.dev/playground) [Agent](https://www.firecrawl.dev/agent) [Pricing](https://www.firecrawl.dev/pricing) [Templates](https://www.firecrawl.dev/templates) [Changelog](https://www.firecrawl.dev/changelog)

Use Cases

[AI Platforms](https://www.firecrawl.dev/use-cases/ai-platforms) [Lead Enrichment](https://www.firecrawl.dev/use-cases/lead-enrichment) [SEO Teams](https://www.firecrawl.dev/use-cases/seo-teams) [Deep Research](https://www.firecrawl.dev/use-cases/deep-research) [Competitive Intelligence](https://www.firecrawl.dev/use-cases/competitive-intelligence)

Documentation

[Getting started](https://docs.firecrawl.dev/introduction) [API Reference](https://docs.firecrawl.dev/api-reference/introduction) [Integrations](https://www.firecrawl.dev/app) [Examples](https://docs.firecrawl.dev/use-cases/overview) [SDKs](https://docs.firecrawl.dev/sdks/overview)

Company

[Blog](https://www.firecrawl.dev/blog) [Careers](https://www.firecrawl.dev/careers) [Creator & OSS program](https://www.firecrawl.dev/creator-oss-program) [Student program](https://www.firecrawl.dev/student-program)

¬© 2025 Firecrawl

[Terms of Service](https://www.firecrawl.dev/terms-of-service) [Privacy Policy](https://www.firecrawl.dev/privacy-policy) [Report Abuse](mailto:help@firecrawl.com?subject=Issue:)

[All systems normal](https://status.firecrawl.dev/)

## Understanding 520 Status Code
Introducing Spark 1 Pro and Spark 1 Mini models in /agent. [Try it now ‚Üí](https://www.firecrawl.dev/agent)

//

Get started

//

### Ready to build?

Start getting Web Data for free and scale seamlessly as your project expands. No credit card needed.

[Start for free](https://www.firecrawl.dev/signin) [See our plans](https://www.firecrawl.dev/pricing)

#### All Questions

[Glossary](https://www.firecrawl.dev/glossary)/ [Web Scraping APIs](https://www.firecrawl.dev/glossary/web-scraping-apis)/Questions

[What is a 429 error in web scraping?](https://www.firecrawl.dev/glossary/web-scraping-apis/what-is-429-error-web-scraping)

[What is a CSS selector in web scraping?](https://www.firecrawl.dev/glossary/web-scraping-apis/what-is-css-selector-web-scraping)

# What is a 520 status code and how to avoid it?

## TL;DR

A 520 error means Cloudflare couldn't get a valid response from the origin server. It's Cloudflare-specific, not a standard HTTP code. Avoid it by using proper request headers, respecting rate limits, and implementing retry logic. Or use Firecrawl‚Äîit handles Cloudflare and anti-bot protection automatically.

## What is a 520 status code and how to avoid it?

A 520 error is Cloudflare-specific, meaning "Unknown Error" or "Web Server Returned an Unknown Error." It occurs when Cloudflare successfully connects to the origin server but receives an unexpected or empty response. This happens when servers are overloaded, misconfigured, or when they detect and block suspicious requests. It's not a standard HTTP status code‚Äîonly appears with Cloudflare-protected sites.

## Why 520 errors occur

Origin servers return invalid responses when overloaded by requests, detect bot-like behavior, have misconfigurations blocking Cloudflare IPs, crash or timeout under load, or return empty responses to suspicious traffic.

For scrapers, 520s often indicate your requests look automated‚Äîmissing headers, unusual patterns, or too many requests too quickly. The server tells Cloudflare "something's wrong" without specifying what.

## How to avoid 520 errors

Use complete, realistic request headers including User-Agent, Accept, and Accept-Language. Respect rate limits‚Äîspace requests like a human (few seconds between requests). Implement retry logic with exponential backoff‚Äîtemporary overload often resolves quickly.

Use residential proxies instead of datacenter IPs‚Äîthey're less likely to trigger anti-bot systems. Rotate user agents and headers to avoid fingerprinting. Monitor for patterns‚Äîif 520s spike, you're likely triggering protection.

## The simple solution

Firecrawl handles Cloudflare and complex web infrastructure automatically. It manages proper headers, rate limiting, proxy rotation, and retry logic‚Äîno 520 errors to debug. Built-in request handling means you get clean data instead of error codes.

This is why modern scraping uses APIs. Spending days debugging 520 errors and Cloudflare protection wastes time. Firecrawl solves it automatically‚Äîfocus on using data, not fighting anti-bot systems.

## Key Takeaways

520 errors are Cloudflare-specific, indicating the origin server returned an invalid response. Often triggered by bot detection‚Äîmissing headers, aggressive rate limiting, or suspicious patterns. Avoid by using proper headers, respecting rate limits, and implementing retries. Or use Firecrawl‚Äîit handles Cloudflare protection automatically, eliminating 520 errors and other anti-bot challenges so you can focus on extracting data.

Last updated: Jan 26, 2026

\[ CTA \]

\[ CRAWL \]

\[ SCRAPE \]

\[ CTA \]

//

Get started

//

Ready to build?

Start getting Web Data for free and scale seamlessly as your project expands. No credit card needed.

[Start for free](https://www.firecrawl.dev/signin) [See our plans](https://www.firecrawl.dev/pricing)

FOOTER

The easiest way to extract

data from the web

Backed by

Y Combinator

[Linkedin](https://www.linkedin.com/company/firecrawl) [Github](https://github.com/firecrawl/firecrawl) [YouTube](https://www.youtube.com/@Firecrawl_dev)

SOC II ¬∑ Type 2

AICPA

SOC 2

[X (Twitter)](https://x.com/firecrawl) [Discord](https://discord.gg/gSmWdAkdwd)

Products

[Playground](https://www.firecrawl.dev/playground) [Agent](https://www.firecrawl.dev/agent) [Pricing](https://www.firecrawl.dev/pricing) [Templates](https://www.firecrawl.dev/templates) [Changelog](https://www.firecrawl.dev/changelog)

Use Cases

[AI Platforms](https://www.firecrawl.dev/use-cases/ai-platforms) [Lead Enrichment](https://www.firecrawl.dev/use-cases/lead-enrichment) [SEO Teams](https://www.firecrawl.dev/use-cases/seo-teams) [Deep Research](https://www.firecrawl.dev/use-cases/deep-research) [Competitive Intelligence](https://www.firecrawl.dev/use-cases/competitive-intelligence)

Documentation

[Getting started](https://docs.firecrawl.dev/introduction) [API Reference](https://docs.firecrawl.dev/api-reference/introduction) [Integrations](https://www.firecrawl.dev/app) [Examples](https://docs.firecrawl.dev/use-cases/overview) [SDKs](https://docs.firecrawl.dev/sdks/overview)

Company

[Blog](https://www.firecrawl.dev/blog) [Careers](https://www.firecrawl.dev/careers) [Creator & OSS program](https://www.firecrawl.dev/creator-oss-program) [Student program](https://www.firecrawl.dev/student-program)

¬© 2025 Firecrawl

[Terms of Service](https://www.firecrawl.dev/terms-of-service) [Privacy Policy](https://www.firecrawl.dev/privacy-policy) [Report Abuse](mailto:help@firecrawl.com?subject=Issue:)

[All systems normal](https://status.firecrawl.dev/)

## Firecrawl vs Octoparse
Introducing the Firecrawl Skill + CLI for Agents. [Learn more ‚Üí](https://docs.firecrawl.dev/sdks/cli)

//

Get started

//

### Ready to build?

Start getting Web Data for free and scale seamlessly as your project expands. No credit card needed.

[Start for free](https://www.firecrawl.dev/signin) [See our plans](https://www.firecrawl.dev/pricing)

#### Table of Contents

[Blog](https://www.firecrawl.dev/blog)

Why Firecrawl Beats Octoparse for AI Web Scraping

![placeholder](https://www.firecrawl.dev/_next/image?url=%2Fblog%2Fauthors%2Feric-img.jpeg&w=48&q=75&dpl=dpl_2hQ8hmy6vNQsu8DPuBRaRM6deLpr)Eric Ciarla

Aug 23, 2025

![Why Firecrawl Beats Octoparse for AI Web Scraping image](https://www.firecrawl.dev/_next/image?url=%2Fimages%2Fblog%2Ffirecrawl-vs-octoparse-data-extraction%2Ffirecrawl-vs-octoparse-data-extraction.webp&w=3840&q=75&dpl=dpl_2hQ8hmy6vNQsu8DPuBRaRM6deLpr)

# Firecrawl vs Octoparse: Web Scraping for AI Applications

AI developers need reliable web scraping tools that can handle modern websites and deliver clean, structured data ready for machine learning workflows. While traditional GUI-based scrapers like Octoparse served basic data collection needs, they struggle with the dynamic content, scale, and developer integration requirements that AI applications demand.

When comparing Octoparse to Firecrawl, **Firecrawl emerges as the superior choice** for AI practitioners who need reliable, developer-friendly web scraping in one powerful platform. Unlike Octoparse's manual GUI-based approach, Firecrawl's Fire Engine handles advanced web scraping through simple API calls, automatically processing dynamic content and delivering structured JSON and markdown outputs that are immediately ready for AI training and analysis.

Built specifically for the AI era, Firecrawl combines intelligent web scraping with automatic data formatting, offers transparent open-source development, and provides enterprise-grade reliability that traditional GUI scrapers simply cannot match. For developers building LLM-powered applications, Firecrawl eliminates the complexity of managing scraping infrastructure while delivering superior results at scale.

We'll explore why Firecrawl consistently outperforms Octoparse for AI web scraping across different metrics.

* * *

## Comprehensive Platform Comparison: Firecrawl vs Octoparse

### Firecrawl: The Developer-First AI Data Platform

**Firecrawl stands alone** as the only platform designed specifically for AI practitioners who need both web scraping and data cleaning in one solution, while Octoparse forces you into GUI workflows and doesn't clean your data.

**Key Technical Advantages:**

- **Fire Engine Performance:** Proprietary crawling technology that outperforms Octoparse by 300% on dynamic content
- **FIRE-1 AI Integration:** Purpose-built for LLM training data with automatic schema detection and intelligent content extraction
- **Reliable Infrastructure:** Advanced proxy rotation and smart wait capabilities that handle complex sites Octoparse struggles with
- **Native LLM Output Formats:** Direct JSON and markdown generation optimized for AI training pipelines

**Enterprise Features:**

- Open-source transparency with [49,000+ GitHub stars](https://github.com/firecrawl/firecrawl)
- Real-time dynamic content handling
- Comprehensive compliance and security features
- Scalable architecture supporting millions of pages

### Octoparse: GUI-Based Scraping Without AI Intelligence

Octoparse is an easy-to-use web scraping tool developed to accommodate complicated web scraping for non-coders and has grown to serve over 4.5 million users worldwide. However, **Octoparse fundamentally lacks the AI-native features** that modern machine learning workflows require.

**Critical Octoparse Limitations for AI Use Cases:**

- **No AI-Optimized Outputs:** Produces basic CSV/JSON without LLM training optimizations
- **GUI-Only Workflow:** Requires visual interface setup, impossible to integrate into automated AI pipelines
- **Limited Dynamic Content:** Octoparse is able to extract AJAX-supplied data and set timeouts but lacks intelligent wait strategies.
- **Manual Configuration:** Each scraping task requires point-and-click setup, preventing scalable automation.
- **No Schema Intelligence:** Cannot automatically detect and structure web content for AI training
- **Maintenance Overhead:** Each website change requires manual workflow updates
- **Limited Integration:** Desktop application doesn't fit modern cloud-based AI development workflows

## Detailed Feature Comparison: Firecrawl vs Octoparse

| Feature | Firecrawl | Octoparse |
| --- | --- | --- |
| **Web Scraping** | ‚úÖ Advanced Fire Engine | ‚ö†Ô∏è Basic GUI Tool |
| **Dynamic Content** | ‚úÖ Smart Wait + JS Rendering | ‚ö†Ô∏è Basic AJAX Support |
| **LLM-Ready Outputs** | ‚úÖ JSON + Markdown | ‚ö†Ô∏è Basic CSV/JSON |
| **Developer APIs** | ‚úÖ Python, Node.js, REST | ‚ùå Desktop App Only |
| **Real-Time Processing** | ‚úÖ Live Crawling | ‚ö†Ô∏è Scheduled Tasks |
| **Anti-Bot Evasion** | ‚úÖ Advanced Proxy Rotation | ‚ö†Ô∏è Basic Proxy Support |
| **Open Source** | ‚úÖ Transparent Development | ‚ùå Proprietary |
| **Enterprise Scale** | ‚úÖ Millions of Pages | ‚ö†Ô∏è Limited Scale |
| **AI Training Integration** | ‚úÖ Purpose-Built | ‚ùå None |
| **Automated Workflows** | ‚úÖ Full API Control | ‚ùå Manual GUI |

* * *

## Why Octoparse Specifically Falls Short for AI Developers

### The GUI Limitation Problem

Octoparse uses a freemium model, with a free tier and several paid plans, but fundamentally operates through a desktop GUI interface. This **creates barriers for modern AI development workflows**.

### Technical Architecture Limitations

**Octoparse's Point-and-Click Approach:**

- It automatically "guesses" the desired data fields for users, which saves a large amount of time and energy but cannot adapt to changing website structures automatically
- Requires manual reconfiguration when websites update their layouts
- Cannot handle complex conditional logic needed for AI data preparation
- Limited to predefined extraction patterns rather than intelligent content recognition

Compare this to **Firecrawl's AI-Native Approach:**

- FIRE-1 AI automatically adapts to website changes
- Intelligent content extraction that understands semantic meaning
- API-driven workflows that integrate seamlessly with AI development tools
- Real-time adaptation to dynamic content without manual intervention

### Cost and Scalability Analysis

**Octoparse Pricing Reality:**

- Standard Edition: $75 per month when billed annually, or $89 per month when billed monthly
- Professional Edition: $158 per month when billed annually, or $189 per month when billed monthly
- Limited concurrent tasks and data extraction quotas
- Additional costs for cloud processing and advanced features

**Hidden Costs of Octoparse for AI Teams:**

- **Developer Time:** Hours spent on manual task creation and maintenance
- **Maintenance Overhead:** Constant updates needed when websites change
- **Integration Complexity:** Additional tools needed to bridge Octoparse output with AI pipelines
- **Scale Limitations:** Cannot handle enterprise-level AI training data requirements

**Firecrawl's Transparent Value:**

- **Predictable API Pricing:** Pay per successful extraction with clear quotas
- **Zero Setup Time:** Immediate integration with existing AI development workflows
- **Automatic Adaptation:** No maintenance required when websites change
- **Enterprise Ready:** Unlimited scale with consistent performance

* * *

## Technical Deep Dive: Why Firecrawl's Architecture Dominates

### Fire Engine: Revolutionary Web Scraping Technology

Firecrawl's **Fire Engine represents a fundamental breakthrough** in web scraping architecture, specifically designed for the complex requirements of AI data preparation. Unlike Octoparse's traditional approach, Fire Engine uses advanced AI to understand and extract content intelligently.

**Advanced Capabilities**

- **Intelligent Content Detection:** FIRE-1 AI automatically identifies and extracts relevant content while filtering noise
- **Dynamic Wait Strategies:** Smart timing that adapts to page loading patterns beyond Octoparse's basic timeout
- **Comprehensive Action Support:** Screenshots, clicks, form submissions, and custom JavaScript execution
- **Automatic Schema Generation:** Converts unstructured web content into structured formats for AI training

### Smart Anti-Bot Technology

Octoparse struggles with modern anti-bot protection. It requires user intervention for CAPTCHA challenges and a manual proxy setup without automatic rotation.

**Firecrawl's Advanced Anti-Bot Features:**

- **Rotating Proxy Networks:** Prevents IP blocking across global infrastructure
- **Browser Fingerprint Randomization:** Mimics real user behavior patterns
- **CAPTCHA Handling:** Automatic detection and solving capabilities
- **Rate Limit Intelligence:** Adaptive timing to respect server limitations

### JavaScript and Dynamic Content Handling

The vast majority of modern websites use JavaScript to load content dynamically, create interactive features, and improve user experience. Traditional scrapers often fail on these sites because they can't execute JavaScript or wait for dynamic content to fully load.

**Firecrawl's JavaScript Superiority:**
Firecrawl excels at handling JavaScript-heavy websites through its intelligent rendering engine. JavaScript-heavy pages have 37% fewer failures with Firecrawl compared to other methods, maintaining 99%+ data integrity. It can also handle infinite scrolling on a dynamic website.

**Octoparse's JavaScript Limitations:**
While Octoparse claims to handle "Ajax and JavaScript" websites, it requires manual configuration for each dynamic element. Users must manually "tick 'Load with AJAX' to select the timeout" and ensure the AJAX timeout is long enough for the page to load. This process has to be repeated for every website change.

### LLM-Optimized Output Generation

Firecrawl **uniquely understands AI training requirements**, generating outputs specifically optimized for machine learning workflows, unlike Octoparse's basic CSV exports.

**Structured JSON for Training:**

```
{
  "content": "Clean, relevant text content",
  "metadata": {
    "title": "Extracted page title",
    "description": "Meta description",
    "keywords": ["relevant", "terms"],
    "publishDate": "2025-01-15",
    "author": "Author name"
  },
  "structure": {
    "headings": ["H1", "H2", "H3"],
    "links": [{ "text": "Link text", "url": "target" }],
    "images": [{ "alt": "Description", "src": "url" }]
  }
}
```

By using Markdown, Firecrawl's outputs are optimized for AI training pipelines, providing:

- Clean, standardized formatting optimized for token efficiency
- Preserved semantic structure for better AI understanding
- Ready for RAG applications without additional processing
- Consistent output regardless of source website complexity

### Real-Time Web Monitoring for AI Applications

AI applications need fresh web data for market analysis, sentiment tracking, and competitive intelligence.

**Firecrawl's Advantage:**

- **Live Crawling:** Real-time data extraction without Octoparse's batch processing delays
- **Change Detection:** Monitor websites for updates and new content automatically
- **Scalable Architecture:** Handle thousands of concurrent crawling operations vs Octoparse's limited concurrent tasks
- **Reliable Delivery:** Enterprise-grade uptime and error handling

Octoparse offers scheduled task capabilities but requires manual desktop application management and individual GUI configuration for each monitoring target, making it impractical for dynamic AI applications that need continuous data streams.

### Ease of Setup for AI Developers

**Installation and Configuration**

With Firecrawl, you can get started in minutes.

```
# Python installation
pip install firecrawl-py

# Node.js installation
npm install @mendable/firecrawl-js

```

Compare this easy setup to Octoparse, where you have to download the desktop app, create an account, and do lots of manual setup.

**Basic Integration**

Firecrawl has direct API integrations with existing workflows.

```
from firecrawl import FirecrawlApp

# Initialize with your API key
app = FirecrawlApp(api_key="fc-your_api_key")

# Start with a simple scrape
result = app.scrape_url("https://example.com", {
    "formats": ["markdown", "json"]
})

print(result['markdown'])  # Clean content ready for AI
```

Octoparse's setup isn't as developer-friendly.
It requires you to open the GUI, create a task, and do a point-and-click setup.
To use the data, you have to export a CSV, write separate processing code, and then do manual maintenance to keep it up to date.

* * *

## Conclusion: Firecrawl Delivers Unmatched AI Web Scraping

Compared to Octoparse, **Firecrawl stands as the winner** for developers and AI practitioners who demand reliability, performance, and integration simplicity.

**Why Firecrawl Dominates:**

- **Integrated Architecture:** Only platform combining advanced web scraping with intelligent data cleaning in one API
- **AI-Native Design:** Purpose-built for LLM training data and modern AI workflows, not retrofitted from legacy tools
- **Superior Performance:** Fire Engine technology delivers 3x faster processing with 99%+ success rates vs competitors
- **Developer Experience:** API-first design with seamless Python, Node.js, and framework integration vs manual GUI workflows
- **Open Source Trust:** Transparent development with 49,000+ GitHub stars and active community vs proprietary black boxes
- **Enterprise Ready:** Scalable, secure, and reliable for production AI applications without desktop application limitations

**Octoparse** requires manual GUI workflows and lacks AI-optimized outputs for modern machine learning pipelines. You get scraping, but no cleaning, data formatting, or schema detection.

**Your Next Steps:**

1. **Start Free:** Sign up for Firecrawl's free tier at [firecrawl.dev](https://firecrawl.dev/)
2. **Test Your Use Case:** Try the 500 free credits on your specific data sources and compare with Octoparse workflows
3. **Integrate Seamlessly:** Use the comprehensive API documentation for immediate implementation in your AI pipeline
4. **Scale Confidently:** Upgrade to paid plans as your AI data requirements grow beyond what GUI tools can handle

For AI practitioners who need reliable, high-quality web data extraction and cleaning, Firecrawl isn't just the best choice‚Äîit's the only platform built specifically for your success. **Stop managing complex tool chains with manual GUI applications and start building better AI applications with clean, structured data from day one.**

The future of AI development demands intelligent, automated data preparation. Choose the platform that was built for that future.

[**Get Started with Firecrawl Today ‚Üí**](https://firecrawl.dev/)

* * *

## Frequently Asked Questions

### Is Firecrawl better than Octoparse for AI projects?

Yes, Firecrawl is specifically designed for AI workflows while Octoparse is a general-purpose GUI scraper. Firecrawl provides API-driven automation, AI-optimized outputs, and intelligent content extraction that Octoparse cannot match. For AI developers, Firecrawl eliminates the manual task creation and CSV processing overhead that Octoparse requires.

### Can Firecrawl handle the same websites as Octoparse?

Firecrawl handles many complex websites through its Fire Engine technology and stealth mode capabilities. While both tools can scrape dynamic websites, Firecrawl's AI-driven approach often adapts automatically to website changes without manual reconfiguration, unlike Octoparse's point-and-click setup requirements.

### Is Firecrawl more cost-effective than Octoparse?

Firecrawl's pricing starts at $16/month for 3,000 credits, while Octoparse's Standard Edition costs $75/month when billed annually. When considering total cost of ownership, Firecrawl often provides better value by eliminating developer time spent on manual task creation, maintenance, and additional data processing tools.

### How does Firecrawl handle anti-bot protection compared to Octoparse?

Firecrawl uses optimized request infrastructure and proxy management for reliable data collection, while Octoparse relies on basic proxy support. Firecrawl's infrastructure handles complex websites more effectively.

### What AI frameworks does Firecrawl integrate with?

Firecrawl provides official integration with LangChain and supports popular Python ML frameworks through its structured JSON and markdown outputs. The API-first design allows integration with frameworks like Llama Index, CrewAI, and other AI development environments.

* * *

\[ CTA \]

\[ CRAWL \]

\[ SCRAPE \]

\[ CTA \]

//

Get started

//

Ready to build?

Start getting Web Data for free and scale seamlessly as your project expands. No credit card needed.

[Start for free](https://www.firecrawl.dev/signin) [See our plans](https://www.firecrawl.dev/pricing)

![placeholder](https://www.firecrawl.dev/_next/image?url=%2Fblog%2Fauthors%2Feric-img.jpeg&w=128&q=75&dpl=dpl_2hQ8hmy6vNQsu8DPuBRaRM6deLpr)

Eric Ciarla [@ericciarla](https://x.com/ericciarla)

CMO of Firecrawl

About the Author

Eric Ciarla is the cofounder and Chief Marketing Officer (CMO) of Firecrawl. He also worked on Mendable.ai and sold it to companies like Snapchat, Coinbase, and MongoDB. Previously worked at Ford and Fracta as a Data Scientist. Eric also co-founded SideGuide, a tool for learning code within VS Code with 50,000 users.

More articles by Eric Ciarla

[Extract Web Data at Scale With Parallel Agents](https://www.firecrawl.dev/blog/introducing-parallel-agents) [Introducing the Firecrawl Skill and CLI - Give Agents Real-Time Web Data](https://www.firecrawl.dev/blog/introducing-firecrawl-skill-and-cli) [How Credal Extracts 6M+ URLs Monthly to Power Production AI Agents](https://www.firecrawl.dev/blog/credal-firecrawl-ai-agents) [How to Create an llms.txt File for Any Website](https://www.firecrawl.dev/blog/How-to-Create-an-llms-txt-File-for-Any-Website) [Introducing Spark 1 Pro and Spark 1 Mini](https://www.firecrawl.dev/blog/introducing-spark-1) [Introducing /agent: Gather Data Wherever It Lives on the Web](https://www.firecrawl.dev/blog/introducing-agent) [Retell‚Äôs AI phone agents get LLM-ready content from Firecrawl](https://www.firecrawl.dev/blog/retell-firecrawl-ai-phone-agents) [Introducing Firecrawl v2.5 - The World's Best Web Data API](https://www.firecrawl.dev/blog/the-worlds-best-web-data-api-v25) [Why Firecrawl Beats Octoparse for AI Web Scraping](https://www.firecrawl.dev/blog/firecrawl-vs-octoparse-data-extraction) [Introducing Firecrawl Observer, Our Open-Source Website Monitoring Tool](https://www.firecrawl.dev/blog/introducing-firecrawl-observer)

FOOTER

The easiest way to extract

data from the web

Backed by

Y Combinator

[Linkedin](https://www.linkedin.com/company/firecrawl) [Github](https://github.com/firecrawl/firecrawl) [YouTube](https://www.youtube.com/@Firecrawl_dev)

SOC II ¬∑ Type 2

AICPA

SOC 2

[X (Twitter)](https://x.com/firecrawl) [Discord](https://discord.gg/gSmWdAkdwd)

Products

[Playground](https://www.firecrawl.dev/playground) [Agent](https://www.firecrawl.dev/agent) [Pricing](https://www.firecrawl.dev/pricing) [Templates](https://www.firecrawl.dev/templates) [Changelog](https://www.firecrawl.dev/changelog)

Use Cases

[AI Platforms](https://www.firecrawl.dev/use-cases/ai-platforms) [Lead Enrichment](https://www.firecrawl.dev/use-cases/lead-enrichment) [SEO Teams](https://www.firecrawl.dev/use-cases/seo-teams) [Deep Research](https://www.firecrawl.dev/use-cases/deep-research) [Competitive Intelligence](https://www.firecrawl.dev/use-cases/competitive-intelligence)

Documentation

[Getting started](https://docs.firecrawl.dev/introduction) [API Reference](https://docs.firecrawl.dev/api-reference/introduction) [Integrations](https://www.firecrawl.dev/app) [Examples](https://docs.firecrawl.dev/use-cases/overview) [SDKs](https://docs.firecrawl.dev/sdks/overview)

Company

[Blog](https://www.firecrawl.dev/blog) [Careers](https://www.firecrawl.dev/careers) [Creator & OSS program](https://www.firecrawl.dev/creator-oss-program) [Student program](https://www.firecrawl.dev/student-program)

¬© 2025 Firecrawl

[Terms of Service](https://www.firecrawl.dev/terms-of-service) [Privacy Policy](https://www.firecrawl.dev/privacy-policy) [Report Abuse](mailto:help@firecrawl.com?subject=Issue:)

[All systems normal](https://status.firecrawl.dev/)

## Flexible Pricing Plans
Introducing Parallel Agents - Run multiple /agent queries simultaneously. [Read more ‚Üí](https://www.firecrawl.dev/blog/introducing-parallel-agents)

//

Transparent

//

## Flexible pricing

Explore transparent pricing built for real-world scraping.  Start for free, then scale as you grow.

üá≥üá¥NOK

Free Plan

A lightweight way to try scraping.

No cost, no card, no hassle.

500 credits (one-time)

kr0123456789

one-time

Get started

Scrape 500 pages

2 concurrent requests

Low rate limits

Hobby

Great for side projects and small tools.

Fast, simple, no overkill.

3,000 credits / month

kr012345678901234567890123456789

/monthly

Billed yearly

2 months free

Subscribe

Scrape 3,000 pages

5 concurrent requests

Basic support

kr87 per extra 1k credits

Standard

Most popular

Perfect for scaling with less effort.

Simple, solid, dependable.

100,000 credits / month

kr012345678901234567890123456789

/monthly

Billed yearly

2 months free

Subscribe

Scrape 100,000 pages

50 concurrent requests

Standard support

kr454 per extra 35k credits

Growth

Built for high volume and speed.

Firecrawl at full force.

500,000 credits / month

kr012345678901234567890123456789.0123456789k

/monthly

Billed yearly

2 months free

Subscribe

Scrape 500,000 pages

100 concurrent requests

Priority support

kr1,711 per extra 175k credits

Extra credits are available via auto-recharge packs. [Enable](https://www.firecrawl.dev/signin?view=signup)

Actual price may vary based on the exchange rate in place between USD and NOK at the time of payment processing or invoicing. Prices exclude all taxes, levies and duties and are paid in USD.

## Scale Plans

High-volume plans for teams that need more power and dedicated support. Get access to higher rate limits, more concurrent browsers, and priority support.

[Need more? Contact us](https://fk4bvu0n5qp.typeform.com/to/Ej6oydlg)

Scale

For teams scaling their data pipelines

1,000,000 credits

kr5,790per month

Billed yearly

2 months free

Subscribe

Scrape 1,000,000 pages

150 concurrent requests

Priority support

Enterprise

Power at your pace with custom solutions

Custom credits

Custom

[Get Started](https://fk4bvu0n5qp.typeform.com/to/Ej6oydlg)

Scrape unlimited pages

Custom concurrent requests

Dedicated support & SLA

Bulk discounts

Zero-data retention

SSO & advanced security

API Credits

Credits are consumed for each API request, varying by endpoint and feature.

Features

Credits

Scrape

1 / page

Crawl

1 / page

Map

1/ page

Search

2/ 10 results

Agent (Preview)

5 daily runs free.

Dynamic pricing

\[ 02 / 03 \]

¬∑

TESTIMONIALS

//

Community

//

## People love    building with Firecrawl

Discover why developers choose Firecrawl every day.

[![Morgan Linton](https://www.firecrawl.dev/assets-original/testimonials/morgan-linton.png)Morgan Linton@morganlinton"If you're coding with AI, and haven't discovered @firecrawl yet, prepare to have your mind blown ü§Ø"](https://x.com/morganlinton/status/1839454165703204955) [![Chris DeWeese](https://www.firecrawl.dev/assets-original/testimonials/chris-deweese.png)Chris DeWeese@chrisdeweese\_"Started using @firecrawl for a project, I wish I used this sooner."](https://x.com/chrisdeweese_/status/1853587120406876601) [![Alex Reibman](https://www.firecrawl.dev/assets-original/testimonials/alex-reibman.png)Alex Reibman@AlexReibman"Moved our internal agent's web scraping tool from Apify to Firecrawl because it benchmarked 50x faster with AgentOps."](https://x.com/AlexReibman/status/1780299595484131836) [![Tom - Morpho](https://www.firecrawl.dev/assets-original/testimonials/tom-morpho.png)Tom - Morpho@TomReppelin"I found gold today. Thank you @firecrawl"](https://x.com/TomReppelin/status/1844382491014201613)

[![Morgan Linton](https://www.firecrawl.dev/assets-original/testimonials/morgan-linton.png)Morgan Linton@morganlinton"If you're coding with AI, and haven't discovered @firecrawl yet, prepare to have your mind blown ü§Ø"](https://x.com/morganlinton/status/1839454165703204955) [![Chris DeWeese](https://www.firecrawl.dev/assets-original/testimonials/chris-deweese.png)Chris DeWeese@chrisdeweese\_"Started using @firecrawl for a project, I wish I used this sooner."](https://x.com/chrisdeweese_/status/1853587120406876601) [![Alex Reibman](https://www.firecrawl.dev/assets-original/testimonials/alex-reibman.png)Alex Reibman@AlexReibman"Moved our internal agent's web scraping tool from Apify to Firecrawl because it benchmarked 50x faster with AgentOps."](https://x.com/AlexReibman/status/1780299595484131836) [![Tom - Morpho](https://www.firecrawl.dev/assets-original/testimonials/tom-morpho.png)Tom - Morpho@TomReppelin"I found gold today. Thank you @firecrawl"](https://x.com/TomReppelin/status/1844382491014201613)

[![Bardia](https://www.firecrawl.dev/assets-original/testimonials/bardia.png)Bardia@thepericulum"The Firecrawl team ships. I wanted types for their node SDK, and less than an hour later, I got them."](https://x.com/thepericulum/status/1781397799487078874) [![Matt Busigin](https://www.firecrawl.dev/assets-original/testimonials/matt-busigin.png)Matt Busigin@mbusigin"Firecrawl is dope. Congrats guys üëè"](https://x.com/mbusigin/status/1836065372010656069) [![Sumanth](https://www.firecrawl.dev/assets-original/testimonials/sumanth.png)Sumanth@Sumanth\_077"Web scraping will never be the same!\\
\\
Firecrawl is an open-source framework that takes a URL, crawls it, and conver..."](https://x.com/Sumanth_077/status/1940049003074478511) [![Steven Tey](https://www.firecrawl.dev/assets-original/testimonials/steven-tey.png)Steven Tey@steventey"Open-source Clay alternative just dropped\\
\\
Upload a CSV of emails and..."](https://x.com/steventey/status/1932945651761098889)

[![Bardia](https://www.firecrawl.dev/assets-original/testimonials/bardia.png)Bardia@thepericulum"The Firecrawl team ships. I wanted types for their node SDK, and less than an hour later, I got them."](https://x.com/thepericulum/status/1781397799487078874) [![Matt Busigin](https://www.firecrawl.dev/assets-original/testimonials/matt-busigin.png)Matt Busigin@mbusigin"Firecrawl is dope. Congrats guys üëè"](https://x.com/mbusigin/status/1836065372010656069) [![Sumanth](https://www.firecrawl.dev/assets-original/testimonials/sumanth.png)Sumanth@Sumanth\_077"Web scraping will never be the same!\\
\\
Firecrawl is an open-source framework that takes a URL, crawls it, and conver..."](https://x.com/Sumanth_077/status/1940049003074478511) [![Steven Tey](https://www.firecrawl.dev/assets-original/testimonials/steven-tey.png)Steven Tey@steventey"Open-source Clay alternative just dropped\\
\\
Upload a CSV of emails and..."](https://x.com/steventey/status/1932945651761098889)

\[ 03 / 03 \]

¬∑

FAQ

//

FAQ

//

## Frequently    asked questions

Everything you need to know about Firecrawl.

Billing

Is Firecrawl free?

Firecrawl is free for the first 500 scraped pages (500 free credits). After that, you can upgrade to our Hobby, Standard or Growth plans for more credits and higher rate limits.

Is there a pay-per-use plan instead of monthly?

We currently do not offer a pay-per-use plan, instead you can upgrade to our Hobby, Standard or Growth plans for more credits and higher rate limits.

Do credits roll over to the next month?

In short, no ‚Äî credits do not roll over to the next month/year. Credit packs follow their own billing period. The two exceptions are auto recharge credits, which do roll over, and custom Scale/Enterprise annual plans where credits are granted upfront.

How many credits do scraping and crawling cost?

Scraping and crawling usually cost 1 credit per webpage or 1 credit per PDF page. There are advanced features available which cost additional credits. Check out the credits table on the pricing page for more details.

Do you charge for failed requests?

We do not usually charge for any failed requests. The only exception is requests using FIRE-1 agent are always billed, even if the request fails. Please contact support at help@firecrawl.com if you notice something wrong.

What payment methods do you accept?

We accept payments through Stripe which accepts most major credit cards, debit cards, and PayPal.

FOOTER

The easiest way to extract

data from the web

Backed by

Y Combinator

[Linkedin](https://www.linkedin.com/company/firecrawl) [Github](https://github.com/firecrawl/firecrawl) [YouTube](https://www.youtube.com/@Firecrawl_dev)

SOC II ¬∑ Type 2

AICPA

SOC 2

[X (Twitter)](https://x.com/firecrawl) [Discord](https://discord.gg/gSmWdAkdwd)

Products

[Playground](https://www.firecrawl.dev/playground) [Agent](https://www.firecrawl.dev/agent) [Pricing](https://www.firecrawl.dev/pricing) [Templates](https://www.firecrawl.dev/templates) [Changelog](https://www.firecrawl.dev/changelog)

Use Cases

[AI Platforms](https://www.firecrawl.dev/use-cases/ai-platforms) [Lead Enrichment](https://www.firecrawl.dev/use-cases/lead-enrichment) [SEO Teams](https://www.firecrawl.dev/use-cases/seo-teams) [Deep Research](https://www.firecrawl.dev/use-cases/deep-research) [Competitive Intelligence](https://www.firecrawl.dev/use-cases/competitive-intelligence)

Documentation

[Getting started](https://docs.firecrawl.dev/introduction) [API Reference](https://docs.firecrawl.dev/api-reference/introduction) [Integrations](https://www.firecrawl.dev/app) [Examples](https://docs.firecrawl.dev/use-cases/overview) [SDKs](https://docs.firecrawl.dev/sdks/overview)

Company

[Blog](https://www.firecrawl.dev/blog) [Careers](https://www.firecrawl.dev/careers) [Creator & OSS program](https://www.firecrawl.dev/creator-oss-program) [Student program](https://www.firecrawl.dev/student-program)

¬© 2025 Firecrawl

[Terms of Service](https://www.firecrawl.dev/terms-of-service) [Privacy Policy](https://www.firecrawl.dev/privacy-policy) [Report Abuse](mailto:help@firecrawl.com?subject=Issue:)

[All systems normal](https://status.firecrawl.dev/)

StripeM-Inner

## Web Data Extraction Insights
Introducing the Firecrawl Skill + CLI for Agents. [Learn more ‚Üí](https://docs.firecrawl.dev/sdks/cli)

Blog

All Posts

Updates

Customers

Example Apps

Web Extraction

AI Engineering

Low Code

[![Extract Web Data at Scale With Parallel Agents](https://www.firecrawl.dev/_next/image?url=%2Fimages%2Fblog%2Fparallel-agents%2Fparallel-agents.webp&w=3840&q=75&dpl=dpl_2hQ8hmy6vNQsu8DPuBRaRM6deLpr)\\
\\
Extract Web Data at Scale With Parallel Agents\\
\\
Parallel Agents let you batch process hundreds or thousands of /agent queries in a spreadsheet or JSON format with real-time streaming results.\\
\\
![Eric Ciarla](https://www.firecrawl.dev/_next/image?url=%2Fblog%2Fauthors%2Feric-img.jpeg&w=48&q=75&dpl=dpl_2hQ8hmy6vNQsu8DPuBRaRM6deLpr)\\
\\
Eric Ciarla\\
\\
Jan 30, 2026](https://www.firecrawl.dev/blog/introducing-parallel-agents)

[Introducing the Firecrawl Skill and CLI - Give Agents Real-Time Web Data\\
\\
A single command teaches AI agents how to scrape, search, crawl, and map the web. Works with Claude Code, Codex, Gemini CLI, OpenCode, and more.\\
\\
![Eric Ciarla](https://www.firecrawl.dev/_next/image?url=%2Fblog%2Fauthors%2Feric-img.jpeg&w=48&q=75&dpl=dpl_2hQ8hmy6vNQsu8DPuBRaRM6deLpr)\\
\\
Eric Ciarla\\
\\
Jan 27, 2026](https://www.firecrawl.dev/blog/introducing-firecrawl-skill-and-cli) [How Credal Extracts 6M+ URLs Monthly to Power Production AI Agents\\
\\
How Credal uses Firecrawl to deliver reliable web scraping at scale for enterprise AI agents that need both fresh external context and durable knowledge base ingestion.\\
\\
![Eric Ciarla](https://www.firecrawl.dev/_next/image?url=%2Fblog%2Fauthors%2Feric-img.jpeg&w=48&q=75&dpl=dpl_2hQ8hmy6vNQsu8DPuBRaRM6deLpr)\\
\\
Eric Ciarla\\
\\
Jan 26, 2026](https://www.firecrawl.dev/blog/credal-firecrawl-ai-agents) [Introducing Spark 1 Pro and Spark 1 Mini\\
\\
Spark 1 Pro and Spark 1 Mini bring flexible model selection to /agent. Mini is 60% cheaper for everyday tasks, Pro delivers maximum accuracy for complex extraction.\\
\\
![Eric Ciarla](https://www.firecrawl.dev/_next/image?url=%2Fblog%2Fauthors%2Feric-img.jpeg&w=48&q=75&dpl=dpl_2hQ8hmy6vNQsu8DPuBRaRM6deLpr)\\
\\
Eric Ciarla\\
\\
Jan 14, 2026](https://www.firecrawl.dev/blog/introducing-spark-1)

[Introducing /agent: Gather Data Wherever It Lives on the Web\\
\\
Firecrawl /agent searches, navigates, and gathers complex websites to find data in hard-to-reach places. What takes humans hours, Agent does in minutes.\\
\\
![Eric Ciarla](https://www.firecrawl.dev/_next/image?url=%2Fblog%2Fauthors%2Feric-img.jpeg&w=48&q=75&dpl=dpl_2hQ8hmy6vNQsu8DPuBRaRM6deLpr)\\
\\
Eric Ciarla\\
\\
Dec 18, 2025](https://www.firecrawl.dev/blog/introducing-agent) [Firecrawl + Lovable - Build Web Data Apps Without Writing Code\\
\\
With the new Firecrawl + Loveable integration, build apps that scrape, search, and interact with live web data - just by describing what you want in plain English.\\
\\
![Nicolas Camara](https://www.firecrawl.dev/_next/image?url=%2Fblog%2Fauthors%2Fnick-img.jpeg&w=48&q=75&dpl=dpl_2hQ8hmy6vNQsu8DPuBRaRM6deLpr)\\
\\
Nicolas Camara\\
\\
Dec 16, 2025](https://www.firecrawl.dev/blog/firecrawl-lovable-integration) [Retell‚Äôs AI phone agents get LLM-ready content from Firecrawl\\
\\
How Retell keeps AI phone agents answering from live, LLM-ready content using Firecrawl‚Äôs web scraping API.\\
\\
![Eric Ciarla](https://www.firecrawl.dev/_next/image?url=%2Fblog%2Fauthors%2Feric-img.jpeg&w=48&q=75&dpl=dpl_2hQ8hmy6vNQsu8DPuBRaRM6deLpr)\\
\\
Eric Ciarla\\
\\
Dec 04, 2025](https://www.firecrawl.dev/blog/retell-firecrawl-ai-phone-agents)

[Introducing Firecrawl v2.5 - The World's Best Web Data API\\
\\
Firecrawl v2.5 delivers the highest quality and most comprehensive web data available, powered by our new Semantic Index and custom browser stack.\\
\\
![Eric Ciarla](https://www.firecrawl.dev/_next/image?url=%2Fblog%2Fauthors%2Feric-img.jpeg&w=48&q=75&dpl=dpl_2hQ8hmy6vNQsu8DPuBRaRM6deLpr)\\
\\
Eric Ciarla\\
\\
Oct 30, 2025](https://www.firecrawl.dev/blog/the-worlds-best-web-data-api-v25) [We just raised our Series A and shipped /v2\\
\\
How we got here. What we're building. Why the web's knowledge should be on tap for AI.\\
\\
![Caleb Peffer](https://www.firecrawl.dev/_next/image?url=%2Fblog%2Fauthors%2Fcaleb.jpg&w=48&q=75&dpl=dpl_2hQ8hmy6vNQsu8DPuBRaRM6deLpr)\\
\\
Caleb Peffer\\
\\
Aug 19, 2025](https://www.firecrawl.dev/blog/firecrawl-v2-series-a-announcement) [How Engage Together Uses Firecrawl to Map Anti-Trafficking Resources\\
\\
Discover how Engage Together leverages Firecrawl‚Äôs /extract API to collect and organize critical data on anti-trafficking programs and resources across communities.\\
\\
![Ashleigh Chapman](https://www.firecrawl.dev/_next/image?url=%2Fimages%2Fauthors%2Fashleigh-chapman.webp&w=48&q=75&dpl=dpl_2hQ8hmy6vNQsu8DPuBRaRM6deLpr)\\
\\
Ashleigh Chapman\\
\\
Aug 17, 2025](https://www.firecrawl.dev/blog/how-engage-together-uses-firecrawl-to-map-anti-trafficking-resources)

[Dub Builds AI Affiliate Pages with Firecrawl\\
\\
Discover how Dub uses Firecrawl to power their AI page builder, transforming company websites into affiliate program landing pages in seconds.\\
\\
![Steven Tey](https://www.firecrawl.dev/_next/image?url=%2Fimages%2Fauthors%2Fsteventey.jpg&w=48&q=75&dpl=dpl_2hQ8hmy6vNQsu8DPuBRaRM6deLpr)\\
\\
Steven Tey\\
\\
Aug 13, 2025](https://www.firecrawl.dev/blog/how-dub-builds-ai-affiliate-pages-with-firecrawl) [Zapier Empowers Chatbots with Firecrawl\\
\\
Discover how Zapier uses Firecrawl to empower customers with custom knowledge in their chatbots.\\
\\
![Andrew Gardner](https://www.firecrawl.dev/_next/image?url=%2Fblog%2Fauthors%2Fandrew-zapier.jpg&w=48&q=75&dpl=dpl_2hQ8hmy6vNQsu8DPuBRaRM6deLpr)\\
\\
Andrew Gardner\\
\\
Jul 21, 2025](https://www.firecrawl.dev/blog/how-zapier-uses-firecrawl-to-power-chatbots) [Open Researcher, our AI Agent That Uses Firecrawl Tools During Research\\
\\
We built a research agent using Anthropic's interleaved thinking and Firecrawl. No orchestration needed.\\
\\
![Eric Ciarla](https://www.firecrawl.dev/_next/image?url=%2Fblog%2Fauthors%2Feric-img.jpeg&w=48&q=75&dpl=dpl_2hQ8hmy6vNQsu8DPuBRaRM6deLpr)\\
\\
Eric Ciarla\\
\\
Jul 01, 2025](https://www.firecrawl.dev/blog/open-researcher-interleaved-thinking)

[How Answer HQ Powers AI Customer Support with Firecrawl\\
\\
Discover how Answer HQ uses Firecrawl to help small businesses import their website data and build intelligent support assistants.\\
\\
![Jacky Liang](https://www.firecrawl.dev/_next/image?url=%2Fblog%2Fauthors%2Fjacky-liang%2Fimg.jpeg&w=48&q=75&dpl=dpl_2hQ8hmy6vNQsu8DPuBRaRM6deLpr)\\
\\
Jacky Liang\\
\\
Jun 05, 2025](https://www.firecrawl.dev/blog/how-answer-hq-powers-ai-customer-support-with-firecrawl) [Announcing /search: Discover and scrape the web with one API call\\
\\
Search the web and get LLM-ready page content for each result in one simple API call. Perfect for agents, devs, and anyone who needs web data fast.\\
\\
![Eric Ciarla](https://www.firecrawl.dev/_next/image?url=%2Fblog%2Fauthors%2Feric-img.jpeg&w=48&q=75&dpl=dpl_2hQ8hmy6vNQsu8DPuBRaRM6deLpr)\\
\\
Eric Ciarla\\
\\
Jun 03, 2025](https://www.firecrawl.dev/blog/introducing-search-endpoint) [Introducing Templates: Ready to use Firecrawl examples\\
\\
A library of reusable playground setups, code snippets, and repos to help you quickly implement Firecrawl for any use case.\\
\\
![Eric Ciarla](https://www.firecrawl.dev/_next/image?url=%2Fblog%2Fauthors%2Feric-img.jpeg&w=48&q=75&dpl=dpl_2hQ8hmy6vNQsu8DPuBRaRM6deLpr)\\
\\
Eric Ciarla\\
\\
May 13, 2025](https://www.firecrawl.dev/blog/introducing-firecrawl-templates)

[How Botpress Enhances Knowledge Base Creation with Firecrawl\\
\\
Discover how Botpress uses Firecrawl to streamline knowledge base population and improve user experience.\\
\\
![Michael Masson](https://www.firecrawl.dev/_next/image?url=%2Fblog%2Fauthors%2Fmike-botpress.jpg&w=48&q=75&dpl=dpl_2hQ8hmy6vNQsu8DPuBRaRM6deLpr)\\
\\
Michael Masson\\
\\
Apr 21, 2025](https://www.firecrawl.dev/blog/how-botpress-enhances-knowledge-base-creation-with-firecrawl) [Integrations Day: Launch Week III - Day 7\\
\\
Firecrawl now connects with over 20 platforms including Discord, Make, Langflow, and more. Discover what's new on Integration Day.\\
\\
![Eric Ciarla](https://www.firecrawl.dev/_next/image?url=%2Fblog%2Fauthors%2Feric-img.jpeg&w=48&q=75&dpl=dpl_2hQ8hmy6vNQsu8DPuBRaRM6deLpr)\\
\\
Eric Ciarla\\
\\
Apr 20, 2025](https://www.firecrawl.dev/blog/launch-week-iii-day-7-integrations) [Firecrawl MCP Upgrades: Launch Week III - Day 6\\
\\
Major updates to the Firecrawl MCP server, now with FIRE-1 support and Server-Sent Events for faster, easier web data access.\\
\\
![Eric Ciarla](https://www.firecrawl.dev/_next/image?url=%2Fblog%2Fauthors%2Feric-img.jpeg&w=48&q=75&dpl=dpl_2hQ8hmy6vNQsu8DPuBRaRM6deLpr)\\
\\
Eric Ciarla\\
\\
Apr 19, 2025](https://www.firecrawl.dev/blog/launch-week-iii-day-6-firecrawl-mcp)

[Developer Day: Launch Week III - Day 5\\
\\
Launch Week III Day 5 is all about developers. We're shipping big improvements to our Python and Rust SDKs, plus a new dark theme for your favorite code editors.\\
\\
![Eric Ciarla](https://www.firecrawl.dev/_next/image?url=%2Fblog%2Fauthors%2Feric-img.jpeg&w=48&q=75&dpl=dpl_2hQ8hmy6vNQsu8DPuBRaRM6deLpr)\\
\\
Eric Ciarla\\
\\
Apr 18, 2025](https://www.firecrawl.dev/blog/launch-week-iii-day-5-dev-day) [Announcing LLMstxt.new: Launch Week III - Day 4\\
\\
Turn any website into a clean, LLM-ready text file in seconds with llmstxt.new ‚Äî powered by Firecrawl.\\
\\
![Eric Ciarla](https://www.firecrawl.dev/_next/image?url=%2Fblog%2Fauthors%2Feric-img.jpeg&w=48&q=75&dpl=dpl_2hQ8hmy6vNQsu8DPuBRaRM6deLpr)\\
\\
Eric Ciarla\\
\\
Apr 17, 2025](https://www.firecrawl.dev/blog/launch-week-iii-day-4-announcing-llmstxt-new) [Introducing /extract v2: Launch Week III - Day 3\\
\\
Firecrawl's updated /extract v2 endpoint brings powerful new capabilities like pagination, intelligent interaction via FIRE-1, and built-in search‚Äîdramatically improving data extraction workflows.\\
\\
![Eric Ciarla](https://www.firecrawl.dev/_next/image?url=%2Fblog%2Fauthors%2Feric-img.jpeg&w=48&q=75&dpl=dpl_2hQ8hmy6vNQsu8DPuBRaRM6deLpr)\\
\\
Eric Ciarla\\
\\
Apr 16, 2025](https://www.firecrawl.dev/blog/launch-week-iii-day-3-extract-v2)

[Announcing FIRE-1, Our Web Action Agent: Launch Week III - Day 2\\
\\
Firecrawl's new FIRE-1 AI Agent enhances web scraping capabilities by intelligently navigating and interacting with web pages.\\
\\
![Eric Ciarla](https://www.firecrawl.dev/_next/image?url=%2Fblog%2Fauthors%2Feric-img.jpeg&w=48&q=75&dpl=dpl_2hQ8hmy6vNQsu8DPuBRaRM6deLpr)\\
\\
Eric Ciarla\\
\\
Apr 15, 2025](https://www.firecrawl.dev/blog/launch-week-iii-day-2-announcing-fire-1) [Introducing Change Tracking: Launch Week III - Day 1\\
\\
Firecrawl's enhanced Change Tracking feature now provides detailed insights into webpage updates, including diffs and structured data comparisons.\\
\\
![Eric Ciarla](https://www.firecrawl.dev/_next/image?url=%2Fblog%2Fauthors%2Feric-img.jpeg&w=48&q=75&dpl=dpl_2hQ8hmy6vNQsu8DPuBRaRM6deLpr)\\
\\
Eric Ciarla\\
\\
Apr 14, 2025](https://www.firecrawl.dev/blog/launch-week-iii-day-1-introducing-change-tracking) [Firecrawl Editor Theme: Launch Week III - Day 0\\
\\
Our official Firecrawl Editor Theme provides a clean, focused coding experience optimized for everyone.\\
\\
![Eric Ciarla](https://www.firecrawl.dev/_next/image?url=%2Fblog%2Fauthors%2Feric-img.jpeg&w=48&q=75&dpl=dpl_2hQ8hmy6vNQsu8DPuBRaRM6deLpr)\\
\\
Eric Ciarla\\
\\
Apr 13, 2025](https://www.firecrawl.dev/blog/launch-week-iii-day-0-firecrawl-editor-theme)

[Announcing Deep Research API\\
\\
Firecrawl's new Deep Research API enables autonomous, AI-powered web research on any topic.\\
\\
![Nicolas Camara](https://www.firecrawl.dev/_next/image?url=%2Fblog%2Fauthors%2Fnick-img.jpeg&w=48&q=75&dpl=dpl_2hQ8hmy6vNQsu8DPuBRaRM6deLpr)\\
\\
Nicolas Camara\\
\\
Mar 27, 2025](https://www.firecrawl.dev/blog/deep-research-api) [How Replit Uses Firecrawl to Power Replit Agent\\
\\
Discover how Replit leverages Firecrawl to keep Replit Agent up to date with the latest API documentation and web content.\\
\\
![Zhen Li](https://www.firecrawl.dev/_next/image?url=%2Fblog%2Fauthors%2Fzhen.jpg&w=48&q=75&dpl=dpl_2hQ8hmy6vNQsu8DPuBRaRM6deLpr)\\
\\
Zhen Li\\
\\
Feb 17, 2025](https://www.firecrawl.dev/blog/how-replit-uses-firecrawl-to-power-ai-agents) [Introducing /extract: Get structured web data with just a prompt\\
\\
Our new /extract endpoint harnesses AI to turn any website into structured data for your applications seamlessly.\\
\\
![Eric Ciarla](https://www.firecrawl.dev/_next/image?url=%2Fblog%2Fauthors%2Feric-img.jpeg&w=48&q=75&dpl=dpl_2hQ8hmy6vNQsu8DPuBRaRM6deLpr)\\
\\
Eric Ciarla\\
\\
Jan 20, 2025](https://www.firecrawl.dev/blog/introducing-extract-open-beta)

[How Stack AI Uses Firecrawl to Power AI Agents\\
\\
Discover how Stack AI leverages Firecrawl to seamlessly feed agentic AI workflows with high-quality web data.\\
\\
![Jonathan Kleiman](https://www.firecrawl.dev/_next/image?url=%2Fblog%2Fauthors%2Fjonathan.jpeg&w=48&q=75&dpl=dpl_2hQ8hmy6vNQsu8DPuBRaRM6deLpr)\\
\\
Jonathan Kleiman\\
\\
Jan 03, 2025](https://www.firecrawl.dev/blog/how-stack-ai-uses-firecrawl-to-power-ai-agents) [How Cargo Empowers GTM Teams with Firecrawl\\
\\
See how Cargo uses Firecrawl to instantly analyze webpage content and power Go-To-Market workflows for their users.\\
\\
![Tariq Minhas](https://www.firecrawl.dev/_next/image?url=%2Fblog%2Fauthors%2Ftariq.jpg&w=48&q=75&dpl=dpl_2hQ8hmy6vNQsu8DPuBRaRM6deLpr)\\
\\
Tariq Minhas\\
\\
Dec 06, 2024](https://www.firecrawl.dev/blog/how-cargo-empowers-gtm-teams-with-firecrawl) [Launch Week II Recap\\
\\
Recapping all the exciting announcements from Firecrawl's second Launch Week.\\
\\
![Eric Ciarla](https://www.firecrawl.dev/_next/image?url=%2Fblog%2Fauthors%2Feric-img.jpeg&w=48&q=75&dpl=dpl_2hQ8hmy6vNQsu8DPuBRaRM6deLpr)\\
\\
Eric Ciarla\\
\\
Nov 04, 2024](https://www.firecrawl.dev/blog/launch-week-ii-recap)

[Launch Week II - Day 7: Introducing Faster Markdown Parsing\\
\\
Our new HTML to Markdown parser is 4x faster, more reliable, and produces cleaner Markdown, built from the ground up for speed and performance.\\
\\
![Eric Ciarla](https://www.firecrawl.dev/_next/image?url=%2Fblog%2Fauthors%2Feric-img.jpeg&w=48&q=75&dpl=dpl_2hQ8hmy6vNQsu8DPuBRaRM6deLpr)\\
\\
Eric Ciarla\\
\\
Nov 03, 2024](https://www.firecrawl.dev/blog/launch-week-ii-day-7-introducing-faster-markdown-parsing) [Launch Week II - Day 6: Announcing Mobile Scraping and Screenshots\\
\\
Interact with sites as if from a mobile device using Firecrawl's new mobile device emulation.\\
\\
![Eric Ciarla](https://www.firecrawl.dev/_next/image?url=%2Fblog%2Fauthors%2Feric-img.jpeg&w=48&q=75&dpl=dpl_2hQ8hmy6vNQsu8DPuBRaRM6deLpr)\\
\\
Eric Ciarla\\
\\
Nov 02, 2024](https://www.firecrawl.dev/blog/launch-week-ii-day-6-introducing-mobile-scraping) [Launch Week II - Day 5: Announcing New Actions\\
\\
Capture page content at any point and wait for specific elements with our new Scrape and Wait for Selector actions.\\
\\
![Eric Ciarla](https://www.firecrawl.dev/_next/image?url=%2Fblog%2Fauthors%2Feric-img.jpeg&w=48&q=75&dpl=dpl_2hQ8hmy6vNQsu8DPuBRaRM6deLpr)\\
\\
Eric Ciarla\\
\\
Nov 01, 2024](https://www.firecrawl.dev/blog/launch-week-ii-day-5-introducing-two-new-actions)

[Launch Week II - Day 4: Advanced iframe Scraping\\
\\
We are thrilled to announce comprehensive iframe scraping support in Firecrawl, enabling seamless handling of nested iframes, dynamically loaded content, and cross-origin frames.\\
\\
![Eric Ciarla](https://www.firecrawl.dev/_next/image?url=%2Fblog%2Fauthors%2Feric-img.jpeg&w=48&q=75&dpl=dpl_2hQ8hmy6vNQsu8DPuBRaRM6deLpr)\\
\\
Eric Ciarla\\
\\
Oct 31, 2024](https://www.firecrawl.dev/blog/launch-week-ii-day-4-advanced-iframe-scraping) [Launch Week II - Day 3: Announcing Credit Packs\\
\\
Easily top up your plan with Credit Packs to keep your web scraping projects running smoothly. Plus, manage your credits effortlessly with our new Auto Recharge feature.\\
\\
![Eric Ciarla](https://www.firecrawl.dev/_next/image?url=%2Fblog%2Fauthors%2Feric-img.jpeg&w=48&q=75&dpl=dpl_2hQ8hmy6vNQsu8DPuBRaRM6deLpr)\\
\\
Eric Ciarla\\
\\
Oct 30, 2024](https://www.firecrawl.dev/blog/launch-week-ii-day-3-introducing-credit-packs) [Launch Week II - Day 2: Introducing Location and Language Settings\\
\\
Specify country and preferred languages to get relevant localized content, enhancing your web scraping results with region-specific data.\\
\\
![Eric Ciarla](https://www.firecrawl.dev/_next/image?url=%2Fblog%2Fauthors%2Feric-img.jpeg&w=48&q=75&dpl=dpl_2hQ8hmy6vNQsu8DPuBRaRM6deLpr)\\
\\
Eric Ciarla\\
\\
Oct 29, 2024](https://www.firecrawl.dev/blog/launch-week-ii-day-2-introducing-location-language-settings)

[Launch Week II - Day 1: Announcing the Batch Scrape Endpoint\\
\\
Our new Batch Scrape endpoint lets you scrape multiple URLs simultaneously, making bulk data collection faster and more efficient.\\
\\
![Eric Ciarla](https://www.firecrawl.dev/_next/image?url=%2Fblog%2Fauthors%2Feric-img.jpeg&w=48&q=75&dpl=dpl_2hQ8hmy6vNQsu8DPuBRaRM6deLpr)\\
\\
Eric Ciarla\\
\\
Oct 28, 2024](https://www.firecrawl.dev/blog/launch-week-ii-day-1-introducing-batch-scrape-endpoint) [Handling 300k requests per day: an adventure in scaling\\
\\
Putting out fires was taking up all our time, and we had to scale fast. This is how we did it.\\
\\
![Gerg≈ë M√≥ricz (mogery)](https://www.firecrawl.dev/_next/image?url=%2Fimages%2Fauthors%2Fmogery.webp&w=48&q=75&dpl=dpl_2hQ8hmy6vNQsu8DPuBRaRM6deLpr)\\
\\
Gerg≈ë M√≥ricz (mogery)\\
\\
Sep 13, 2024](https://www.firecrawl.dev/blog/an-adventure-in-scaling) [How Athena Intelligence Empowers Enterprise Analysts with Firecrawl\\
\\
Discover how Athena Intelligence leverages Firecrawl to fuel its AI-native analytics platform for enterprise analysts.\\
\\
![Ben Reilly](https://www.firecrawl.dev/_next/image?url=%2Fblog%2Fauthors%2F%2Fben-reilly.png&w=48&q=75&dpl=dpl_2hQ8hmy6vNQsu8DPuBRaRM6deLpr)\\
\\
Ben Reilly\\
\\
Sep 10, 2024](https://www.firecrawl.dev/blog/how-athena-intelligence-empowers-analysts-with-firecrawl)

[Launch Week I Recap\\
\\
A look back at the new features and updates introduced during Firecrawl's inaugural Launch Week.\\
\\
![Eric Ciarla](https://www.firecrawl.dev/_next/image?url=%2Fblog%2Fauthors%2Feric-img.jpeg&w=48&q=75&dpl=dpl_2hQ8hmy6vNQsu8DPuBRaRM6deLpr)\\
\\
Eric Ciarla\\
\\
Sep 02, 2024](https://www.firecrawl.dev/blog/firecrawl-launch-week-1-recap) [Launch Week I / Day 7: Crawl Webhooks (v1)\\
\\
New /crawl webhook support. Send notifications to your apps during a crawl.\\
\\
![Nicolas Camara](https://www.firecrawl.dev/_next/image?url=%2Fblog%2Fauthors%2Fnick-img.jpeg&w=48&q=75&dpl=dpl_2hQ8hmy6vNQsu8DPuBRaRM6deLpr)\\
\\
Nicolas Camara\\
\\
Sep 01, 2024](https://www.firecrawl.dev/blog/launch-week-i-day-7-webhooks) [Launch Week I / Day 6: LLM Extract (v1)\\
\\
Extract structured data from your web pages using the extract format in /scrape.\\
\\
![Nicolas Camara](https://www.firecrawl.dev/_next/image?url=%2Fblog%2Fauthors%2Fnick-img.jpeg&w=48&q=75&dpl=dpl_2hQ8hmy6vNQsu8DPuBRaRM6deLpr)\\
\\
Nicolas Camara\\
\\
Aug 31, 2024](https://www.firecrawl.dev/blog/launch-week-i-day-6-llm-extract)

[Launch Week I / Day 5: Real-Time Crawling with WebSockets\\
\\
Our new WebSocket-based method for real-time data extraction and monitoring.\\
\\
![Eric Ciarla](https://www.firecrawl.dev/_next/image?url=%2Fblog%2Fauthors%2Feric-img.jpeg&w=48&q=75&dpl=dpl_2hQ8hmy6vNQsu8DPuBRaRM6deLpr)\\
\\
Eric Ciarla\\
\\
Aug 30, 2024](https://www.firecrawl.dev/blog/launch-week-i-day-5-real-time-crawling-websockets) [Launch Week I / Day 4: Announcing Firecrawl /v1\\
\\
Our biggest release yet - v1, a more reliable and developer-friendly API for seamless web data gathering.\\
\\
![Eric Ciarla](https://www.firecrawl.dev/_next/image?url=%2Fblog%2Fauthors%2Feric-img.jpeg&w=48&q=75&dpl=dpl_2hQ8hmy6vNQsu8DPuBRaRM6deLpr)\\
\\
Eric Ciarla\\
\\
Aug 29, 2024](https://www.firecrawl.dev/blog/launch-week-i-day-4-introducing-firecrawl-v1) [Launch Week I / Day 3: Introducing the Map Endpoint\\
\\
Our new Map endpoint enables lightning-fast website mapping for enhanced web scraping projects.\\
\\
![Eric Ciarla](https://www.firecrawl.dev/_next/image?url=%2Fblog%2Fauthors%2Feric-img.jpeg&w=48&q=75&dpl=dpl_2hQ8hmy6vNQsu8DPuBRaRM6deLpr)\\
\\
Eric Ciarla\\
\\
Aug 28, 2024](https://www.firecrawl.dev/blog/launch-week-i-day-3-introducing-map-endpoint)

[Launch Week I / Day 2: 2x Rate Limits\\
\\
Firecrawl doubles rate limits across all plans, supercharging your web scraping capabilities.\\
\\
![Eric Ciarla](https://www.firecrawl.dev/_next/image?url=%2Fblog%2Fauthors%2Feric-img.jpeg&w=48&q=75&dpl=dpl_2hQ8hmy6vNQsu8DPuBRaRM6deLpr)\\
\\
Eric Ciarla\\
\\
Aug 27, 2024](https://www.firecrawl.dev/blog/launch-week-i-day-2-doubled-rate-limits) [Launch Week I / Day 1: Introducing Teams\\
\\
Our new Teams feature, enabling seamless collaboration on web scraping projects.\\
\\
![Eric Ciarla](https://www.firecrawl.dev/_next/image?url=%2Fblog%2Fauthors%2Feric-img.jpeg&w=48&q=75&dpl=dpl_2hQ8hmy6vNQsu8DPuBRaRM6deLpr)\\
\\
Eric Ciarla\\
\\
Aug 26, 2024](https://www.firecrawl.dev/blog/launch-week-i-day-1-introducing-teams) [How Gamma Supercharges Onboarding with Firecrawl\\
\\
See how Gamma uses Firecrawl to instantly generate websites and presentations to 20+ million users.\\
\\
![Jon Noronha](https://www.firecrawl.dev/_next/image?url=%2Fblog%2Fauthors%2Fjon-noronha.jpg&w=48&q=75&dpl=dpl_2hQ8hmy6vNQsu8DPuBRaRM6deLpr)\\
\\
Jon Noronha\\
\\
Aug 08, 2024](https://www.firecrawl.dev/blog/how-gamma-supercharges-onboarding-with-firecrawl)

[Announcing Fire Engine for Firecrawl\\
\\
The most scalable, reliable, and fast way to get web data for Firecrawl.\\
\\
![Eric Ciarla](https://www.firecrawl.dev/_next/image?url=%2Fblog%2Fauthors%2Feric-img.jpeg&w=48&q=75&dpl=dpl_2hQ8hmy6vNQsu8DPuBRaRM6deLpr)\\
\\
Eric Ciarla\\
\\
Aug 06, 2024](https://www.firecrawl.dev/blog/introducing-fire-engine-for-firecrawl) [Firecrawl July 2024 Updates\\
\\
Discover the latest features, integrations, and improvements in Firecrawl for July 2024.\\
\\
![Eric Ciarla](https://www.firecrawl.dev/_next/image?url=%2Fblog%2Fauthors%2Feric-img.jpeg&w=48&q=75&dpl=dpl_2hQ8hmy6vNQsu8DPuBRaRM6deLpr)\\
\\
Eric Ciarla\\
\\
Jul 31, 2024](https://www.firecrawl.dev/blog/firecrawl-july-2024-updates) [Firecrawl June 2024 Updates\\
\\
Discover the latest features, integrations, and improvements in Firecrawl for June 2024.\\
\\
![Nicolas Camara](https://www.firecrawl.dev/_next/image?url=%2Fblog%2Fauthors%2Fnick-img.jpeg&w=48&q=75&dpl=dpl_2hQ8hmy6vNQsu8DPuBRaRM6deLpr)\\
\\
Nicolas Camara\\
\\
Jun 30, 2024](https://www.firecrawl.dev/blog/firecrawl-june-2024-updates)

FOOTER

The easiest way to extract

data from the web

Backed by

Y Combinator

[Linkedin](https://www.linkedin.com/company/firecrawl) [Github](https://github.com/firecrawl/firecrawl) [YouTube](https://www.youtube.com/@Firecrawl_dev)

SOC II ¬∑ Type 2

AICPA

SOC 2

[X (Twitter)](https://x.com/firecrawl) [Discord](https://discord.gg/gSmWdAkdwd)

Products

[Playground](https://www.firecrawl.dev/playground) [Agent](https://www.firecrawl.dev/agent) [Pricing](https://www.firecrawl.dev/pricing) [Templates](https://www.firecrawl.dev/templates) [Changelog](https://www.firecrawl.dev/changelog)

Use Cases

[AI Platforms](https://www.firecrawl.dev/use-cases/ai-platforms) [Lead Enrichment](https://www.firecrawl.dev/use-cases/lead-enrichment) [SEO Teams](https://www.firecrawl.dev/use-cases/seo-teams) [Deep Research](https://www.firecrawl.dev/use-cases/deep-research) [Competitive Intelligence](https://www.firecrawl.dev/use-cases/competitive-intelligence)

Documentation

[Getting started](https://docs.firecrawl.dev/introduction) [API Reference](https://docs.firecrawl.dev/api-reference/introduction) [Integrations](https://www.firecrawl.dev/app) [Examples](https://docs.firecrawl.dev/use-cases/overview) [SDKs](https://docs.firecrawl.dev/sdks/overview)

Company

[Blog](https://www.firecrawl.dev/blog) [Careers](https://www.firecrawl.dev/careers) [Creator & OSS program](https://www.firecrawl.dev/creator-oss-program) [Student program](https://www.firecrawl.dev/student-program)

¬© 2025 Firecrawl

[Terms of Service](https://www.firecrawl.dev/terms-of-service) [Privacy Policy](https://www.firecrawl.dev/privacy-policy) [Report Abuse](mailto:help@firecrawl.com?subject=Issue:)

[All systems normal](https://status.firecrawl.dev/)

## Firecrawl Agent Overview
Introducing the Firecrawl Skill + CLI for Agents. [Learn more ‚Üí](https://docs.firecrawl.dev/sdks/cli)

[In Research Preview - Try for free](https://www.firecrawl.dev/app/agent)

# Introducing Agent

Describe what data you want to extract

and /agent handles the rest. [Read the docs ‚Üí](https://docs.firecrawl.dev/features/agent)

Spark 1 MiniNew

5 free daily runs

Run Agent

Get the founders of Firecrawl, Pylon, and Mintlify

Get me all the Jordans from nike.com

Top 3 Hacker News stories today and the top 3 comments for each

\[ 01 / 06 \]

¬∑

How It Works

//

How It Works

//

## From prompt to data

Whether you need one data point or entire datasets at scale. Firecrawl Agent just works.

Agent searching

LIVE

SOURCE

STATUS

ycombinator.com/companies

extracted

firecrawl.dev/agent

extracted

crunchbase.com/organization/firecrawl

extracted

github.com/firecrawl

extracted

producthunt.com/posts/firecrawl

extracted

Structured output

JSON

RESULT

{

"name": "Firecrawl",

"founders": \["Eric C.", "Nicolas C.", "Caleb P."\],

"category": "Developer Tools",

"website": "https://firecrawl.dev"

}

247 records extracted

The evolution of /extract ‚Äî URLs are now optional

[Read docs](https://docs.firecrawl.dev/features/agent)

\[ 02 / 06 \]

¬∑

Use Cases

//

Use Cases

//

## Built for any task

From lead generation to dataset curation, Agent finds data in hard to reach places.

Lead Gen

‚ÄúGet all YC W24 companies with founders‚Äù

E-commerce

‚ÄúGet all Nike Air Jordan listings with prices‚Äù

Market Data

‚ÄúGet market cap for top 50 tech stocks‚Äù

Datasets

‚ÄúBuild a dataset of all AI papers from arXiv‚Äù

Real Estate

‚ÄúGet 3BR apartments in SF under $4k‚Äù

Research

‚ÄúExtract all Michelin star restaurants in NYC‚Äù

\[ 03 / 06 \]

¬∑

Get Started

//

Easy to integrate

//

## Start using /agent today

Agent is available in the API, SDKs and MCPs for easy integration.

PythonNode.jscURL

Copy

\[ INPUT \]

```
from firecrawl import FirecrawlApp
from pydantic import BaseModel
from typing import List, Optional

app = FirecrawlApp(api_key ="fc-YOUR-API-KEY")

class Company(BaseModel):
    name: str
    founders: List[str]
    funding: Optional[str] = None
    website: str

class ExtractSchema(BaseModel):
    companies: List[Company]

result = app.agent(
    prompt ="Get all YC W24 companies",
    schema =ExtractSchema
)
```

\[ .JSON \]

```
{
  "companies": [\
    {\
      "name": "Firecrawl",\
      "founders": ["Eric C.", "Nicolas C.", "Caleb P."],\
      "website": "https://firecrawl.dev",\
      "category": "Developer Tools"\
    },\
    {\
      "name": "Pylon",\
      "founders": ["Marty Kausas", "Advait Ruia"],\
      "website": "https://usepylon.com",\
      "category": "Customer Support"\
    },\
    {\
      "name": "Mintlify",\
      "founders": ["Han Wang", "Hahnbee Lee"],\
      "website": "https://mintlify.com",\
      "category": "Developer Tools"\
    }\
  ]
}
```

\[ CTA \]

\[ CRAWL \]

\[ SCRAPE \]

\[ CTA \]

//

Get started

//

Ready to build?

Start getting Web Data for free and scale seamlessly as your project expands. No credit card needed.

[Start for free](https://www.firecrawl.dev/signin) [See our plans](https://www.firecrawl.dev/pricing)

\[ 04 / 06 \]

¬∑

Pricing

//

Research Preview

//

## Agent Pricing

Dynamic pricing based on query's complexity

5

free runs daily

Explore Agent's capabilities at no cost

### Pricing during research preview is dynamic:

- Simple queries use fewer credits
- Complex queries use more credits
- See credit usage in real-time in the agent panel

[Try Agent free](https://www.firecrawl.dev/app/agent)

Use `maxCredits` parameter to limit spending.

### Model Pricing

Parallel Agents

Spark 1 Fast

Quick lookups available only in Parallel Agents

10credits / cell

Spark 1 Mini

Lightweight model, 60% cheaper

Dynamicbased on tokens

Most Accurate

Spark 1 Pro

High-performance model for complex tasks

Dynamicbased on tokens

Parallel Agents uses an intelligent waterfall: Spark 1 Fast attempts instant retrieval first, then automatically upgrades to Spark 1 Mini when full agent research is needed.

\[ 05 / 06 \]

¬∑

FAQ

//

FAQ

//

## Frequently asked questions

Everything you need to know about Firecrawl Agent.

Agent

What is the AI Agent?

How is Agent different from /extract?

What types of data can I extract?

Pricing

How many free runs do I get?

How much does it cost?

Usage

Do I need to provide URLs?

What output formats are supported?

How long does an extraction take?

Can Agent handle complex websites?

\[ CTA \]

\[ CRAWL \]

\[ SCRAPE \]

\[ CTA \]

//

Get started

//

Ready to build?

Start getting Web Data for free and scale seamlessly as your project expands. No credit card needed.

[Start for free](https://www.firecrawl.dev/signin) [See our plans](https://www.firecrawl.dev/pricing)

FOOTER

The easiest way to extract

data from the web

Backed by

Y Combinator

[Linkedin](https://www.linkedin.com/company/firecrawl) [Github](https://github.com/firecrawl/firecrawl) [YouTube](https://www.youtube.com/@Firecrawl_dev)

SOC II ¬∑ Type 2

AICPA

SOC 2

[X (Twitter)](https://x.com/firecrawl) [Discord](https://discord.gg/gSmWdAkdwd)

Products

[Playground](https://www.firecrawl.dev/playground) [Agent](https://www.firecrawl.dev/agent) [Pricing](https://www.firecrawl.dev/pricing) [Templates](https://www.firecrawl.dev/templates) [Changelog](https://www.firecrawl.dev/changelog)

Use Cases

[AI Platforms](https://www.firecrawl.dev/use-cases/ai-platforms) [Lead Enrichment](https://www.firecrawl.dev/use-cases/lead-enrichment) [SEO Teams](https://www.firecrawl.dev/use-cases/seo-teams) [Deep Research](https://www.firecrawl.dev/use-cases/deep-research) [Competitive Intelligence](https://www.firecrawl.dev/use-cases/competitive-intelligence)

Documentation

[Getting started](https://docs.firecrawl.dev/introduction) [API Reference](https://docs.firecrawl.dev/api-reference/introduction) [Integrations](https://www.firecrawl.dev/app) [Examples](https://docs.firecrawl.dev/use-cases/overview) [SDKs](https://docs.firecrawl.dev/sdks/overview)

Company

[Blog](https://www.firecrawl.dev/blog) [Careers](https://www.firecrawl.dev/careers) [Creator & OSS program](https://www.firecrawl.dev/creator-oss-program) [Student program](https://www.firecrawl.dev/student-program)

¬© 2025 Firecrawl

[Terms of Service](https://www.firecrawl.dev/terms-of-service) [Privacy Policy](https://www.firecrawl.dev/privacy-policy) [Report Abuse](mailto:help@firecrawl.com?subject=Issue:)

[All systems normal](https://status.firecrawl.dev/)

## Firecrawl Changelog Updates
Introducing Spark 1 Pro and Spark 1 Mini models in /agent. [Try it now ‚Üí](https://www.firecrawl.dev/agent)

Changelog

Feb 3, 2026

## v2.8.0 is live

![v2.8.0 Launch](https://www.firecrawl.dev/images/v28.webp)

Firecrawl v2.8.0 brings major improvements to agent workflows, developer tooling, and self-hosted deployments across the API and SDKs.

### Highlights

- **Parallel Agents** \- Execute thousands of `/agent` queries simultaneously with automatic failure handling and intelligent waterfall execution. Powered by Spark 1 Fast for instant retrieval, automatically upgrading to Spark 1 Mini for complex queries requiring deeper research.
- **Firecrawl Skill** \- Enables agents to use Firecrawl for web scraping and data extraction, install via `npx skills add firecrawl/cli`.
- **Firecrawl CLI** \- Command-line interface with full scrape, search, crawl & map support, install via `npm install -g firecrawl-cli`.
- **Spark Model Family** \- Three new models powering /agent: Spark 1 Fast for instant retrieval (currently only available in Playground), Spark 1 Mini for complex research queries, and Spark 1 Pro for advanced extraction tasks.
- **Agent Enhancements** \- Webhook support, model selection, and new MCP Server tools for autonomous web data gathering.

Read the full changelog [here](https://github.com/firecrawl/firecrawl/releases/tag/v2.8.0).

Jan 30, 2026

## Parallel Agents: Extract Web Data at Scale

We're bringing **parallel processing** to [/agent](https://www.firecrawl.dev/agent), letting you batch hundreds or even thousands of queries simultaneously. What took hours of sequential agent queries now completes in minutes with automatic failure handling and parallel execution.

Try it in the [Agent Playground](https://www.firecrawl.dev/app/agent) \- the playground automatically determines when your use case is a good fit for Parallel Agents.

![Parallel Agents](https://www.firecrawl.dev/images/blog/parallel-agents/parallel-agents.webp)

### Highlights

- **Parallel Batch Processing**: Run thousands of /agent queries simultaneously to enrich companies, research competitors, or build product datasets at scale.
- **Intelligent Waterfall**: Tries instant retrieval first, then automatically upgrades specific cells to full agent research (Spark One Mini) only when needed.
- **Real-Time Spreadsheet Interface**: Work in familiar CSV format with instant visual feedback as cells populate in real-time.
- **Zero Configuration**: Input your data schema, write one prompt, hit run. No workflow building required.
- **Predictable Pricing**: 10 credits per cell with Spark-1 Fast.

Read the full blog [here](https://www.firecrawl.dev/blog/introducing-parallel-agents).

Jan 27, 2026

## Introducing the Firecrawl Skill & CLI

![Firecrawl Skill + CLI](https://www.firecrawl.dev/images/blog/firecrawl-cli-skills-launch/firecrawlskillscli.webp)
We're introducing the **Firecrawl Skill and CLI**, a new way for AI agents to reliably access real-time web data on their own. With a single install, agents like Claude Code, Antigravity, and OpenCode can access all of your favorite Firecrawl endpoints - including scrape, search, crawl, and map for any use case you need.

Install the skill with `$ npx skills add firecrawl/cli` and learn more in our [docs](https://docs.firecrawl.dev/sdks/cli).

### Highlights

- **One-Command Install**: Install the skill with a single command and teach agents how to install, authenticate, and use all of Firecrawl's powerful end-to-end.
- **Real-Time Web Data at Runtime**: Agents can pull fresh, full-page content from docs, product pages, pricing, and articles exactly when they need it.
- **Context-Efficient for Agents**: Uses a file-based approach for context management and bash methods for efficient search and retrieval.
- **Works Across Complex & Dynamic Sites**: Powered by Firecrawl's custom browser stack to reliably extract complete data from large, JavaScript-heavy sites.
- **Proven, Best-in-Class Coverage**: Backed by benchmark results showing >80% coverage across real-world evaluations.

Read the full blog [here](http://firecrawl.dev/blog/introducing-firecrawl-skill-and-cli).

Dec 5, 2025

## v2.7.0 is here!

![v2.7.0 Launch](https://www.firecrawl.dev/images/v27.png)

### Highlights

- **ZDR Search Support** \- Enterprise customers can now search with Zero Data Retention enabled end to end. If you're interested, contact [alex@firecrawl.dev](mailto:alex@firecrawl.dev) to enable for your team.
- **Partner Integrations API** \- Available in closed beta for native integrations. Get in touch with us at [eric@firecrawl.dev](mailto:eric@firecrawl.dev) if you are intested in offering Firecrawl as a native integration in your product.
- **Improved Branding Format** \- Better detection and support across all platforms.
- **Faster Screenshots** \- Enhanced viewport and full page screenshots with improved speed and accuracy.
- **Self-hosted Improvements** \- Significant enhancements for deployments and infrastructure.
- **Performance Enhancements** \- Platform-wide improvements for better user experience.

Read the full changelog [here](https://github.com/firecrawl/firecrawl/releases/tag/v2.7.0)

Nov 14, 2025

## v2.6.0 available now

![v2.6.0 Launch](https://www.firecrawl.dev/images/v26.png)

### Highlights

- **Unified Billing Model** \- Credits and tokens merged into single system. Extract now uses credits (15 tokens = 1 credit), existing tokens work everywhere.
- **Enhanced Branding Format** \- Full support across Playground, MCP, JS and Python SDKs.
- **Reliability and Speed Improvements** \- All endpoints significantly faster with improved reliability.
- **Instant Credit Purchases** \- Buy credit packs directly from dashboard without waiting for auto-recharge.
- **Improved Markdown Parsing** \- Enhanced markdown conversion and main content extraction accuracy.
- **Change Tracking** \- Faster and more reliable detection of web page content updates.
- **Core Stability Fixes** \- Fixed tons of core stability issues, PDF timeouts, and improved error handling.

Read the full changelog [here](https://github.com/firecrawl/firecrawl/releases/tag/v2.6.0)

Oct 25, 2025

## v2.5.0 - The World's Best Web Data API

![v2.5.0 Launch](https://www.firecrawl.dev/images/v25.png)

Today, we're excited to announce Firecrawl v2.5, which delivers the **highest quality** and **most comprehensive** web data API available. This release represents a significant leap forward in web data extraction, powered by two major infrastructure improvements: our new Semantic Index and a completely custom browser stack.

See the benchmarks below:

![Benchmarks](https://www.firecrawl.dev/images/benchmark.png)

We've open-sourced these benchmarks! Check out [scrape-evals](https://www.firecrawl.dev/blog/introducing-scrape-evals), our reproducible framework for testing web scraping engines on 1,000 real URLs.

### Highlights

- **Open-Source Scrape-Evals Benchmark**


We've released [scrape-evals](https://www.firecrawl.dev/blog/introducing-scrape-evals), an open-source benchmark testing 13 web scraping engines on 1,000 real URLs for coverage and quality.

- **Full-Page, High-Quality Extraction**


Improved browser stack ensures complete and consistent data from any type of website.

- **Semantic Index for Faster Results**


Retrieve either fresh data or a previously indexed snapshot with faster speeds and increased coverage.

- **5x Cheaper Search & New Credit Packs**


Search is now 5x cheaper and now every plan has an auto-recharge credit pack sized to match your scale.

- **Smarter Concurrency & Crawl Architecture**


New crawling system improves throughput, reliability, and queue fairness across large workloads.

- **Excel (.xlsx) Scraping Support**


Extract clean data directly from spreadsheets or csv files.


### Get Started with Firecrawl v2.5

Firecrawl v2.5 is available now for all users - no code changes required. You can start experiencing the improved quality and coverage today:

- Experiment in our interactive [playground](https://www.firecrawl.dev/playground)
- Review the complete [documentation](https://docs.firecrawl.dev/)
- [Sign up](https://www.firecrawl.dev/) to integrate Firecrawl into your applications

We're excited to see what you build with the world's most reliable web data API.

Read more about it in our blog post [here](https://www.firecrawl.dev/blog/the-worlds-best-web-data-api-v25) and view the full changelog [here](https://github.com/firecrawl/firecrawl/releases/tag/v2.5.0)

Oct 13, 2025

## v2.4.0 is live now

![v2.4.0 Launch](https://www.firecrawl.dev/images/v24.png)

### What's New

- **New PDF Search Category** \- Search specifically for PDF documents using our v2/search endpoint with the new 'pdf' category filter
- **10x Better Semantic Crawling** \- Improved accuracy and relevance when crawling with a prompt
- **New x402 Search Endpoint** \- Our search API available via Coinbase x402 integration
- **Fire-enrich v2 Example** \- AI-powered data enrichment tool that transforms emails into rich datasets. See [repo](https://github.com/firecrawl/fire-enrich)
- **Enhanced Crawl Status & Warnings** \- Real-time status updates with clear feedback for robots.txt limitations and low-result scenarios
- **20+ Self-Host Improvements** \- Major stability and functionality upgrades for self-hosted deployments

Read the full changelog [here](https://github.com/firecrawl/firecrawl/releases/tag/v2.4.0)

Sep 19, 2025

## Firecrawl v2.3.0 is here

![v2.3.0 Launch](https://www.firecrawl.dev/images/v23.png)

### What's New

- YouTube transcript support
- Added odt & rtf parsing support
- Docx parsing is ~50x faster
- Enterprise Auto-Recharge
- Playground UX improvements
- Self hosting improvements

Read the full changelog [here](https://github.com/firecrawl/firecrawl/releases/tag/v2.3.0)

Sep 12, 2025

## Firecrawl v2.2.0 is here

![v2.2.0 Launch](https://www.firecrawl.dev/images/v22.png)

### New Features

- MCP version 3 is live. Stable support for cloud mcp with HTTP Transport and SSE modes. Compatible with v2 and v1 from.
- Webhooks: Now we support signatures + extract support + event failures
- Map is now 15x faster + supports more urls
- Search reliability improvements
- Usage is now tracked by API Key
- Support for additional locations (CA, CZ, IL, IN, IT, PL, and PT)
- Queue status endpoint
- Added `maxPages` parameter to v2 scrape API for pdf parsing

Read the full changelog [here](https://github.com/firecrawl/firecrawl/releases/tag/v2.2.0)

Aug 29, 2025

## Firecrawl v2.1.0 is here

![v2.1.0 Launch](https://www.firecrawl.dev/images/v21.png)

### New Features

- **Search Categories**: Filter search results by specific categories using the `categories` parameter:

  - `github`: Search within GitHub repositories, code, issues, and documentation
  - `research`: Search academic and research websites (arXiv, Nature, IEEE, PubMed, etc.)
  - More coming soon
- **Image Extraction:** Added image extraction support to the v2 scrape endpoint.
- **Data Attribute Scraping:** Now supports extraction of `data-*` attributes.
- **Hash-Based Routing:** Crawl endpoints now handle hash-based routes.
- **Improved Google Drive Scraping:** Added ability to scrape TXT, PDF, and Sheets from Google Drive.
- **PDF Enhancements:** Extracts PDF titles and shows them in metadata.
- Map endpoint supports up to **100k results**.

Read the full changelog [here](https://github.com/firecrawl/firecrawl/releases/tag/v2.1.0)

Aug 19, 2025

## Introducing Firecrawl v2

![Firecrawl v2](https://www.firecrawl.dev/images/v2-changelog.png)

### Key Improvements

- Faster by default: Requests are cached with maxAge defaulting to 2 days, and sensible defaults like blockAds, skipTlsVerification, and removeBase64Images are enabled.

- New summary format: You can now specify "summary" as a format to directly receive a concise summary of the page content.

- Updated JSON extraction: JSON extraction and change tracking now use an object format. The old "extract" format has been renamed to "json".

- Enhanced screenshot options: Use the object form.

- New search sources: Search across "news" and "images" in addition to web results by setting the sources parameter.

- Smart crawling with prompts: Pass a natural-language prompt to crawl and the system derives paths/limits automatically. Use the new crawl-params-preview endpoint to inspect the derived options before starting a job.


Read the full changelog [here](https://github.com/firecrawl/firecrawl/releases/tag/v2.0.0)

Jul 18, 2025

## Firecrawl v1.15.0 is here

## v1.15.0 Release

We're excited to announce the release of Firecrawl v1.15.0, packed with tons of improvements, bug fixes and enterprise features.

![v1.15.0 Launch](https://www.firecrawl.dev/images/v115.jpg)

- SSO for enterprise
- Improved scraping reliability
- Search params added to activity logs
- FireGEO example (Open Source FireGEO). See [repo](https://github.com/firecrawl/firegeo)
- And over 50 PRs merged for bug & improvements üî•

Read the full changelog [here](https://github.com/firecrawl/firecrawl/releases/tag/v1.15.0)

Jul 4, 2025

## Firecrawl v1.14.0 is here

## v1.14.0 Release

We're excited to announce the release of Firecrawl v1.14.0, packed with cool updates.

![v1.14.0 Launch](https://www.firecrawl.dev/images/v114.jpg)

- Authenticated scraping (Join the waitlist [here](https://firecrawl.dev/authenticated-scraping))
- Zero data retention for enterprise (Email us at [help@firecrawl.com](mailto:help@firecrawl.com) to enable it)
- Improved p75 speeds
- New MCP version w/ maxAge + better tool calling
- Open Researcher Example (Open Source Researcher). See [repo](https://github.com/firecrawl/open-researcher)
- And so much more. Check out [here](https://github.com/firecrawl/firecrawl/releases/tag/v1.14.0) for all the details üî•

Jun 27, 2025

## Firecrawl v1.13.0 is here

## v1.13.0 Release

We're excited to announce the release of Firecrawl v1.13.0, packed with awesome features.

![v1.13.0 Launch](https://www.firecrawl.dev/images/v113.jpg)

- Added AU, FR, DE to [Enhanced Mode](https://docs.firecrawl.dev/features/proxies#location-based-proxy-selection)
- Crawl subdomains with [allowSubdomains](https://docs.firecrawl.dev/api-reference/endpoint/crawl-post#body-allow-subdomains)
- Google slides scraping
- Generate a PDF of the current page. See [docs](https://docs.firecrawl.dev/api-reference/endpoint/scrape#generate-pdf)
- Higher res screenshots with [quality param](https://docs.firecrawl.dev/api-reference/endpoint/scrape#screenshot)
- Weekly view for usage on the dashboard
- Fireplexity Example (Open Source Perplexity). See [repo](https://github.com/firecrawl/fireplexity)
- And more!

Jun 20, 2025

## Firecrawl v1.12.0 is here

## v1.12.0 Release

We're excited to announce the release of Firecrawl v1.12.0, packed with new features.

![v1.12.0 Launch](https://www.firecrawl.dev/images/v112.jpg)

- New Concurrency System - Specify max concurrency by request in crawl and batch scrape for better control. [See docs](https://docs.firecrawl.dev/api-reference/endpoint/crawl-post#body-max-concurrency).
- Crawl Entire Domain Param - Follow internal links to sibling or parent URLs, not just child paths (prev. allowBackwardLinks). [See docs](https://docs.firecrawl.dev/api-reference/endpoint/crawl-post#body-crawl-entire-domain).
- Google Docs Scraping - We now officially support scraping Google Docs files
- Improved Activity Logs - Better support for FIRE-1 requests. [See your logs here.](https://www.firecrawl.dev/app/logs)
- /search Playground Enhanced - Location Params added. [Check out the playground.](https://www.firecrawl.dev/playground?mode=search)
- Firestarter Example - Open Source Chatbot building platform. [Repo here.](https://github.com/firecrawl/firestarter)
- Plus tons of performance improvements and bug fixes.

Jun 13, 2025

## Firecrawl v1.11.0 is here

## v1.11.0 Release

We're excited to announce the release of Firecrawl v1.11.0, packed with major performance improvements and new features.

![Index Launch](https://www.firecrawl.dev/images/index-launch.jpg)

**Major Updates:**

- **Firecrawl Index**: 500% faster scraping speeds when opted in. See [docs](https://docs.firecrawl.dev/features/fast-scraping) for more details.
- **Enhanced Activity Logs**:

  - View webhook events
  - See and manage active crawls
- **Fire Enrich Example**: New open-source Clay integration. Open Source repository [here](https://github.com/firecrawl/fire-enrich).
- **Community Java SDK**: Expanding our SDK support. View [repository](https://github.com/firecrawl/firecrawl-java-sdk).
- And many more improvements!

Jun 3, 2025

## Introducing Search

## Introducing Search

We're excited to announce the launch of our new Search API endpoint that combines web search with Firecrawl's powerful scraping capabilities.

![Search API](https://www.firecrawl.dev/images/llm_ready_search_for_devs_and_agents.webp)

**Key Features:**

- Search the web and get full content from results in one API call
- Choose specific output formats (markdown, HTML, links, screenshots)
- Customize search parameters (language, country, time range, number of results)
- Full SDK support for Python and Node.js

May 16, 2025

## Firecrawl v1.9.0 Release

## Firecrawl v1.9.0 Release

### **What's New:**

**Self-Host Improvements**

- Supabase client error fixes
- Fixed support for LLM Providers
- Crawl is much faster now
- Global adoption of cacheable lookup system
- Easier setup for self-host

**MCP Improvements (v1.11.0)**

- Tons of improvements to it (prompts, examples, and how to use params properly)

**SDK & API Enhancements**

- Added change tracking to SDK 2.0
- Crawl delay support with per-crawl concurrency limiting
- New Qwen3 crawler example via OpenRouter
- Cancel batch scrape endpoint

**Performance & Limits**

- Global adoption of cacheable lookup system
- Increased map endpoint limit from 5,000 to 30,000 links
- Search schema limit increased from 50 to 100

**Fixes & Stability**

- Better error handling for SSL failures
- Optional chaining bug fixes
- WaitAction field validation in firecrawl-py
- Concurrency queue reworked to prioritize by time, not priority

**Dashboard (Cloud version)**

- New activity logs

**GitHub Changelog**: [https://github.com/firecrawl/firecrawl/compare/v1.8.0...v1.9.0](https://github.com/firecrawl/firecrawl/compare/v1.8.0...v1.9.0)

May 5, 2025

## Enhanced Mode Updates

- **What is Enhanced Mode**: Enhanced Mode is a specialized proxy feature for scraping websites with advanced anti-bot protection, providing better success rates when extracting data from challenging sites.

- **Pricing Change**: Starting May 8th, 2025, Enhanced Mode proxy requests will cost 5 credits per request (previously included in standard credit pricing).

- **Quality Improvements**: The price adjustment reflects significant quality improvements to Enhanced Mode, ensuring higher success rates and more reliable data extraction from sites with sophisticated anti-scraping measures.

- **Usage Optimization**: For optimal credit usage, consider using Enhanced Mode as a retry mechanism only when encountering specific error status codes (401, 403, or 500).


Apr 28, 2025

## Firecrawl Launch Week III ‚Äì Summary

## Firecrawl Launch Week III ‚Äì Summary

**Day 7 ‚Äì Integration Day**

- 20+ new/updated integrations: Discord Bot, Make, n8n, Langflow, LlamaIndex, Dify, and more.

**Day 6 ‚Äì Firecrawl MCP**

- MCP now supports FIRE-1 agent for interaction-aware scraping.
- Added SSE streaming for real-time data.

**Day 5 ‚Äì Developer Day**

- **Python SDK v2.0**: async, named params, typed responses.
- **Rust SDK**: batch scraping, cancel jobs, `llms.txt`, smarter search.
- Up to 20 seats on every plan.
- New Firecrawl Dark Theme for VS Code & compatible editors.

**Day 4 ‚Äì LLMstxt.new**

- Prefix any URL with `llmstxt.new/` ‚Üí clean `.txt` output.
- Two outputs: `llms.txt` (summary) & `llms-full.txt` (full content).
- API-ready for LLM training/inference.

**Day 3 ‚Äì /extract v2**

- FIRE-1 powered extraction with pagination & dynamic flows.
- Extract without a URL via built-in search.
- Faster, more accurate models.

**Day 2 ‚Äì FIRE-1 Agent**

- AI agent for smart navigation and interaction.
- Handles pagination, buttons, and JS-rendered elements.

**Day 1 ‚Äì Change Tracking**

- Detect & diff webpage changes via SDK.
- Structured `changeTracking` format with timestamps.

**Day 0 ‚Äì Firecrawl Editor Theme**

- Official theme for VS Code, Cursor, Windsurf, etc.

Apr 4, 2025

## v1.7.0 Release Notes

### New Features

- **Deep Research Open Alpha**: Structured outputs + customizability.
- **Concurrent Browsers**: Improved rate limits for all users.
- **Compare Beta**: Figure what has changed in the website directly in /scrape and /crawl endpoints. Currently in closed beta.
- **/extract**: URLs are now optional.
- **/scrape**: Warns if concurrency-limited.
- **New Firecrawl Examples**: Featuring models like Claude 3.7, Gemini 2.5, Deepseek V3, Mistral 3.1, and more.
- **Crawl**: `maxDiscoveryDepth` option added.

### Fixes & Improvements

- Fixed **circular JSON error** in search.
- Reworked new **tally** system.
- Fixed sitemaps poisoning crawler with unrelated links.
- Crawler status retries added on failure (up to 3 times).
- Credit check now snaps to remaining credits if exceeded.
- Fixed path filtering bug in Map.
- Removed unsupported schema in `llmExtract`.

Mar 12, 2025

## Concurrent Browsers

We're excited to introduce **concurrent browsers** in our pricing!

We also 5x'd the rate limits, now displayed as concurrent browsers. This change provides more visibility and allows users to upgrade for faster speeds. Enjoy the awesome increase in rate limits across all plans!

See the new rate limits [here](https://docs.firecrawl.dev/rate-limits).

Mar 7, 2025

## v1.6.0

### Introducing LLMs.txt API

The /llmstxt endpoint allows you to transform any website into clean, [LLM-ready text files](https://www.firecrawl.dev/blog/How-to-Create-an-llms-txt-File-for-Any-Website). Simply provide a URL, and Firecrawl will crawl the site and generate both llms.txt and llms-full.txt files that can be used for training or analysis with any LLM.

Docs here: [https://docs.firecrawl.dev/features/alpha/llmstxt](https://docs.firecrawl.dev/features/alpha/llmstxt)

### Introducing Deep Research API (Alpha)

The /deep-research endpoint enables AI-powered deep research and analysis on any topic. Simply provide a research query, and Firecrawl will autonomously explore the web, gather relevant information, and synthesize findings into comprehensive insights.

Join the waitlist here: [https://www.firecrawl.dev/deep-research](https://www.firecrawl.dev/deep-research)

### Official Firecrawl MCP Server

Introducing the Firecrawl MCP Server. Give Cursor, Windsurf, Claude enhanced web extraction capabilities. Big thanks to [@vrknetha](https://github.com/vrknetha), [@cawstudios](https://caw.tech/) for the initial implementation!

See here: [https://github.com/firecrawl/firecrawl-mcp-server](https://github.com/firecrawl/firecrawl-mcp-server)

### Fixes & Enhancements

- Improved charset detection and re-decoding.
- Fixed extract token limit issues.
- Addressed issues with includes/excludes handling.
- Fixed AI SDK handling of JSON responses.

### New Features & Improvements

- AI-SDK Migration ‚Äì transitioned to AI-SDK.
- Auto-Recharge Emails ‚Äì notify users about upgrades.
- Fire-Index Added ‚Äì introduced a new indexing system.
- Self-Hosting Enhancements ‚Äì OpenAI-compatible API & Ollama env support.
- Batch Billing ‚Äì streamlined billing processes.
- Supabase Read Replica Routing ‚Äì improved database performance.

### Crawler & AI Improvements

- Implemented Claude 3.7 and GPT-4.5 web crawlers.
- Added Groq Web Crawler example.
- Updated crawl-status behavior for better error handling.
- Improved cross-origin redirect handling.

### Documentation & Maintenance

- Updated Dockerfile.
- Fixed missing "required" field in docs.

Feb 20, 2025

## Self Host Overhaul - v1.5.0

### Self-Host Fixes

- **Reworked Guide:** The `SELF_HOST.md` and `docker-compose.yaml` have been updated for clarity and compatibility
- **Kubernetes Imporvements:** Updated self-hosted Kubernetes deployment examples for compatibility and consistency (#1177)
- **Self-Host Fixes:** Numerous fixes aimed at improving self-host performance and stability (#1207)
- **Proxy Support:** Added proxy support tailored for self-hosted environments (#1212)
- **Playwright Integration:** Added fixes and continuous integration for the Playwright microservice (#1210)
- **Search Endpoint Upgrade:** Added SearXNG support for the `/search` endpoint (#1193)

### Core Fixes & Enhancements

- **Crawl Status Fixes:** Fixed various race conditions in the crawl status endpoint (#1184)
- **Timeout Enforcement:** Added timeout for scrapeURL engines to prevent hanging requests (#1183)
- **Query Parameter Retention:** Map function now preserves query parameters in results (#1191)
- **Screenshot Action Order:** Ensured screenshots execute after specified actions (#1192)
- **PDF Scraping:** Improved handling for PDFs on complex websites (#1198)
- **Map/scrapeURL Abort Control:** Integrated AbortController to stop scraping when the request times out (#1205)
- **SDK Timeout Enforcement:** Enforced request timeouts in the SDK (#1204)

### New Features & Additions

- **Proxy Options:** Introduced proxy configuration options for infrastructure management (#1196)
- **Deep Research (Alpha):** Launched an alpha implementation of deep research (#1202)
- **LLM Text Generator:** Added a new endpoint for llms.txt generation (#1201)

### Docker & Containerization

- **Production Ready Docker Image:** A streamlined, production ready Docker image is now available to simplify self-hosted deployments.

Feb 14, 2025

## v1.4.4

### Features & Enhancements

- Scrape API: Added action & wait time validation ( [#1146](https://github.com/firecrawl/firecrawl/pull/1146))
- Extraction Improvements:
  - Added detection of PDF/image sub-links & extracted text via Gemini ( [#1173](https://github.com/firecrawl/firecrawl/pull/1173))
  - Multi-entity prompt enhancements for extraction ( [#1181](https://github.com/firecrawl/firecrawl/pull/1181))
  - Show sources out of \_\_experimental in extraction ( [#1180](https://github.com/firecrawl/firecrawl/pull/1180))
- Environment Setup: Added Serper & Search API env vars to docker-compose ( [#1147](https://github.com/firecrawl/firecrawl/pull/1147))
- Credit System Update: Now displays "tokens" instead of "credits" when out of tokens ( [#1178](https://github.com/firecrawl/firecrawl/pull/1178))

### Examples

- Gemini 2.0 Crawler: Implemented new crawling example ( [#1161](https://github.com/firecrawl/firecrawl/pull/1161))
- Gemini TrendFinder: [https://github.com/firecrawl/gemini-trendfinder](https://github.com/firecrawl/gemini-trendfinder)
- Normal Search to Open Deep Research: [https://github.com/nickscamara/open-deep-research](https://github.com/nickscamara/open-deep-research)

### Fixes

- HTML Transformer: Updated free\_string function parameter type ( [#1163](https://github.com/firecrawl/firecrawl/pull/1163))
- Gemini Crawler: Updated library & improved PDF link extraction ( [#1175](https://github.com/firecrawl/firecrawl/pull/1175))
- Crawl Queue Worker: Only reports successful page count in num\_docs ( [#1179](https://github.com/firecrawl/firecrawl/pull/1179))
- Scraping & URLs:
  - Fixed relative URL conversion ( [#584](https://github.com/firecrawl/firecrawl/pull/584))
  - Enforced scrape rate limit in batch scraping ( [#1182](https://github.com/firecrawl/firecrawl/pull/1182))

Feb 7, 2025

## Examples Week - v1.4.3

### Summary of changes

- Open Deep Research: An open source version of OpenAI Deep Research. See here: [https://github.com/nickscamara/open-deep-research](https://github.com/nickscamara/open-deep-research)
- R1 Web Extractor Feature: New extraction capability added.
- O3-Mini Web Crawler: Introduces a lightweight crawler for specific use cases.
- Updated Model Parameters: Enhancements to o3-mini\_company\_researcher.
- URL Deduplication: Fixes handling of URLs ending with /, index.html, index.php, etc.
- Improved URL Blocking: Uses tldts parsing for better blocklist management.
- Valid JSON via rawHtml in Scrape: Ensures valid JSON extraction.
- Product Reviews Summarizer: Implements summarization using o3-mini.
- Scrape Options for Extract: Adds more configuration options for extracting data.
- O3-Mini Job Resource Extractor: Extracts job-related resources using o3-mini.
- Cached Scrapes for Extract evals: Improves performance by using cached data for extractions evals.

Jan 31, 2025

## Extract & API Improvements - v1.4.2

We're excited to announce several new features and improvements:

### New Features

- Added web search capabilities to the extract endpoint via the `enableWebSearch` parameter
- Introduced source tracking with `__experimental_showSources` parameter
- Added configurable webhook events for crawl and batch operations
- New `timeout` parameter for map endpoint
- Optional ad blocking with `blockAds` parameter (enabled by default)

### Infrastructure & UI

- Enhanced proxy selection and infrastructure reliability
- Added domain checker tool to cloud platform
- Redesigned LLMs.txt generator interface for better usability

Jan 24, 2025

## Extract Improvements - v1.4.1

We've significantly enhanced our data extraction capabilities with several key updates:

- Extract now returns a lot more data
- Improved infrastructure reliability
- Migrated from Cheerio to a high-performance Rust-based parser for faster and more memory-efficient parsing
- Enhanced crawl cancellation functionality for better control over running jobs

Jan 7, 2025

## /extract changes

We have updated the `/extract` endpoint to now be asynchronous. When you make a request to `/extract`, it will return an ID that you can use to check the status of your extract job. If you are using our SDKs, there are no changes required to your code, but please make sure to update the SDKs to the latest versions as soon as possible.

For those using the API directly, we have made it backwards compatible. However, you have 10 days to update your implementation to the new asynchronous model.

For more details about the parameters, refer to the docs sent to you.

Jan 3, 2025

## v1.2.0

### Introducing /v1/search

The search endpoint combines web search with Firecrawl‚Äôs scraping capabilities to return full page content for any query.

Include `scrapeOptions` with `formats: ["markdown"]` to get complete markdown content for each search result otherwise it defaults to getting SERP results (url, title, description).

More info here: [v1/search docs](https://docs.firecrawl.dev/api-reference/endpoint/search)

### Fixes and improvements

- Fixed LLM not following the schema in the python SDK for `/extract`
- Fixed schema json not being able to be sent to the `/extract` endpoint through the Node SDK
- Prompt is now optional for the `/extract` endpoint
- Our fork of [MinerU](https://github.com/firecrawl/mineru-api) is now default for PDF Parsing

Dec 27, 2024

## v1.1.0

### Changelog Highlights

#### Feature Enhancements

- **New Features**:

  - Geolocation, mobile scraping, 4x faster parsing, better webhooks,
  - Credit packs, auto-recharges and batch scraping support.
  - Iframe support and query parameter differentiation for URLs.
  - Similar URL deduplication.
  - Enhanced map ranking and sitemap fetching.

#### Performance Improvements

- Faster crawl status filtering and improved map ranking algorithm.
- Optimized Kubernetes setup and simplified build processes.
- Sitemap discoverability and performance improved

#### Bug Fixes

- Resolved issues:
  - Badly formatted JSON, scrolling actions, and encoding errors.
  - Crawl limits, relative URLs, and missing error handlers.
- Fixed self-hosted crawling inconsistencies and schema errors.

#### SDK Updates

- Added dynamic WebSocket imports with fallback support.
- Optional API keys for self-hosted instances.
- Improved error handling across SDKs.

#### Documentation Updates

- Improved API docs and examples.
- Updated self-hosting URLs and added Kubernetes optimizations.
- Added articles: mastering `/scrape` and `/crawl`.

#### Miscellaneous

- Added new Firecrawl examples
- Enhanced metadata handling for webhooks and improved sitemap fetching.
- Updated blocklist and streamlined error messages.

Oct 28, 2024

![Batch Scrape](https://www.firecrawl.dev/images/blog/firecrawl-batch-scrape.jpg)

## Introducing Batch Scrape

You can now scrape multiple URLs simultaneously with our new Batch Scrape endpoint.

- Read more about the Batch Scrape endpoint [here](https://www.firecrawl.dev/blog/launch-week-ii-day-1-introducing-batch-scrape-endpoint).
- Python SDK (1.4.x) and Node SDK (1.7.x) updated with batch scrape support.

Oct 10, 2024

## Cancel Crawl in the SDKs, More Examples, Improved Speed

- Added crawl cancellation support for the Python SDK (1.3.x) and Node SDK (1.6.x)
- OpenAI Voice + Firecrawl example added to the repo
- CRM lead enrichment example added to the repo
- Improved our Docker images
- Limit and timeout fixes for the self hosted playwright scraper
- Improved speed of all scrapes

Sep 27, 2024

## Fixes + Improvements (no version bump)

- Fixed 500 errors that would happen often in some crawled websites and when servers were at capacity
- Fixed an issue where v1 crawl status wouldn't properly return pages over 10mb
- Fixed an issue where `screenshot` would return undefined
- Push improvements that reduce speed times when a scraper fails

Sep 24, 2024

![Actions](https://www.firecrawl.dev/images/actions.png)

## Introducing Actions

Interact with pages before extracting data, unlocking more data from every site!

Firecrawl now allows you to perform various actions on a web page before scraping its content. This is particularly useful for interacting with dynamic content, navigating through pages, or accessing content that requires user interaction.

- Version 1.5.x of the Node SDK now supports type-safe Actions.
- Actions are now available in the REST API and Python SDK (no version bumps required!).

Here is a python example of how to use actions to navigate to google.com, search for Firecrawl, click on the first result, and take a screenshot.

```
from firecrawl import Firecrawl

app = Firecrawl(api_key="fc-YOUR_API_KEY")

# Scrape a website:
scrape_result = app.scrape_url('firecrawl.dev',
    params={
        'formats': ['markdown', 'html'],
        'actions': [\
            {"type": "wait", "milliseconds": 2000},\
            {"type": "click", "selector": "textarea[title=\"Search\"]"},\
            {"type": "wait", "milliseconds": 2000},\
            {"type": "write", "text": "firecrawl"},\
            {"type": "wait", "milliseconds": 2000},\
            {"type": "press", "key": "ENTER"},\
            {"type": "wait", "milliseconds": 3000},\
            {"type": "click", "selector": "h3"},\
            {"type": "wait", "milliseconds": 3000},\
            {"type": "screenshot"}\
        ]
    }
)
print(scrape_result)
```

For more examples, check out our [API Reference](https://docs.firecrawl.dev/api-reference/endpoint/scrape).

Sep 23, 2024

![Firecrawl E2E Type Safe LLM Extract](https://www.firecrawl.dev/images/newllmextract.jpeg)

## Mid-September Updates

### Typesafe LLM Extract

- E2E Type Safety for LLM Extract in Node SDK version 1.5.x.
- 10x cheaper in the cloud version. From 50 to 5 credits per extract.
- Improved speed and reliability.

### Rust SDK v1.0.0

- Rust SDK v1 is finally here! Check it out [here](https://crates.io/crates/firecrawl/1.0.0).

### Map Improved Limits

- Map smart results limits increased from 100 to 1000.

### Faster scrape

- Scrape speed improved by 200ms-600ms depending on the website.

### Launching changelog

- For now on, for every new release, we will be creating a changelog entry here.

### Improvements

- Lots of improvements pushed to the infra and API. For all Mid-September changes, refer to the commits [here](https://github.com/firecrawl/firecrawl/commits/main/).

Sep 8, 2024

## September 8, 2024

### Patch Notes (No version bump)

- Fixed an issue where some of the custom header params were not properly being set in v1 API. You can now pass headers to your requests just fine.

Aug 29, 2024

![Firecrawl V1](https://www.firecrawl.dev/images/blog/f-v1-changelog.png)

## Firecrawl V1 is here! With that we introduce a more reliable and developer friendly API.

### Here is what's new:

- Output Formats for /scrape: Choose what formats you want your output in.
- New /map endpoint: Get most of the URLs of a webpage.
- Developer friendly API for /crawl/id status.
- 2x Rate Limits for all plans.
- Go SDK and Rust SDK.
- Teams support.
- API Key Management in the dashboard.
- onlyMainContent is now default to true.
- /crawl webhooks and websocket support.

Learn more about it [here](https://docs.firecrawl.dev/v1).

Start using v1 right away at [https://firecrawl.dev](https://firecrawl.dev/)

\[ CTA \]

\[ CRAWL \]

\[ SCRAPE \]

\[ CTA \]

//

Get started

//

Ready to build?

Start getting Web Data for free and scale seamlessly as your project expands. No credit card needed.

[Start for free](https://www.firecrawl.dev/signin) [See our plans](https://www.firecrawl.dev/pricing)

FOOTER

The easiest way to extract

data from the web

Backed by

Y Combinator

[Linkedin](https://www.linkedin.com/company/firecrawl) [Github](https://github.com/firecrawl/firecrawl) [YouTube](https://www.youtube.com/@Firecrawl_dev)

SOC II ¬∑ Type 2

AICPA

SOC 2

[X (Twitter)](https://x.com/firecrawl) [Discord](https://discord.gg/gSmWdAkdwd)

Products

[Playground](https://www.firecrawl.dev/playground) [Agent](https://www.firecrawl.dev/agent) [Pricing](https://www.firecrawl.dev/pricing) [Templates](https://www.firecrawl.dev/templates) [Changelog](https://www.firecrawl.dev/changelog)

Use Cases

[AI Platforms](https://www.firecrawl.dev/use-cases/ai-platforms) [Lead Enrichment](https://www.firecrawl.dev/use-cases/lead-enrichment) [SEO Teams](https://www.firecrawl.dev/use-cases/seo-teams) [Deep Research](https://www.firecrawl.dev/use-cases/deep-research) [Competitive Intelligence](https://www.firecrawl.dev/use-cases/competitive-intelligence)

Documentation

[Getting started](https://docs.firecrawl.dev/introduction) [API Reference](https://docs.firecrawl.dev/api-reference/introduction) [Integrations](https://www.firecrawl.dev/app) [Examples](https://docs.firecrawl.dev/use-cases/overview) [SDKs](https://docs.firecrawl.dev/sdks/overview)

Company

[Blog](https://www.firecrawl.dev/blog) [Careers](https://www.firecrawl.dev/careers) [Creator & OSS program](https://www.firecrawl.dev/creator-oss-program) [Student program](https://www.firecrawl.dev/student-program)

¬© 2025 Firecrawl

[Terms of Service](https://www.firecrawl.dev/terms-of-service) [Privacy Policy](https://www.firecrawl.dev/privacy-policy) [Report Abuse](mailto:help@firecrawl.com?subject=Issue:)

[All systems normal](https://status.firecrawl.dev/)

## Web Data APIs Glossary
Introducing the Firecrawl Skill + CLI for Agents. [Learn more ‚Üí](https://docs.firecrawl.dev/sdks/cli)

# The Web Data APIs Glossary

Your complete reference for Web Search, Crawling, Scraping, and Extraction APIs. Learn about discovery, retrieval, and data structuring for the modern web.

## Browse by Category

Explore definitions and Q&A organized by topic

[**Web Search APIs**\\
\\
Querying pre-built indexes to find relevant information. Key concepts: relevance, ranking, and retrieval.\\
\\
12questions](https://www.firecrawl.dev/glossary/web-search-apis) [**Web Crawling APIs**\\
\\
Discovering and fetching web pages at scale. Key concepts: URL discovery, link traversal, politeness, and crawl management.\\
\\
19questions](https://www.firecrawl.dev/glossary/web-crawling-apis) [**Web Scraping APIs**\\
\\
Automated web content fetching. Key concepts: dynamic content, request handling, and data retrieval.\\
\\
55questions](https://www.firecrawl.dev/glossary/web-scraping-apis) [**Web Extraction APIs**\\
\\
Parsing HTML to extract structured data fields. Key concepts: selectors, patterns, and data structuring.\\
\\
18questions](https://www.firecrawl.dev/glossary/web-extraction-apis)

\[ CTA \]

\[ CRAWL \]

\[ SCRAPE \]

\[ CTA \]

//

Get started

//

Ready to build?

Start getting Web Data for free and scale seamlessly as your project expands. No credit card needed.

[Start for free](https://www.firecrawl.dev/signin) [See our plans](https://www.firecrawl.dev/pricing)

FOOTER

The easiest way to extract

data from the web

Backed by

Y Combinator

[Linkedin](https://www.linkedin.com/company/firecrawl) [Github](https://github.com/firecrawl/firecrawl) [YouTube](https://www.youtube.com/@Firecrawl_dev)

SOC II ¬∑ Type 2

AICPA

SOC 2

[X (Twitter)](https://x.com/firecrawl) [Discord](https://discord.gg/gSmWdAkdwd)

Products

[Playground](https://www.firecrawl.dev/playground) [Agent](https://www.firecrawl.dev/agent) [Pricing](https://www.firecrawl.dev/pricing) [Templates](https://www.firecrawl.dev/templates) [Changelog](https://www.firecrawl.dev/changelog)

Use Cases

[AI Platforms](https://www.firecrawl.dev/use-cases/ai-platforms) [Lead Enrichment](https://www.firecrawl.dev/use-cases/lead-enrichment) [SEO Teams](https://www.firecrawl.dev/use-cases/seo-teams) [Deep Research](https://www.firecrawl.dev/use-cases/deep-research) [Competitive Intelligence](https://www.firecrawl.dev/use-cases/competitive-intelligence)

Documentation

[Getting started](https://docs.firecrawl.dev/introduction) [API Reference](https://docs.firecrawl.dev/api-reference/introduction) [Integrations](https://www.firecrawl.dev/app) [Examples](https://docs.firecrawl.dev/use-cases/overview) [SDKs](https://docs.firecrawl.dev/sdks/overview)

Company

[Blog](https://www.firecrawl.dev/blog) [Careers](https://www.firecrawl.dev/careers) [Creator & OSS program](https://www.firecrawl.dev/creator-oss-program) [Student program](https://www.firecrawl.dev/student-program)

¬© 2025 Firecrawl

[Terms of Service](https://www.firecrawl.dev/terms-of-service) [Privacy Policy](https://www.firecrawl.dev/privacy-policy) [Report Abuse](mailto:help@firecrawl.com?subject=Issue:)

[All systems normal](https://status.firecrawl.dev/)

## Firecrawl Careers Page
Introducing Spark 1 Pro and Spark 1 Mini models in /agent. [Try it now ‚Üí](https://www.firecrawl.dev/agent)

Careers

At Firecrawl, we're building the interface between LLMs and real-time data on the web. We're building the eyes for AGI.

Lean team ‚Äî We plan to hit $100M in ARR with fewer than 30 people

Extreme speed ‚Äî Look at how fast we ship on [X](https://x.com/firecrawl)

Founder-led ‚Äî 80% of our team are former founders, 80% have a developer background

### Engineering

[**Forward Deployment Engineer (Developer Success)** \\
\\
San Francisco, CA (Hybrid) OR Remote-Global\\
\\
Full Time](https://jobs.ashbyhq.com/firecrawl/bda40f47-a69b-44d4-ac1a-3f86f20d802d)

### Marketing & Growth

[**Designer (Brand + Product)** \\
\\
Remote-Global\\
\\
Full Time](https://jobs.ashbyhq.com/firecrawl/cf35aad9-adb4-4a13-87e9-bab9eead8d00) [**Distribution Partnerships Lead** \\
\\
San Francisco, CA (Hybrid)\\
\\
Full Time](https://jobs.ashbyhq.com/firecrawl/3c7ec24a-b011-4238-bfc6-aac6f8ed3b9a) [**Sales Engineer (Developer-Focused)** \\
\\
San Francisco, CA (Hybrid) OR Remote-Global\\
\\
Full Time](https://jobs.ashbyhq.com/firecrawl/851c1270-56a3-4d14-b4a4-f9eac2ab3a7f)

\[ CTA \]

\[ CRAWL \]

\[ SCRAPE \]

\[ CTA \]

//

Get started

//

Ready to build?

Start getting Web Data for free and scale seamlessly as your project expands. No credit card needed.

[Start for free](https://www.firecrawl.dev/signin) [See our plans](https://www.firecrawl.dev/pricing)

FOOTER

The easiest way to extract

data from the web

Backed by

Y Combinator

[Linkedin](https://www.linkedin.com/company/firecrawl) [Github](https://github.com/firecrawl/firecrawl) [YouTube](https://www.youtube.com/@Firecrawl_dev)

SOC II ¬∑ Type 2

AICPA

SOC 2

[X (Twitter)](https://x.com/firecrawl) [Discord](https://discord.gg/gSmWdAkdwd)

Products

[Playground](https://www.firecrawl.dev/playground) [Agent](https://www.firecrawl.dev/agent) [Pricing](https://www.firecrawl.dev/pricing) [Templates](https://www.firecrawl.dev/templates) [Changelog](https://www.firecrawl.dev/changelog)

Use Cases

[AI Platforms](https://www.firecrawl.dev/use-cases/ai-platforms) [Lead Enrichment](https://www.firecrawl.dev/use-cases/lead-enrichment) [SEO Teams](https://www.firecrawl.dev/use-cases/seo-teams) [Deep Research](https://www.firecrawl.dev/use-cases/deep-research) [Competitive Intelligence](https://www.firecrawl.dev/use-cases/competitive-intelligence)

Documentation

[Getting started](https://docs.firecrawl.dev/introduction) [API Reference](https://docs.firecrawl.dev/api-reference/introduction) [Integrations](https://www.firecrawl.dev/app) [Examples](https://docs.firecrawl.dev/use-cases/overview) [SDKs](https://docs.firecrawl.dev/sdks/overview)

Company

[Blog](https://www.firecrawl.dev/blog) [Careers](https://www.firecrawl.dev/careers) [Creator & OSS program](https://www.firecrawl.dev/creator-oss-program) [Student program](https://www.firecrawl.dev/student-program)

¬© 2025 Firecrawl

[Terms of Service](https://www.firecrawl.dev/terms-of-service) [Privacy Policy](https://www.firecrawl.dev/privacy-policy) [Report Abuse](mailto:help@firecrawl.com?subject=Issue:)

[All systems normal](https://status.firecrawl.dev/)

